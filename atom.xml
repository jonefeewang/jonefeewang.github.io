<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王军飞的随笔</title>
  
  <subtitle>always be the best</subtitle>
  <link href="https://www.wangjunfei.com/atom.xml" rel="self"/>
  
  <link href="https://www.wangjunfei.com/"/>
  <updated>2022-02-11T03:32:19.523Z</updated>
  <id>https://www.wangjunfei.com/</id>
  
  <author>
    <name>王军飞</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《华为灰度管理法》阅读-第五章 灰度选拔</title>
    <link href="https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%80%89%E6%8B%94/"/>
    <id>https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%80%89%E6%8B%94/</id>
    <published>2021-03-16T07:49:45.000Z</published>
    <updated>2022-02-11T03:32:19.523Z</updated>
    
    <content type="html"><![CDATA[<p>华为的干部评价标准包括品德价值，核心价值观，绩效和能力四个维度。</p><p>品德价值是底线，核心价值观是基础，绩效是必要条件和分水岭，能力是关键成功因素。这四句话是华为高层对于干部标准的高度概括。</p><h2 id="华为干部“四力”"><a href="#华为干部“四力”" class="headerlink" title="华为干部“四力”"></a><a href="#%E5%8D%8E%E4%B8%BA%E5%B9%B2%E9%83%A8%E2%80%9C%E5%9B%9B%E5%8A%9B%E2%80%9D" title="华为干部“四力”"></a>华为干部“四力”</h2><p>决断力<br>所谓决断力，就是要求高层干部冒敢于评估的风险，去做决策。敢于决策，且善于决策的人，才能成为高层干部，才能成为接班人。</p><h3 id="理解力"><a href="#理解力" class="headerlink" title="理解力"></a><a href="#%E7%90%86%E8%A7%A3%E5%8A%9B" title="理解力"></a>理解力</h3><p>理解力就是要听懂公司对于战略和战术背后的布局，并且变成自己的行动。</p><h3 id="执行力"><a href="#执行力" class="headerlink" title="执行力"></a><a href="#%E6%89%A7%E8%A1%8C%E5%8A%9B" title="执行力"></a>执行力</h3><p>执行力的培养是一个漫长的过程。</p><h3 id="人际连接力"><a href="#人际连接力" class="headerlink" title="人际连接力"></a><a href="#%E4%BA%BA%E9%99%85%E8%BF%9E%E6%8E%A5%E5%8A%9B" title="人际连接力"></a>人际连接力</h3><p>能当面聊绝不打电话，能电话说清绝不发邮件。对于干部来讲，要鼓励通过主动沟通来解决问题。</p><p>不同类型的干部对于四力的把控，可以从人员分级上来考量：</p><p>高层干部培养决断力，中基层干部要加强理解力，执行力和人际连接力。</p><p>对于高层干部，要更多的使用使命感去激发他们。</p><p>对于中层干部，要加强他们的危机感和紧迫感，让他们多做事，多动脑。</p><p>对于基层干部，要给他们构建起一种饥饿感，让他们觉得总有更多的目标要完成，有更多的事情去做。</p><h2 id="明确指的优先选拔的干部类型"><a href="#明确指的优先选拔的干部类型" class="headerlink" title="明确指的优先选拔的干部类型"></a><a href="#%E6%98%8E%E7%A1%AE%E6%8C%87%E7%9A%84%E4%BC%98%E5%85%88%E9%80%89%E6%8B%94%E7%9A%84%E5%B9%B2%E9%83%A8%E7%B1%BB%E5%9E%8B" title="明确指的优先选拔的干部类型"></a>明确指的优先选拔的干部类型</h2><p>第一类 有成功搞得区域业务实践经验。</p><p>第二类 是在影响公司长远发展的关键事件中表现突出的干部。要鼓励干部在关键时候敢于作为，敢于挺身而出。</p><p>第三类 是有干劲，服从公司安排，愿意承担挑战性岗位和更大责任的干部。</p><p>华为干部管理中还有一个重要的原则，叫作从成功的组织中选拔干部。如果一个组织没有达到好的绩效结果，就算一把手被免掉了，二把手、三把手也根本没有机会被提拔。</p>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://www.wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第四章 灰度高效组织体系</title>
    <link href="https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%AB%98%E6%95%88%E7%BB%84%E7%BB%87%E4%BD%93%E7%B3%BB/"/>
    <id>https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%AB%98%E6%95%88%E7%BB%84%E7%BB%87%E4%BD%93%E7%B3%BB/</id>
    <published>2021-03-16T07:48:59.000Z</published>
    <updated>2022-02-11T03:29:16.370Z</updated>
    
    <content type="html"><![CDATA[<p>很多企业组织是金字塔结构，一线员工发现了客户的需求或者机会要层层汇报，最后由总经理拍板。拍板后的决定又层层下传，到一线落地执行。这样的流程往往会夹杂一些自己的意见，最终决策人会因为对信息的真实性与准确性产生怀疑而难以判断。</p><p>华为是怎么突破这个呢？华为通过20年的管理变革，塑造了流程性组织。流程性组织最大的特点是决策指令并不来自于最高层，而是来自离客户最近的人，这就是以客户为中心的导向驱动。</p>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://www.wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第三章 灰度的评价</title>
    <link href="https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%9A%84%E8%AF%84%E4%BB%B7/"/>
    <id>https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%9A%84%E8%AF%84%E4%BB%B7/</id>
    <published>2021-03-16T07:47:49.000Z</published>
    <updated>2022-02-11T03:30:33.344Z</updated>
    
    <content type="html"><![CDATA[<p>选对人，是人力资源成功的第一步。要向达到卓越的成果，我们就需要对绩效目标进行科学的管理。</p><p>价值评价的根本在于精准，但是人类社会在人才价值度量上是无法做到精准的，华为的灰度思想，就是要在牢牢抓住科学目标的基础上，允许绩效评价的迭代与优化。</p><h2 id="科学的目标管理体系"><a href="#科学的目标管理体系" class="headerlink" title="科学的目标管理体系"></a><a href="#%E7%A7%91%E5%AD%A6%E7%9A%84%E7%9B%AE%E6%A0%87%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB" title="科学的目标管理体系"></a>科学的目标管理体系</h2><p>绩效管理要紧紧围绕科学的目标，公正的过程和刚性的应用这三个方面展开。</p><p>刚性的应用:<br>我们花了很多精力去做目标管理，做公证的评价，但如果是评价出来的结果没有得到有效应用，那其实整个绩效工作也是没有意义的，所以一定要依据评价结果，做到刚性的应用。</p><h2 id="区别对待不同层级，做到公正底考核"><a href="#区别对待不同层级，做到公正底考核" class="headerlink" title="区别对待不同层级，做到公正底考核"></a><a href="#%E5%8C%BA%E5%88%AB%E5%AF%B9%E5%BE%85%E4%B8%8D%E5%90%8C%E5%B1%82%E7%BA%A7%EF%BC%8C%E5%81%9A%E5%88%B0%E5%85%AC%E6%AD%A3%E5%BA%95%E8%80%83%E6%A0%B8" title="区别对待不同层级，做到公正底考核"></a>区别对待不同层级，做到公正底考核</h2><p>通过PBC对中基层员工进行绩效管理<br>中基层员工根据他们的工作职责去承接一部分战略落地结果。对于这个群体，要引导他们用正确的方法去做正确的事，不断追求更好的工作效果，不需要太复杂的绩效目标进行考核，只要符合他们的岗位职责即可。</p><p>用这种方式去管理目标，我们需要重点考量三个因素。第一，阶段性工作目标，第二关键措施，第三，中基层员工他们的团队合作。</p><h2 id="高层人员的绩效管理主要采用述职的方法"><a href="#高层人员的绩效管理主要采用述职的方法" class="headerlink" title="高层人员的绩效管理主要采用述职的方法"></a><a href="#%E9%AB%98%E5%B1%82%E4%BA%BA%E5%91%98%E7%9A%84%E7%BB%A9%E6%95%88%E7%AE%A1%E7%90%86%E4%B8%BB%E8%A6%81%E9%87%87%E7%94%A8%E8%BF%B0%E8%81%8C%E7%9A%84%E6%96%B9%E6%B3%95" title="高层人员的绩效管理主要采用述职的方法"></a>高层人员的绩效管理主要采用述职的方法</h2><p>述职就是不断地通过和战略目标对标，将公司的战略目标分解过程和执行效果进行及时的校准，形成考核依据。</p><p>通过述职的方式还有一个好处，即可以促进高层领导理清思路，明确责任，抓住重点，综合平衡。</p><p>高层述职要掌握两个重点：</p><p>第一，绩效目标要形成“扭麻花”</p><p>设么叫扭麻花？比如，我们想要把销售目标传递下去，销售部门要制定目标，产品技术部门也要制定同样的目标，要形成合理去构建目标体系。</p><p>第二，要关注不同阶段的目标设计。</p><h2 id="绩效管理的原则"><a href="#绩效管理的原则" class="headerlink" title="绩效管理的原则"></a><a href="#%E7%BB%A9%E6%95%88%E7%AE%A1%E7%90%86%E7%9A%84%E5%8E%9F%E5%88%99" title="绩效管理的原则"></a>绩效管理的原则</h2><p>第一个原则，以行为为导向，引导员工以正确的行为做正确的事，不断改进工作。</p><p>第二个原则，个人目标和组织目标一致。</p><p>第三个原则，客观公正。 考核结果要以客观事实和数据为依据，考核过程要透明、公开，千万不能搞模棱两可的打分制。我非常反对360度评测，在华为没有这种评测机制。大家都说的那个人一定真的好么？ 不一定。真正做事情的人，必然会在做事的过程中与他人产生一些冲突，这种冲突一定会反应到别人对他的评价里来。</p><p>绩效管理的目的是什么？ 不是去考察一个不做事的人的人际关系，而是要考虑他实实在在的贡献，我们的评价一定要以事实为依据，以目标数据为考量标准，而不能考察人情分。</p><h2 id="做好PDCA循环，做到公正的执行"><a href="#做好PDCA循环，做到公正的执行" class="headerlink" title="做好PDCA循环，做到公正的执行"></a><a href="#%E5%81%9A%E5%A5%BDPDCA%E5%BE%AA%E7%8E%AF%EF%BC%8C%E5%81%9A%E5%88%B0%E5%85%AC%E6%AD%A3%E7%9A%84%E6%89%A7%E8%A1%8C" title="做好PDCA循环，做到公正的执行"></a>做好PDCA循环，做到公正的执行</h2><p>在PDCA循环中，正确的时间分配是，30%的时间花在绩效目标上，50%的时间拿来做绩效辅导，绩效评价10%，绩效反馈10%。对于管理者来说，绩效辅导就是把自己的成功经验和下属分享，最常用的方法就是开例会。一轮PDCA循环后，员工被分为了不同的等级，应该关注哪类人呢： 即关注最优秀的人和最差的人。这就是管理常说的“二八原则”，即用最少的成本抓住主要矛盾，这也是管理者要解决的问题。</p><p>绩效结果公开制度对管理者而言又是一个陡然的压力，意味着认为绩效评价不合理的员工有可能向公司投诉，管理者的盖子就捂不住了，评价不公正就会被揭开。这样的改个把绩效目标的设定和绩效评估的过程变得更加严格。这就是为什么刚性的应用可以优化整个绩效管理的过程，同时形成正向的绩效发展导向。</p>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://www.wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第二章 灰度用人之法</title>
    <link href="https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%94%A8%E4%BA%BA%E4%B9%8B%E6%B3%95/"/>
    <id>https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%94%A8%E4%BA%BA%E4%B9%8B%E6%B3%95/</id>
    <published>2021-03-16T07:47:02.000Z</published>
    <updated>2022-02-11T03:30:07.874Z</updated>
    
    <content type="html"><![CDATA[<h2 id="华为用人的六条标准"><a href="#华为用人的六条标准" class="headerlink" title="华为用人的六条标准"></a><a href="#%E5%8D%8E%E4%B8%BA%E7%94%A8%E4%BA%BA%E7%9A%84%E5%85%AD%E6%9D%A1%E6%A0%87%E5%87%86" title="华为用人的六条标准"></a>华为用人的六条标准</h2><p>很多企业没有用人标准，每个面试官都按照自己的思路招人。但其实一个企业就像是企业家的孩子，最重要的是要传承基因。企业只有有了基因密码，才可以复制和掌握。</p><ol><li>全力以赴的奋斗精神</li></ol><p>想要打造一支狼性团队，就一定不能找绵阳；找了一群绵阳，想要把它们培养成狼，这是绝对不可能的。所以要打造一支狼性团队，首先要招狼崽。从人才人口触发，就是要找全力以赴、有奋斗激情的人。</p><ol start="2"><li>客户为先的服务意识</li></ol><p>一个企业要打造以客户为中心的文化，前提是要有以客户为先的服务意识。</p><ol start="3"><li>至诚守信的优秀品格</li></ol><p>在华为，大家在会上承诺要做的事，到规定时间一定都会很自觉地交出成绩单，这就是诚信。</p><p>华为把诚信设为高压线，一旦触碰就会立即被开除。</p><ol start="4"><li>积极进取的开放心态</li></ol><p>对于新事物要永远保持一个积极开放的心态。许多大企业的员工总有一副高高在上的姿态，这是很不可取的。一定要始终保持开放的心态，主动而为，积极开放，这样爱能接纳更多好的动心，并为己所用。</p><ol start="5"><li>携手共进的合作精神</li></ol><p>这也是华为用人标准中很重要的点。在华为内部有一句话：胜则举杯相庆，败则拼死相救。</p><ol start="6"><li>扎实的专业知识与技能</li></ol><p>华为的六条用人标准中，真正针对专业技术的要求只占一条，而且放到最后。为什么？因为人的能力是可变的，知识技能也是可变的，但是人的素质是早已形成的，不是说变就能变的。</p><h2 id="华为识人的五项素质"><a href="#华为识人的五项素质" class="headerlink" title="华为识人的五项素质"></a><a href="#%E5%8D%8E%E4%B8%BA%E8%AF%86%E4%BA%BA%E7%9A%84%E4%BA%94%E9%A1%B9%E7%B4%A0%E8%B4%A8" title="华为识人的五项素质"></a>华为识人的五项素质</h2><h3 id="1-第一个素质：主动性"><a href="#1-第一个素质：主动性" class="headerlink" title="1. 第一个素质：主动性"></a><a href="#1-%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E4%B8%BB%E5%8A%A8%E6%80%A7" title="1. 第一个素质：主动性"></a>1. 第一个素质：主动性</h3><p>主动性是指人在工作当众补习投入更多的精力，善于发现和创造性的机会，提前预测事情发生的可能性，采取行动，从而提高工作绩效，避免问题的发生和创造新的机遇。</p><p>这种主动性不只是简单地积极行动，而是强调要有结果，要有预见性，而且这种预见性要产生好的结果。</p><p>主动性可以分为四个等级：</p><ul><li>主动性零级的人不会自觉完成工作，需要他人的督促，不能提前计划和思考问题，直接问题发生才意识到事情的严重性。</li></ul><p>主动性一级的人能主动行动，自觉投入更多的努力去工作。这类人不需要别人督促，只要分配的工作在他的工作范围内，他就会自觉的投入时间去做。</p><ul><li><p>主动性二级的人能主动思考、快速行动，及时发现某种机会和问题，并快速做出反应。二级建立在一级的基础之上，主动性二级的人不光能快速自觉地工作，还会主动思考，预判某一种情况，然后采取相应的行动。二级建立在一级的基础之上，主动性二级的人不光能快速的自觉地工作，还会主动思考，预判某一种情况，然后采取相应的行动。如果你手下有这样总是“蠢蠢欲动”的人，那真是捡到宝贝了。</p></li><li><p>主动性三级是最高等级。这类人不会等着问题发生，而是会未雨绸缪，提前行动，规避问题，甚至创造出机会来。谈管理的时候，常常会说抗洪的一个例子。很多人说洪水来的时候有抗洪先锋就行了，但也有人说我们平时把工作做好，疏浚通淤，建造堤坝，就不会有洪水发生。这个例子很好的说明了主动性二级和三级的区别。</p></li></ul><h3 id="2-第二个素质：概念思维"><a href="#2-第二个素质：概念思维" class="headerlink" title="2. 第二个素质：概念思维"></a><a href="#2-%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E6%A6%82%E5%BF%B5%E6%80%9D%E7%BB%B4" title="2. 第二个素质：概念思维"></a>2. 第二个素质：概念思维</h3><p>我们常说要找聪明人，那么聪明和不聪明的人区别到底在哪里呢？其实最主要的是概念思维，换言之就是思考方式。概念思维是一种识别表面上没有</p><p>明显联系的事情之间内部联系本质特征的能力，也就是说在面对不确定现象的时候，能找到里面的要害，高屋建瓴，一语道破。这是一种大的思维结构，要根据有限的信息作出全面的判断。能做这种结构话思维的人就是聪明人。</p><p>概念思维也分为四个等级。</p><ul><li><p>概念思维零级的人不能准确而周密地去思考问题，碰到问题想不清楚，弄不明白。</p></li><li><p>概念思维一级的人可以进行简单的类比。所谓简单的类比，就是根据自己过去的经验，对某个行为进行类似的复制。比如说我会打篮球，那么在此基础上，我也能通过简单类比，很快学会其他相似的球类运动。</p></li><li><p>概念思维二级的人能触类旁通。触类旁通通就是指运用复杂概念的能力，通过掌握事物发展的客观规律，以点带面的思考问题。比如我是厨师，菜炒的很好，同时我也可以去做管理，用炒菜的方式来管人。有一些做营销的人跨界做人力资源管理也做得很好，去做财务也能胜任，那是因为每个职位背后的深层规律是相同的。更厉害的人可以跨行业，在不同的行业间游刃有余低地切换。</p></li></ul><p>这不是因为他们是天才，而是因为他们掌握了事物发展的根本规律，做到了触类旁通。</p><ul><li>概念思维三级的人懂得深入浅出，他们不仅能将复杂事务一眼看破，还能高度总结成简单易懂的概念，让别人也能理解。</li></ul><p>老子在《道德经》中讲过一句话，叫做“治大国如烹小鲜”，意思是治理一个大国这么复杂的事情其实就跟做一锅菜是一样的。</p><p>再举一个例子，1997年，李一男在华为领导无线产品的开发。当时华为要从固网转到无线产品开发，没有任何积累。李一男就从国外的了类似产品的一张产品说明书开始，构建起了庞大的华为无线产品开发体系。李一男之所以能创造这样的奇迹，是因为他能够深入浅出地抓住事物的深层规律。</p><h3 id="3-第三个素质：影响力"><a href="#3-第三个素质：影响力" class="headerlink" title="3. 第三个素质：影响力"></a><a href="#3-%E7%AC%AC%E4%B8%89%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E5%BD%B1%E5%93%8D%E5%8A%9B" title="3. 第三个素质：影响力"></a>3. 第三个素质：影响力</h3><p>影响力是指施加影响的能力，是试图去说服、劝服、影响他人，留下印象，让他人支持自己观点的能力。影响力其实是一个场，这个场是一个人魅力所构成的天然资源，是一种人与人相互影响的一个方式。影响力的难点在于，主观上我们想要别人接受我们的观点，但是客观上我们又没有权利将自己的意愿强加给别人。</p><p>影响力同样也分为四个等级。</p><ul><li><p>影响力零级的人不能清楚地表达，说服不了比人。这类人不仅不能有效的影响他人，还容易被他人所影响，盲从者、从众者就是典型的代表。</p></li><li><p>影响力一级的人采用直接说服的方法来施加影响，通过向别人讲述理由、证据、事实等来直接说服对方接受自己的观点。在影响别人的过程中，他只能去争理。他会做很多准备，来告诉别人该怎么做。</p></li><li><p>影响力二级的人能换位思考。换位思考就是用别人的话去解决别人的问题，这又高出一个境界。我们经常说某人情商很高，见人说人话，见鬼说鬼话，比如他给你聊家常的时候，其实是在给你讲道理，想要影响你。</p></li><li><p>影响力三级的人用的是综合策略。他会用复杂的策略影响别人，或者通过微妙的手段来使别人接受自己的观点。围魏救赵就是一个典型的例子，我其实想要A，但是我不说A，我讲的是B的故事.</p></li></ul><h3 id="4-第四个素质：成就导向"><a href="#4-第四个素质：成就导向" class="headerlink" title="4. 第四个素质：成就导向"></a><a href="#4-%E7%AC%AC%E5%9B%9B%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E6%88%90%E5%B0%B1%E5%AF%BC%E5%90%91" title="4. 第四个素质：成就导向"></a>4. 第四个素质：成就导向</h3><p>成就导向指的是拥有完成某项任务，或在工作中追求卓越的愿望。也就是说，一个人对自己的定位是小富即安，还是愿意从事具有挑战性的工作。成就导向高的人在公祖欧中会强烈的表现自己的能力，并且不断地为自己树立标准。这就是我们经常讲的自驱力。</p><p>成就导向零级的人安于现状，不追求个人技术或专业上的进步。</p><p>成就导向一级的人追求更好，努力将工作做得更好，或努力要达到某个优秀的标准。</p><p>成就导向二级的人会自己给自己设立富有挑战性的目标，他压根不需要上级给他设定目标，而是会自己给自己设立富有挑战性的目标，并且为了达到目标而努力。</p><p>成就导向三级是最高级，这类人会在仔细权衡代价和收益后，冒着经过评估的风险做出某种决策，他们为了获得更大的成功敢于冒险，这也是我们经常讲的企业家特质之一。</p><h3 id="5-第五个素质：坚韧性"><a href="#5-第五个素质：坚韧性" class="headerlink" title="5. 第五个素质：坚韧性"></a><a href="#5-%E7%AC%AC%E4%BA%94%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E5%9D%9A%E9%9F%A7%E6%80%A7" title="5. 第五个素质：坚韧性"></a>5. 第五个素质：坚韧性</h3><p>坚韧性是指在艰苦或不利的条件下能克服自身困难，努力实现目标：面的他人的敌意能保持冷静和稳定的状态，忍受这种压力。聪明人往往坚韧性不够，韧性够的人往往冲劲又不足，但最终成功的人不一定要机位聪明，却一定要能坚持。</p><ul><li><p>坚韧性零级的人经受不了批评、挫折和压力，稍微遇到点压力就选择放弃。坚韧性零级的人很难做成什么事情。</p></li><li><p>坚韧性一级的人叫“压不垮”。这类人在工作中能够保持良好的体能和稳定的情绪，能顶住压力工作。坚韧性一级的人能像老黄牛一样的勤勤恳恳的工作，任劳任怨，但是不能对结果负责，也不一定能把事情做好。</p></li><li><p>坚韧性二级的人叫“干得成”。这类人不仅能在艰苦的环境中顶住压力，重要的是一定能把事情做成。</p></li><li><p>坚韧性三级的人能通过建设性的方式消除他人的敌意或保证自己情绪的稳定，不受制与压力， 还能把压力解除。</p></li></ul><h2 id="用五项素质进行人才的评估"><a href="#用五项素质进行人才的评估" class="headerlink" title="用五项素质进行人才的评估"></a><a href="#%E7%94%A8%E4%BA%94%E9%A1%B9%E7%B4%A0%E8%B4%A8%E8%BF%9B%E8%A1%8C%E4%BA%BA%E6%89%8D%E7%9A%84%E8%AF%84%E4%BC%B0" title="用五项素质进行人才的评估"></a>用五项素质进行人才的评估</h2><p>五项素质的内在逻辑。</p><p>主动性代表一个人的态度、一种追求。</p><p>概念思维是一个人的本体。一个人的本体是良好的、强大的，才能驱动成功。</p><p>影响力是一个人和外部进行能量和信息交互的长，影响力越大，场就越大，对周边的影响也就越大。</p><p>成就导向是一个人的目标追求，目标追求越大，动力就越足。</p><p>坚韧性是一个人的底，这个底构建了人生的基础。如果这个底越厚，也就是如果一个人有很强的韧性，他就可以在人生的历程中客服一个又一个的困难。</p><p>这五项素质反复锤炼，就构成了领军人才需要具备的素养：积极，聪明，有强大的场能影响他人，有远大的追求，面对挑战坚持不懈。</p><h4 id="五项素质的评估结果，对应了三类人才的分类标准："><a href="#五项素质的评估结果，对应了三类人才的分类标准：" class="headerlink" title="五项素质的评估结果，对应了三类人才的分类标准："></a><a href="#%E4%BA%94%E9%A1%B9%E7%B4%A0%E8%B4%A8%E7%9A%84%E8%AF%84%E4%BC%B0%E7%BB%93%E6%9E%9C%EF%BC%8C%E5%AF%B9%E5%BA%94%E4%BA%86%E4%B8%89%E7%B1%BB%E4%BA%BA%E6%89%8D%E7%9A%84%E5%88%86%E7%B1%BB%E6%A0%87%E5%87%86%EF%BC%9A" title="五项素质的评估结果，对应了三类人才的分类标准："></a>五项素质的评估结果，对应了三类人才的分类标准：</h4><ol><li><p>开创性人才：主动性，概念思维，影响力，成就导向，坚韧性均达到二级以上。</p></li><li><p>守成型人才：主动性、概念思维、影响力，成就导向达到一级及以上，坚韧性为二级及以上</p></li><li><p>执行性人才：主动性，概念思维，影响力，成就导向，坚韧性均达到一级。</p></li></ol>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://www.wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第一章 灰度文化</title>
    <link href="https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%81%B0%E5%BA%A6%E6%96%87%E5%8C%96/"/>
    <id>https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%81%B0%E5%BA%A6%E6%96%87%E5%8C%96/</id>
    <published>2021-03-16T07:40:08.000Z</published>
    <updated>2022-02-11T03:30:53.090Z</updated>
    
    <content type="html"><![CDATA[<p>人性是复杂的，绝对不是简单的黑与白，因此，在构建人才战队的过程中，灰度管理是其哲学精要！以灰度来看，人才是一种资源，管理者与管理的使命就在于激发人的正能量，抑制人的负能量，团结一些可以团结的人，调动一切可以调动的积极性，挖掘一切可以挖掘的潜力，实现公司的目标和战略。</p><p>华为团队管理核心理念的第一条是倡导和建设以客户为中心，以奋斗者为本的高绩效企业文化。这条理念可以分为三条：以客户为中心，以奋斗者为本，高绩效的企业文化。</p><p>以客户为中心是一切行为的导向，以奋斗者为本其实是一种精神。高绩效是一种公平竞争的机制，绩效好，升职加薪，配股提拔，这是一种简介明了的管理风格，不需要太多理论，一切以实事求是的结果为导向。这跟公平的环境、英雄不问出处的氛围有极大的关系。高绩效企业文化其实就是这种英雄不问出处、每个人在公平环境中竞争的体现。</p><p>华为团队管理核心理念的第二条是导向冲锋，持续促进干部员工队伍艰苦分度，传承公司核心价值观。</p><p>华为团队管理核心理念的第三条是以奋斗者为本。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><a href="#%E6%80%BB%E7%BB%93" title="总结"></a>总结</h2><h4 id="核心理念："><a href="#核心理念：" class="headerlink" title="核心理念："></a><a href="#%E6%A0%B8%E5%BF%83%E7%90%86%E5%BF%B5%EF%BC%9A" title="核心理念："></a>核心理念：</h4><ol><li><p>高绩效企业文化</p></li><li><p>导向冲锋</p></li><li><p>以奋斗者为本</p></li></ol><h4 id="高绩效企业的三个关键词"><a href="#高绩效企业的三个关键词" class="headerlink" title="高绩效企业的三个关键词:"></a><a href="#%E9%AB%98%E7%BB%A9%E6%95%88%E4%BC%81%E4%B8%9A%E7%9A%84%E4%B8%89%E4%B8%AA%E5%85%B3%E9%94%AE%E8%AF%8D" title="高绩效企业的三个关键词:"></a>高绩效企业的三个关键词:</h4><ol><li><p>以客户为中心</p></li><li><p>以奋斗者为本</p></li><li><p>高绩效企业文化</p></li></ol>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://www.wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-前言</title>
    <link href="https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E5%89%8D%E8%A8%80/"/>
    <id>https://www.wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E5%89%8D%E8%A8%80/</id>
    <published>2021-03-16T06:32:03.000Z</published>
    <updated>2022-02-11T03:31:19.607Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言：华为30年：-从0到7000亿元营收的嬗变"><a href="#前言：华为30年：-从0到7000亿元营收的嬗变" class="headerlink" title="前言：华为30年： 从0到7000亿元营收的嬗变"></a><a href="#%E5%89%8D%E8%A8%80%EF%BC%9A%E5%8D%8E%E4%B8%BA30%E5%B9%B4%EF%BC%9A-%E4%BB%8E0%E5%88%B07000%E4%BA%BF%E5%85%83%E8%90%A5%E6%94%B6%E7%9A%84%E5%AC%97%E5%8F%98" title="前言：华为30年： 从0到7000亿元营收的嬗变"></a>前言：华为30年： 从0到7000亿元营收的嬗变</h1><h2 id="第一阶段：-从0到1亿元，即产品红利阶段"><a href="#第一阶段：-从0到1亿元，即产品红利阶段" class="headerlink" title="第一阶段： 从0到1亿元，即产品红利阶段"></a><a href="#%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%EF%BC%9A-%E4%BB%8E0%E5%88%B01%E4%BA%BF%E5%85%83%EF%BC%8C%E5%8D%B3%E4%BA%A7%E5%93%81%E7%BA%A2%E5%88%A9%E9%98%B6%E6%AE%B5" title="第一阶段： 从0到1亿元，即产品红利阶段"></a>第一阶段： 从0到1亿元，即产品红利阶段</h2><p>华为能实现从0到1的突破，最重要的是没有局限于做一个贸易上，而是找到了自己生长的根本，也就是打造产品。<br>（指的是之前是从香港代理产品到大陆卖，仅仅是一个代理贸易商）<br>从1亿到1亿元这个阶段的成功原因，我总结出两个关键点：</p><ul><li><p>第一，复制领导者。经历从0到1的成功之后，领导者个人能力也就发挥到了极致，如果想进一步突破，就必须找到在某些方面超越自己的人，这就是复制领导者。华为这个极端，研发上有郑宝用，李一男，市场上有孙亚芳，可谓人才济济！</p></li><li><p>第二，正确的市场策略。</p></li></ul><h2 id="第二阶段：从10亿到100亿，即管理红利阶段"><a href="#第二阶段：从10亿到100亿，即管理红利阶段" class="headerlink" title="第二阶段：从10亿到100亿，即管理红利阶段"></a><a href="#%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%EF%BC%9A%E4%BB%8E10%E4%BA%BF%E5%88%B0100%E4%BA%BF%EF%BC%8C%E5%8D%B3%E7%AE%A1%E7%90%86%E7%BA%A2%E5%88%A9%E9%98%B6%E6%AE%B5" title="第二阶段：从10亿到100亿，即管理红利阶段"></a>第二阶段：从10亿到100亿，即管理红利阶段</h2><p>上一阶段复制领导者的结果，就是企业会进入“山头主义”，即市场、研发、供应链都各自有强人带领，彼此谁也不服谁，有些重大问题非要领导者亲自出面协调才可以推动，而领导者又往往投鼠忌器，于是在管理上，“和稀泥”就成了一种常态。</p><p>面对华为的市场与研发之争，任正非寻求解决问题的方法是到美国取经，看看西方文明是如何解决这种争论的。在IBM他找到了答案，即用流程的方式而不是人治的方式，可以很好的将两者统筹起来。不听研发，也不听市场，而是听客户，这就形成了华为核心价值观的基础—-以客户为中心! （这一点我比较存疑，客户是一个泛指概念，客户也分好几类，好几拨，往往不同类型的客户也代表不同类型的市场导向。以客户为中心的一个典型反例就是苹果，苹果遵循自己的产品理念，并不是以遵循客户的需求为主，引领客户和消费者往自己的理念上去走，从销量和利润上来看，它是成功的。而安卓是恰恰相反，客户要什么我就给你什么，导致产品最后变成一个大杂烩，没有”灵魂”。我理解是苹果的强大，可以让他去做到引领产品和消费理念，而不是追随,苹果这里的根本是引领和输出一种审美和消费价值观。 关于以客户为中心，还是以其他为中心的理念之争，我觉得还可以有更多的争论，但关键是自己要根据实际情况去运用，活学活用，不能拿拘泥于某一边，这就要求高级管理者有洞察和决策能力，在什么时候做出什么样的决定，而不是死板的去套搬。）</p><p>直到今天，我们看到很多企业的变革半途而费，其实就和领导者在变革上态度上的坚定有很大关系。</p><h2 id="第三阶段：从100亿到1000亿元，及人才红利阶段"><a href="#第三阶段：从100亿到1000亿元，及人才红利阶段" class="headerlink" title="第三阶段：从100亿到1000亿元，及人才红利阶段"></a><a href="#%E7%AC%AC%E4%B8%89%E9%98%B6%E6%AE%B5%EF%BC%9A%E4%BB%8E100%E4%BA%BF%E5%88%B01000%E4%BA%BF%E5%85%83%EF%BC%8C%E5%8F%8A%E4%BA%BA%E6%89%8D%E7%BA%A2%E5%88%A9%E9%98%B6%E6%AE%B5" title="第三阶段：从100亿到1000亿元，及人才红利阶段"></a>第三阶段：从100亿到1000亿元，及人才红利阶段</h2><p>突破千亿，华为花了9年时间。要实现这个目标，最重要的一点是对客户的选择。</p><p>还有一点是人才红利。</p><p>华为在早期就特别注重人才的选拔，人才红利不断累积。</p><h2 id="第四阶段：突破1000亿元以后，即战略红利阶段"><a href="#第四阶段：突破1000亿元以后，即战略红利阶段" class="headerlink" title="第四阶段：突破1000亿元以后，即战略红利阶段"></a><a href="#%E7%AC%AC%E5%9B%9B%E9%98%B6%E6%AE%B5%EF%BC%9A%E7%AA%81%E7%A0%B41000%E4%BA%BF%E5%85%83%E4%BB%A5%E5%90%8E%EF%BC%8C%E5%8D%B3%E6%88%98%E7%95%A5%E7%BA%A2%E5%88%A9%E9%98%B6%E6%AE%B5" title="第四阶段：突破1000亿元以后，即战略红利阶段"></a>第四阶段：突破1000亿元以后，即战略红利阶段</h2><p>华为的人才管理具体是怎么样支撑以上四个阶段的成功的呢？总结起来有以下五点：</p><ol><li><p>第一，选对优秀的人。</p></li><li><p>第二，给优秀的人指定正确的标准，也就是要设立科学的绩效目标，引导人才以正确的方式做正确的事。</p></li><li><p>第三，摆好队形，构建好组织。</p></li><li><p>第四，选好干部。</p></li><li><p>第五，分好钱。</p></li></ol>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://www.wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://www.wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>消息队列领域前沿调研</title>
    <link href="https://www.wangjunfei.com/2021/03/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%A2%86%E5%9F%9F%E5%89%8D%E6%B2%BF%E8%B0%83%E7%A0%94/"/>
    <id>https://www.wangjunfei.com/2021/03/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%A2%86%E5%9F%9F%E5%89%8D%E6%B2%BF%E8%B0%83%E7%A0%94/</id>
    <published>2021-03-15T08:46:55.000Z</published>
    <updated>2022-02-11T04:39:48.503Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="云原生"><a href="#云原生" class="headerlink" title="云原生"></a><a href="#%E4%BA%91%E5%8E%9F%E7%94%9F" title="云原生"></a>云原生</h1><h2 id="云原生定义"><a href="#云原生定义" class="headerlink" title="云原生定义"></a><a href="#%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%9A%E4%B9%89" title="云原生定义"></a>云原生定义</h2><p>云原生组织(The Cloud Native Computing Foundation)在官方文档里对云原生做了定义: (参看官方文档):</p><blockquote><p>Cloud-native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.RxJava</p></blockquote><blockquote><p>翻译: 云原生技术赋予了企业在现代化、动态化的环境比如公有云、私有云以及混合云上开发和运营应用的能力。容器，service mesh，微服务，不可变基础设施以及声名式api都是典型的云原生技术。</p></blockquote><blockquote><p>These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.</p></blockquote><blockquote><p>翻译: 这类技术能让各系统松散的结合在一起，而且有弹性，可控制、可观测的。配合强壮的自动化工具，可以让工程师轻而易举的经常对系统做重大的变更。</p></blockquote><p>随着用户对应用(app，以下称应用)的需求不断增加，应用会变得越来越复杂，但用户的要求却会越来越高，他们希望应用能有更快的响应速度，全新的功能，以及零时间宕机。性能问题，重复出现的错误，演进速度慢越来越会让人难以接受，用户会轻易的转向竞争对手。</p><p>云原生更多的是速度和敏捷。随着市场环境的不断变化，技术需要快速的支撑产品来抢占市场和商机，云原生就是这样的辅助技术。</p><p>云原生的速度和敏捷特性来自于以下几个方面的支持:</p><h2 id="Mafka的云原生建设目标"><a href="#Mafka的云原生建设目标" class="headerlink" title="Mafka的云原生建设目标"></a><a href="#Mafka%E7%9A%84%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BB%BA%E8%AE%BE%E7%9B%AE%E6%A0%87" title="Mafka的云原生建设目标"></a>Mafka的云原生建设目标</h2><p>Mafka作为支撑服务(PaaS)之一，同样也需要满足云原生中速度和敏捷的要求，主要体现在以下几个方面:</p><h3 id="集群SLA要求"><a href="#集群SLA要求" class="headerlink" title="集群SLA要求:"></a><a href="#%E9%9B%86%E7%BE%A4SLA%E8%A6%81%E6%B1%82" title="集群SLA要求:"></a>集群SLA要求:</h3><ol><li><p>更快的扩容</p><ul><li>依托容器技术、自身架构的改造，当集群需要扩容，缩容时，集群能快速、简单的实现扩容</li></ul></li><li><p>更快的容灾切换速度</p><ul><li>当机房出现断电等灾难时，客户端能实现快速的容灾切换速度。</li></ul></li><li><p>更长的消息保存时间，更大的消息传输</p><ul><li><p>当用户需要更长、更久的消息保存时间时，依托自身的架构改造，能实现冷热消息的分离存储。</p></li><li><p>集群能实现更大消息(超过1M的消息体)生产和消费</p></li></ul></li><li><p>更小的集群宕机影响</p><ul><li>当集群出现宕机时，最小程度的减少对业务的影响，力求对用户无感知。</li></ul></li><li><p>更快的宕机恢复</p><ul><li>当集群出现宕机时，集群能自动拉起新的机器(实例)来补充，快速恢复数据，满足用户的数据副本要求。</li></ul></li></ol><h3 id="集群运营要求"><a href="#集群运营要求" class="headerlink" title="集群运营要求:"></a><a href="#%E9%9B%86%E7%BE%A4%E8%BF%90%E8%90%A5%E8%A6%81%E6%B1%82" title="集群运营要求:"></a>集群运营要求:</h3><ol><li><p>集群自动化，智能化运营</p><ul><li>集群自动化运营和管理，节点替换、宕机下线，流量均衡，负载均衡，版本升级等能做到“一键自动化”，智能化。</li></ul></li><li><p>智能化用户辅助和预警</p><ul><li><p>用户队列发生积压时，能收集数据帮助用户快速定位问题，解决问题。</p></li><li><p>用户流量不均衡时，能提示用户更高效的生产和消费方式。</p></li><li><p>通过分析用户的消费速度和机器环境，提前预警队列消费积压等问题。</p></li></ul></li></ol><h1 id="流式计算"><a href="#流式计算" class="headerlink" title="流式计算"></a><a href="#%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97" title="流式计算"></a>流式计算</h1><h2 id="实时计算"><a href="#实时计算" class="headerlink" title="实时计算"></a><a href="#%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97" title="实时计算"></a>实时计算</h2><p>数据的业务价值随着时间的流失而迅速降低，因此在数据发生后必须尽快对其进行计算和处理。而传统的大数据处理模式无法满足数据实时计算的需求。</p><p>在诸如实时大数据分析、风控预警、实时预测、金融交易等诸多业务场景领域，批量处理对于上述对于数据处理时延要求苛刻的应用领域而言是完全无法胜任其业务需求的。</p><h2 id="现有流式计算技术"><a href="#现有流式计算技术" class="headerlink" title="现有流式计算技术"></a><a href="#%E7%8E%B0%E6%9C%89%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF" title="现有流式计算技术"></a>现有流式计算技术</h2><p>storm、trident是比较早的流式计算技术，spark更新一些，现在最流行是Flink/Samza以及kafka stream一类非微批，每个事件逐一实时处理的新技术。</p><p>各个技术之间的比较如下图:</p><table><thead><tr><th align="center">项目</th><th align="center">Storm</th><th align="center">Trident</th><th align="center">Spark Streaming</th><th align="center">Flink</th><th align="center">Samza</th><th align="center">Kafka streams</th></tr></thead><tbody><tr><td align="center">数据流模型</td><td align="center">原生</td><td align="center">微批</td><td align="center">微批</td><td align="center">原生</td><td align="center">原生</td><td align="center">原生</td></tr><tr><td align="center">状态存储</td><td align="center">不支持状态管理</td><td align="center">本地存储，外部数据库</td><td align="center">多种状态存储方式</td><td align="center">多种状态存储方式</td><td align="center">本地存储，Kafka主题</td><td align="center">本地存储，日志变更主题</td></tr><tr><td align="center">时延</td><td align="center">低</td><td align="center">高</td><td align="center">高</td><td align="center">低</td><td align="center">低</td><td align="center">低</td></tr><tr><td align="center">保障机制</td><td align="center">at-least-once</td><td align="center">exactly-once</td><td align="center">exactly-once</td><td align="center">exactly-once</td><td align="center">at-least-once</td><td align="center">exactly-once</td></tr><tr><td align="center">容错机制</td><td align="center">record ack</td><td align="center">record ack</td><td align="center">RDD based，checkpoint</td><td align="center">checkpoint</td><td align="center">Kafka log-base</td><td align="center">Kafka log</td></tr><tr><td align="center">成熟度</td><td align="center">作为较早开发的流处理框架，虽然有很多不足，但实际应用仍然比较广泛</td><td align="center">当前比较流行的框架之一，Spark大环境</td><td align="center">较新的流处理框架，性能非常优秀，阿里应用并做相应修改Blink</td><td align="center">基于Kafka作为数据源</td><td align="center">完全基于Kafka集群实现</td><td align="center"></td></tr><tr><td align="center">定位</td><td align="center">框架</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">库</td></tr></tbody></table><p>由上图可见，Flink/Samza/Kafka Stream典型的特征是，高吞吐，低延时，实时流式处理。但三者又有不同点，Flink可以基于多种数据存储做计算，Samza/Kafka Stream都是以kafka为数据源做计算。</p><p>但Kafka Stream在这里独有三个优势:</p><ol><li><p>Kafka Stream非常的轻量级，可以应用到微服务、IOT等实时流式计算场景:</p><ul><li>Samza/Flink都是计算框架，需要部署一个集群，将自己的流式作业上传到集群处理，kafaStreams是lib库，业务程序集成后就可以可开始流式计算。</li></ul></li><li><p>KafkaStreams是本地lib库，开发迭代成本低</p><ul><li>意味着RD可以在本地开发和测试自己的Kafka Stream流式任务，Samza/Flink等需要将服务部署到集群上，开发者很难了解框架的具体运行方式，从而使得调试成本高，并且使用受限.</li></ul></li><li><p>接入方便，使用成本低</p><ul><li>Mafka在公司内广泛使用，业务已经将消息和数据发往了Mafka，如果Mafka推出stream流式计算，业务只要升级Mafka client版本，既可拥有流式计算能力，相对业务来说，使用流式计算技术的成本非常低。</li></ul></li></ol>]]></content>
    
    
    <summary type="html">云原生，流式计算，本文对消息队列领域目前的前沿技术进行了简单的调研和分析。</summary>
    
    
    
    <category term="消息队列" scheme="https://www.wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://www.wangjunfei.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="kafka" scheme="https://www.wangjunfei.com/tags/kafka/"/>
    
    <category term="云原生" scheme="https://www.wangjunfei.com/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="流式计算" scheme="https://www.wangjunfei.com/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Mafka对比RocketMQ(一)简介</title>
    <link href="https://www.wangjunfei.com/2020/04/28/Mafka%E5%AF%B9%E6%AF%94RocketMQ-%E4%B8%80-%E7%AE%80%E4%BB%8B/"/>
    <id>https://www.wangjunfei.com/2020/04/28/Mafka%E5%AF%B9%E6%AF%94RocketMQ-%E4%B8%80-%E7%AE%80%E4%BB%8B/</id>
    <published>2020-04-28T10:10:16.000Z</published>
    <updated>2022-02-11T04:03:24.066Z</updated>
    
    <content type="html"><![CDATA[<p><span class="github-emoji" style="display:inline;vertical-align:middle"><span>⚠</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 原创文章，转载请注明出处</p><h2 id="Mafka简介"><a href="#Mafka简介" class="headerlink" title="Mafka简介"></a><a href="#Mafka%E7%AE%80%E4%BB%8B" title="Mafka简介"></a>Mafka简介</h2><h3 id="什么是Mafka"><a href="#什么是Mafka" class="headerlink" title="什么是Mafka?"></a><a href="#%E4%BB%80%E4%B9%88%E6%98%AFMafka" title="什么是Mafka?"></a>什么是Mafka?</h3><p>Mafka是基础架构-MQ团队从2016年开始自研的消息队列产品，底层基于Apache Kafka，增加了自研的基于机房粒度的中心化调度、时间回溯、粘性分配、死信、延迟队列、适用于美团自用的同步/异步客户端、机房容灾等高阶特性，目前版本是3.0。</p><h3 id="为什么建造Mafka"><a href="#为什么建造Mafka" class="headerlink" title="为什么建造Mafka?"></a><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BB%BA%E9%80%A0Mafka" title="为什么建造Mafka?"></a>为什么建造Mafka?</h3><p>消息队列是现代互联网技术架构中不可缺少的一个基础组件，对于美团这样的业务多样性的大型互联网公司来说，这个组件尤其变得更为重要。2016年Mafka诞生之前，美团拥有自研的消息队列产品Nuclear MQ和Swallow，但是随着公司业务的不断扩大，业务线对消息队列功能多样性，以及可用性，可靠性，高并发能力的要求越来越高，原有队列产品的局限性和先天不足劣势迅速暴露出来。正是在这样紧迫形势下，MQ团队经过深入调研和分析，发现原有产品的基础技术架构已无法满足用户需求，决定基于开源社区比较成熟的消息队列产品Apache Kafka研发打造适用于美团的消息队列产品，Mafka就这样诞生了。</p><p>Apache Kafka诞生于同样是互联网公司的LinkedIn，经过企业级互联网产品的实战检验，拥有优秀的技术架构和设计。但Kafka的定位是作为Apache基金会下一个开源的消息队列产品，其功能和设计演进完全是集所有公司和用户需求的基础共性为重点的，涉及到具体某个公司的个性化或特定环境下的需求和演进，并不是他演进的方向。所以直接拿Kafka来部署，作为美团的企业级消息队列产品是没法使用的。所以，MQ团队对Kafka做了深度的定制和自研，来满足美团的业务场景。为了区分开源产品Apache Kafka和经过MQ团队改造后的Kafka，MQ团队将后者命名为Mafka。</p><p>Mafka 基于Kafka 0.9.0.1版本研发，至今已迭代了3个版本(第四个版本正在迭代中)。开源Kafka只有Broker和clientSDK两个模块，实际真正使用到美团这样的多样性大型互联网O2O公司内，其原生设计已经远远满足不了业务的功能需求以及企业级产品标准。Mafka除了对Kafka原有的Broker和java clientSDK两个模块做了深度自研和定制外，还增加了Castle、延时队列、Push消费组、Mafka Scanner、Auth队列鉴权、全模块自动测试系统、c++/php客户端、用户平台、运营平台等9个模块的系统支持。其中，仅仅是Broker模块，新增代码将近4万行，删除代码近9000行，涉及800多次提交。整个Mafka 系统新增代码量数十万行。</p><h3 id="Mafka架构图"><a href="#Mafka架构图" class="headerlink" title="Mafka架构图"></a><a href="#Mafka%E6%9E%B6%E6%9E%84%E5%9B%BE" title="Mafka架构图"></a>Mafka架构图</h3><p><img src="/2020/04/28/Mafka%E5%AF%B9%E6%AF%94RocketMQ-%E4%B8%80-%E7%AE%80%E4%BB%8B/mafka_arch.svg" title="Mafka架构图"></p><h2 id="RocketMQ简介"><a href="#RocketMQ简介" class="headerlink" title="RocketMQ简介"></a><a href="#RocketMQ%E7%AE%80%E4%BB%8B" title="RocketMQ简介"></a>RocketMQ简介</h2><h3 id="rocket演进历史"><a href="#rocket演进历史" class="headerlink" title="rocket演进历史"></a><a href="#rocket%E6%BC%94%E8%BF%9B%E5%8E%86%E5%8F%B2" title="rocket演进历史"></a>rocket演进历史</h3><p><img src="/2020/04/28/Mafka%E5%AF%B9%E6%AF%94RocketMQ-%E4%B8%80-%E7%AE%80%E4%BB%8B/rocketmq_iter.png" title="rocketmq演进历史"></p><blockquote><p>2007年，淘宝实施了“五彩石”项目，将交易系统由单机交易升级到了分布式，这个过程中产生了Notify。<br>2010年，阿里巴巴B2B部门基于ActiveMQ的5.1版本也开发了自己的一款消息引擎，称为Napoli。<br>2011年，Linkin推出Kafka消息引擎，阿里巴巴在研究了Kafka的整体机制和架构设计之后，基于Kafka的设计使用Java进行了完全重写并推出了MetaQ 1.0版本，主要是用于解决顺序消息和海量堆积的问题，由开源社区killme2008维护。<br>2012年，阿里巴巴对于MetaQ进行了架构重组升级，开发出了MetaQ 2.0，这时就发现MetaQ原本基于Kafka的架构在阿里巴巴如此庞大的体系下很难进行水平扩展，所以在2012年的时候就开发了RocketMQ 3.0。<br>2015年，又基于RocketMQ开发了阿里云上的Aliware MQ和Notify 3.0。<br>2016年，阿里巴巴将RocketMQ的内核引擎捐赠给了Apache基金会。</p></blockquote><p>MetaQ和RocketMQ区别：两者等价，在阿里内部称为MetaQ 3.0，对外称为RocketMQ 3.0。</p><p>以上就是RocketMQ的整体发展历史，其实在阿里巴巴内部围绕着RocketMQ内核打造了三款产品，分别是MetaQ、Notify和Aliware MQ。这三者分别采用了不同的模型：</p><blockquote><p>MetaQ主要使用了拉模型，解决了顺序消息和海量堆积问题。<br>Notify主要使用了推模型，解决了事务消息<br>而云产品Aliware MQ则是提供了商业化的版本。</p></blockquote><p>从阿里内部同学获取到的信息，阿里内部使用多套消息队列服务，并不统一，有三套消息队列服务: notify, metaQ(kafka),RocketMQ。没有特殊需求时，一般使用metaQ，需要事务消息时，使用notify，需要定时消息时使用RocketMQ.</p><p>RocketMQ架构图</p><p><img src="/2020/04/28/Mafka%E5%AF%B9%E6%AF%94RocketMQ-%E4%B8%80-%E7%AE%80%E4%BB%8B/rocketmq_arch.svg" title="rocketMQ 架构"></p>]]></content>
    
    
    <summary type="html">Mafka是美团基于kafka自研的消息中间件，RocketMQ是阿里巴巴开源的一个消息队列，本系列文章会对Mafka和RocketMQ的技术架构、功能等做深入的对比和研究。</summary>
    
    
    
    <category term="消息队列" scheme="https://www.wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://www.wangjunfei.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="rocketmq" scheme="https://www.wangjunfei.com/tags/rocketmq/"/>
    
    <category term="kafka" scheme="https://www.wangjunfei.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ消息队列(一)架构</title>
    <link href="https://www.wangjunfei.com/2020/04/28/RocketMQ%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E4%B8%80-%E6%9E%B6%E6%9E%84/"/>
    <id>https://www.wangjunfei.com/2020/04/28/RocketMQ%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E4%B8%80-%E6%9E%B6%E6%9E%84/</id>
    <published>2020-04-28T10:07:34.000Z</published>
    <updated>2022-02-11T04:03:16.971Z</updated>
    
    <content type="html"><![CDATA[<p><span class="github-emoji" style="display:inline;vertical-align:middle"><span>⚠</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 原创文章，转载请注明出处</p><h2 id="架构概览"><a href="#架构概览" class="headerlink" title="架构概览"></a><a href="#%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88" title="架构概览"></a>架构概览</h2><p>RockeMQ 主要包含两个模块 Broker和Name Server，如下图所示:</p><p><img src="/2020/04/28/RocketMQ%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E4%B8%80-%E6%9E%B6%E6%9E%84/rocketmq_arch.svg" title="rocketmq arch"></p><h3 id="NameServer"><a href="#NameServer" class="headerlink" title="NameServer"></a><a href="#NameServer" title="NameServer"></a>NameServer</h3><p>NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。</p><p>主要包括两个功能：</p><ol><li><p>Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；</p></li><li><p>路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。</p></li></ol><p>然后Producer和Consumer通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。</p><p>NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。</p><p>当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。</p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a><a href="#Broker" title="Broker"></a>Broker</h3><p>Broker主要负责消息的存储、投递和查询以及服务高可用保证。broker会每隔30s向集群中的所有nameserver发送一个心跳包，nameserver会每隔10s扫描自己保存的broker列表，看broker最后一次发送的心跳包是否是120s前的，如果是就删除这个broker，关闭链接。</p><h3 id="生产端和生产端集群"><a href="#生产端和生产端集群" class="headerlink" title="生产端和生产端集群"></a><a href="#%E7%94%9F%E4%BA%A7%E7%AB%AF%E5%92%8C%E7%94%9F%E4%BA%A7%E7%AB%AF%E9%9B%86%E7%BE%A4" title="生产端和生产端集群"></a>生产端和生产端集群</h3><p>Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。</p><p>group name相同的一组生产端，称之为生产端集群。集群内每个生产者都会给master发送心跳，所以master是掌握所有生产者信息的，在事务消息回查时，broker端可选择生产端集群中的一个，来执行回查逻辑。</p><h3 id="消费端和消费端集群"><a href="#消费端和消费端集群" class="headerlink" title="消费端和消费端集群"></a><a href="#%E6%B6%88%E8%B4%B9%E7%AB%AF%E5%92%8C%E6%B6%88%E8%B4%B9%E7%AB%AF%E9%9B%86%E7%BE%A4" title="消费端和消费端集群"></a>消费端和消费端集群</h3><p>Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。</p><p>groupname相同的消费端，称之为一个集群。集群内每个消费者都会给broker发送心跳，所以broker端也掌握了所有消费者的信息，每个消费者上线、或下线时都会来查阅这个信息，进行队列重分配。</p><h3 id="Broker集群"><a href="#Broker集群" class="headerlink" title="Broker集群"></a><a href="#Broker%E9%9B%86%E7%BE%A4" title="Broker集群"></a>Broker集群</h3><p>RocketMQ的集群比较特殊，是多个单元组成的一个集群。如上图所示，整个集群包含5台broker，两个单元，第一个单元是3台broker，一主两从，第二个单元是一主一从。集群的划分是以cluster name名称为准备，命名相同的机器都属于一个集群。如上图，所有broker的cluster name属性都叫order-cluster，他们都属于一个集群。</p><p>name相同的一组broker是一个单元，同一单元内，id属性为0的broker是master，id属性为1的为第一slave，其他都是slave.</p><h2 id="Topic和队列概念"><a href="#Topic和队列概念" class="headerlink" title="Topic和队列概念"></a><a href="#Topic%E5%92%8C%E9%98%9F%E5%88%97%E6%A6%82%E5%BF%B5" title="Topic和队列概念"></a>Topic和队列概念</h2><p>Kafka里每个topic各自的partition消息，都会写入自己的文件里。RocketMQ不一样，它把所有的topic数据全部写入一个文件里，称之为commit log。但消费的时候怎么区分每个队列呢？答案是broker接收到消息后，统一都写入一个消息日志(commit log)文件，由转发服务(reput Service)再转发生成消费队列(consume quue)文件，如下图所示:</p><p><img src="/2020/04/28/RocketMQ%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E4%B8%80-%E6%9E%B6%E6%9E%84/rocketmq_queue.svg" title="rocketmq concept"></p><p>上图可以看到有两个文件：</p><p>(1) CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；</p><p>(2) ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，类似于kafka中的partition概念，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；</p><p>还有一个文件是:</p><p>IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。</p><h3 id="队列分布方式"><a href="#队列分布方式" class="headerlink" title="队列分布方式"></a><a href="#%E9%98%9F%E5%88%97%E5%88%86%E5%B8%83%E6%96%B9%E5%BC%8F" title="队列分布方式"></a>队列分布方式</h3><p>了解了RocketMQ中 topic和consume queue概念，以及rocketmq集群搭建方式后，就很容易了解 rocketmq队列的分布方式了，以图1中2 master 3 slave的5 台机器组成的集群为例，比如创建一个topic 和6个队列(consume queue)，可以如下来分布。</p><p><img src="/2020/04/28/RocketMQ%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E4%B8%80-%E6%9E%B6%E6%9E%84/rocketmq_queue_deploy.svg" title="rocketmq deploy"></p><p>brokerA的master节点有3个队列， brokerB的master节点有3个队列，这里的队列类似Kafka中的partition概念。</p>]]></content>
    
    
    <summary type="html">RocketMQ是阿里巴巴开源的一个消息队列，本系列文章会对RocketMQ的技术架构、功能等做深入的研究。</summary>
    
    
    
    <category term="消息队列" scheme="https://www.wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://www.wangjunfei.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="rocketmq" scheme="https://www.wangjunfei.com/tags/rocketmq/"/>
    
    <category term="kafka" scheme="https://www.wangjunfei.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>磁盘读写优化技术研究-Zookeeper/Kafka/MySQL</title>
    <link href="https://www.wangjunfei.com/2020/03/15/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6-Zookeeper-Kafka-MySQL/"/>
    <id>https://www.wangjunfei.com/2020/03/15/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6-Zookeeper-Kafka-MySQL/</id>
    <published>2020-03-15T01:58:57.000Z</published>
    <updated>2022-02-11T04:15:01.270Z</updated>
    
    <content type="html"><![CDATA[<p><span class="github-emoji" style="display:inline;vertical-align:middle"><span>⚠</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 原创文章，转载请注明出处</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><a href="#%E6%91%98%E8%A6%81" title="摘要"></a>摘要</h2><p>本文对linux下磁盘的读写优化技术做了一个搜底和总览，包括基本的文件读写知识，磁盘，page cache ，zeror copy，mmap等知识，还对zookeeper 、kafka 、mysql 在使用磁盘读写文件时的优化技术做了分析。</p><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a><a href="#%E5%85%B3%E9%94%AE%E8%AF%8D" title="关键词"></a>关键词</h2><p>磁盘读写, 文件系统, block, page cache, zero copy, mmap, zookeeper, kafka, mysql</p><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a><a href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86" title="基础知识"></a>基础知识</h2><h3 id="1-文件系统"><a href="#1-文件系统" class="headerlink" title="1.文件系统"></a><a href="#1-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F" title="1.文件系统"></a>1.文件系统</h3><p>Linux使用文件系统来管理磁盘，将此磁盘分为一个个“block“单元，如下图所示，文件内容被写进一段连续的block单元内，中间空出来的即是我们平常所说的“碎片空间(fragment)”。常见的文件系统包含ext/ext2/ext3/ext4，以及windows使用NTFS等。</p><p>在现代ext4文件系统上，碎片空间已经不是问题，因为在分配每个文件存储的位置时，系统会特意让两个文件之间距离较远的位置，这样既方便文件不断变大，也不需要去整理碎片，但是极端场景下，比如整块磁盘空间都快用完的时候，就需要去挪动或迁移碎片，腾出可用空间，正常情况下是不需要的。</p><p><img src="/2020/03/15/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6-Zookeeper-Kafka-MySQL/file_blocks.svg" title="file blocks"></p><p>block内除了存储文件的真实内容之外，还需要存储每个文件的属性信息，<br>比如gid/uid/permission/atime/modtime，以及文件存储在哪些block上的信息等元数据， 这类数据称之为metadata，在linux操作系统中叫index node，简称inode。ext3之前的文件系统，indoe需要使用一个集合来存储某个文件写在了哪些block上，随着文件的增大，这个集合会越来越大，造成系统的一个瓶颈。ext3之后的inode设计上，不再记录block集合信息，而是采用记录开始位置，和文件大小的两个属性，如下所示 ：</p><figure class="highlight arcade"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct ext3_extent {  </span><br><span class="line"> __le32  ee_block; <span class="regexp">/\* first logical block extent covers 文件的开始block信息 \*/</span>   </span><br><span class="line"> __le16  ee_len;   <span class="regexp">/\* number of blocks covered by extent 文件的大小\*/</span>  </span><br><span class="line"> __le16  ee_start_hi;  <span class="regexp">/\* high 16 bits of physical block \*/</span>  </span><br><span class="line"> __le32 ee_start; <span class="regexp">/\* low 32 bits of physical block \*/</span>  </span><br><span class="line">};  </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><h3 id="2-数据落盘"><a href="#2-数据落盘" class="headerlink" title="2. 数据落盘?"></a><a href="#2-%E6%95%B0%E6%8D%AE%E8%90%BD%E7%9B%98" title="2. 数据落盘?"></a>2. 数据落盘?</h3><p>由上边可以看出，读、写文件时，除了写文件内容本身之外，还要至少一次磁盘寻址，来写metadata一类的信息，总结这些额外的信息包括下边几个:</p><ol><li>文件所占的block数量</li><li>文件最后一次访问时间atime</li><li>文件最后一次的修改时间</li></ol><p>针对这些额外的inode信息写操作，linux写文件时也有相应的两个函数来处理:</p><ol><li>fsync() : 将文件内容+文件metadata数据同步刷到磁盘上</li><li>fdatasync(): 只将文件内容同步刷到磁盘上</li></ol><p>java中的FileChannel api也提供了这个选项</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> @param metdata 是否同时将metadata信息同步flush到磁盘上  </span></span><br><span class="line"><span class="comment">*/</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">force</span><span class="params">(<span class="type">boolean</span> metaData)</span> <span class="keyword">throws</span> IOException  </span><br></pre></td></tr></tbody></table></figure><p>因此，在高频次写文件操作时，可以使用fdatasync减少一次磁盘操作，来提升写速度。</p><p>另外两个比较混淆的文件操作:</p><ol><li>FileDescriptor.sync() 底层同样调用的是fsync，将文件内容+文件metadata信息全部刷到了磁盘上</li><li>OutputStream.flush只是将缓冲区内的数据发给操作系统，但有可能并未落盘，可能在pagecache内。</li></ol><p>注意:<br>OutputStream和FileoutputStream是一空函数,但 FilterOutputStream.flush<br>,BufferedOutputStream.flush,ObjectOutputStream.flush确实是有内容的。</p><p>如果要把文件内容真正落盘，需要先调用stream的flush，将数据发送给操作系统，然后在调用FileDiscriptor的sync方法或 FileChannel.force方法，将数据真正落盘.</p><h3 id="2-Zero-Copy技术"><a href="#2-Zero-Copy技术" class="headerlink" title="2.Zero Copy技术"></a><a href="#2-Zero-Copy%E6%8A%80%E6%9C%AF" title="2.Zero Copy技术"></a>2.Zero Copy技术</h3><p>在Java程序内通过InputStream和OutputStream读取或写入文件数据时，操作系统底层的实现一般是这样的：  </p><p><img src="/2020/03/15/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6-Zookeeper-Kafka-MySQL/read_write_file.svg" title="read and write a file"></p><ol><li>在用户空间内，程序发出读取数据指令。</li><li>操作系统切换至内核空间，内核通过DMA读取磁盘数据。</li><li>内核将自己读到的数据，从自己的buffer copy到用户的buffer内</li><li>操作系统切换至用户空间</li><li>继续用户处理逻辑</li><li>完成处理后，将数据写入磁盘时，需要将buffer copy到内核的buffer内。</li><li>操作系统切换至内核空间</li><li>内核将数据通过disk controller写入磁盘</li><li>操作系统切换至用户空间继续</li></ol><p>可以看到，一个简单文件处理后保存操作，涉及到4次上下文切换和两次copy.</p><p>但linux系统都提供一种zero copy的技术支持，在用户空间内这个函数通常叫sendFile，可以使用linux man 命令(man sendfile)查看到，他的工作原理如下:</p><p><img src="/2020/03/15/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6-Zookeeper-Kafka-MySQL/zero_copy.svg" title="zero copy"></p><p>上图可见，用在程序里调用sendfile后，操作系统将数据从磁盘读入buffer后，直接发送给了网络，没有再把buffer拷贝到用户空间，但是仍然会有两次上下文切换。</p><p>nginx和apache httpd 服务器都支持sendfile指令。</p><p>具体到java中的“sendfile” 是FileChannel的transferto方法</p><figure class="highlight aspectj"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> transferTo(<span class="keyword">long</span> position,  </span><br><span class="line"> <span class="keyword">long</span> count,  </span><br><span class="line"> WritableByteChannel <span class="keyword">target</span>)  </span><br><span class="line"> <span class="keyword">throws</span> IOException  </span><br><span class="line"><span class="comment">// Transfers bytes from this channel's file to the given writable byte channel.  </span></span><br></pre></td></tr></tbody></table></figure><h3 id="3-mmap技术"><a href="#3-mmap技术" class="headerlink" title="3.mmap技术"></a><a href="#3-mmap%E6%8A%80%E6%9C%AF" title="3.mmap技术"></a>3.mmap技术</h3><p>上边所说的sendfile使用zero copy技术，实际上我们并没有修改文件内容， 然后再保存，只是简单的将本次磁盘上的文件内容发送给了网络。</p><p>现代操作系统都支持一种技术叫mmap，将文件内容直接映射到用户空间内的一块内存buffer上，可以读也可以写，省去了kernel到用户空间的多次copy。</p><p><img src="/2020/03/15/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6-Zookeeper-Kafka-MySQL/mmap.svg" title="mmap"></p><p>这种技术能在内存中修改文件的内容，修改后还能保存，省去了buffer 在kernel和用户之间的copy，所以速度非常快。它实际上使用的类似OS管理虚拟内存的方式，将文件内容page in /page out。对应到java里的api 就是MappedByteBuffer，实际上也是一个byte buffer，同 directBuffer一样，这些内存都不在jvm的堆内。</p><p>使用MappedByteBuffer时，直接指定开始读的文件位置，和需要读多少长度的内容。</p><figure class="highlight sas"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">MappedByteBuffer <span class="keyword">out</span> = <span class="keyword">file</span>.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, <span class="keyword">length</span>);  </span><br></pre></td></tr></tbody></table></figure><p>但这种技术也是有缺点的：</p><ol><li>每个mmap生成的文件handle在一个进程内是有限制的，在linux下是64k，如果超过整个数字，就无法在map文件</li><li>由于各种原因，jvm没有暴露关闭文件映射的方法，不能显式调用munmap()，要关闭掉这个文件映射，只能将MappedByteBuffer置为null，等java的gc过来回收，但如果内存很大，迟迟未gc的话，会耗尽文件handle。另外因为映射未及时关闭的话，不能再用普通的文件IO操作来读写文件。要显式关闭的话，只能使用hack的方法来调用sun.misc.Cleaner。</li><li>对文件的所有修改都是在内存中，可以调用MappedByteBuffer的force方法，强制将内容flush到磁盘上，但是如果每次都这样强刷，是有性能损耗的。但如果让操作系统来管理什时候flush的话，机器突然宕机会有丢失数据的风险</li><li>每次mmap文件时只能产生最大2GB的空间。</li></ol><h3 id="4-Page-Cache"><a href="#4-Page-Cache" class="headerlink" title="4.Page Cache"></a><a href="#4-Page-Cache" title="4.Page Cache"></a>4.Page Cache</h3><p>在上边第二部分已经说过，数据不落盘的话，就是在操作系统的缓冲区内，这里就是pageCache，Linux操作系统默认在文件写入时，为了加快写入的速度，都会先写入page cache。page cache 实际是内存的缓冲区，在内存的分页Page内，写入数据的page称之为脏页(dirtyPage)，需要随后flush到磁盘上。</p><p>在读取文件数据时，操作系统读完之后，也会将数据暂存在page cache上，第二次读相同文件时，数据已经在内存page cache 内了，所以会更快一些。</p><p>Linux操作系统会将所有可用的内存作为page cache使用，物尽其用，不让其浪费，这就是在linux下看free memory时总是非常小的原因。</p><p>在数据写入page cache后，操作系统负载flush数据的线程会监视两个值，第一个是dirtypage 里的数据最长能存活多长时间必须刷入磁盘，第二个是flush线程多久需要 wakeup起来运行一次。flush线程运行时，除了看脏页存活时间外，还会看另外两个值，dirty_background_ratio和dirty_ratio.</p><p>这两个参数的意义：</p><ol><li>vm.dirty_background_ratio 是指dirtyPage占总内存百分比多少的时候，系统开始强制将dirtyPage的数据刷入磁盘。</li><li>vm.dirty_ratio 指dirtyPage占据多少百分比内存时，开始强制block所有的IO操作，强制将dirtyPage内的数据刷入磁盘。</li></ol><p>简单说，就是第一个控制dirtyPage可以有多大，但有可能第一个条件达到时， flush线程还未到达触发条件，第二控制是兜底，最大不能超过多大，否则所有的IO都暂停，强刷数据到磁盘上。</p><p>pageCache不能设置太大，也不能设置太小。太大的话，脏页里的数据会太多，刷入磁盘时卡顿时间会很长，太小的话，又起不到写数据是加速的作用。</p><h2 id="ZooKeeper磁盘写优化"><a href="#ZooKeeper磁盘写优化" class="headerlink" title="ZooKeeper磁盘写优化"></a><a href="#ZooKeeper%E7%A3%81%E7%9B%98%E5%86%99%E4%BC%98%E5%8C%96" title="ZooKeeper磁盘写优化"></a>ZooKeeper磁盘写优化</h2><h3 id="1-groupCommit"><a href="#1-groupCommit" class="headerlink" title="1.groupCommit"></a><a href="#1-groupCommit" title="1.groupCommit"></a>1.groupCommit</h3><p>在“一致性协议研究-zookeeper”章节中说过，zookeeper运行过程中，会生成两个文件，一个是txn-log，一个是snapShot文件。txn-log是事务日志，每个写请求都会转发给leader，leader发送propose数据给follower，flollower将数据落盘，然后ack 集群leader。Leader在收到足够的ack数量后，会发送commit请求给 follower，正式完成写请求。</p><p>如上一章所属，为了保证一致性，follower必须将数据“真正”落盘后，才能ack集群leader。如果在流量很大的情况下，这种频繁落盘操作势必会成为瓶颈，zookeeper怎么来解决这个性能问题呢？</p><p>follower在接收到leader的propose请求后，准确的说并未真实落盘，仍然在缓冲区内，zookeeper会缓存多条事务，等设定的阈值条数到了之后，再写入磁盘。相关代码如下:</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 插入新的事务，将事务序列化到文件中  </span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="type">boolean</span> <span class="title function_">append</span><span class="params">(TxnHeader hdr, Record txn)</span>  </span><br><span class="line"> <span class="keyword">throws</span> IOException{  </span><br><span class="line"> <span class="comment">//..  </span></span><br><span class="line"> fos = <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(logFileWrite);  </span><br><span class="line"> logStream=<span class="keyword">new</span> <span class="title class_">BufferedOutputStream</span>(fos);  </span><br><span class="line"> oa = BinaryOutputArchive.getArchive(logStream);  </span><br><span class="line"> <span class="type">FileHeader</span> <span class="variable">fhdr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileHeader</span>(TXNLOG_MAGIC,VERSION, dbId);  </span><br><span class="line"> fhdr.serialize(oa, <span class="string">"fileheader"</span>);  </span><br><span class="line"> <span class="comment">//...  </span></span><br><span class="line">}  </span><br><span class="line">  </span><br><span class="line"><span class="comment">//继续，插入新的事务  </span></span><br><span class="line"> toFlush.add(si);  </span><br><span class="line"> <span class="keyword">if</span> (toFlush.size() &gt; <span class="number">1000</span>) {  </span><br><span class="line"> <span class="comment">//积累到1000条后，开始flush，真正落盘  </span></span><br><span class="line"> flush(toFlush);  </span><br><span class="line"> }  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">flush</span><span class="params">(LinkedList&lt;Request&gt; toFlush)</span>  </span><br><span class="line"> <span class="keyword">throws</span> IOException, RequestProcessorException  </span><br><span class="line"> {  </span><br><span class="line"> <span class="comment">//...  </span></span><br><span class="line"> <span class="comment">// 调用 zk database 的commit ，真正落盘开始  </span></span><br><span class="line"> zks.getZKDatabase().commit();  </span><br><span class="line"> <span class="comment">//..  </span></span><br><span class="line"> }  </span><br><span class="line">   </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">commit</span><span class="params">()</span> <span class="keyword">throws</span> IOException {  </span><br><span class="line"> <span class="comment">//...  </span></span><br><span class="line"> <span class="keyword">for</span>(FileOutputStream log : streamsToFlush)  </span><br><span class="line"> log.getChannel().force(<span class="literal">false</span>); <span class="comment">//落盘  </span></span><br><span class="line"> <span class="comment">///...  </span></span><br><span class="line"> }  </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>以上代码摘自SyncRequestProcessor和FilTxnLog两个类。有代码可见，group commit其实就是batch commit.</p><h3 id="2-文件预分配"><a href="#2-文件预分配" class="headerlink" title="2.文件预分配"></a><a href="#2-%E6%96%87%E4%BB%B6%E9%A2%84%E5%88%86%E9%85%8D" title="2.文件预分配"></a>2.文件预分配</h3><p>linux系统下，文件的一次写入最少会包含两次磁盘寻址，一次是写文件的真正内容，另外一次是更新文件的metadata信息，如上文所说的inode信息，需要更新使用的block数量，文件修改时间等信息。 zookeeper中的事务日志文件写入，采用了预分配的方法，每次创建一个新文件时，预先分配一定数量的文件空间(默认64M)(预定数量的block)，这样在平时高速追加文件内容时，就不需要每次去更新文件的meta信息，增加一次磁盘寻址了。相关的代码如下:</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/*  </span></span><br><span class="line"><span class="comment"> \* Grows the file to the specified number of bytes. This only happenes if   </span></span><br><span class="line"><span class="comment"> \* the current file position is sufficiently close (less than 4K) to end of   </span></span><br><span class="line"><span class="comment"> \* file.   </span></span><br><span class="line"><span class="comment"> \*   </span></span><br><span class="line"><span class="comment"> \* @param f output stream to pad  </span></span><br><span class="line"><span class="comment"> \* @param currentSize application keeps track of the cuurent file size  </span></span><br><span class="line"><span class="comment"> \* @param preAllocSize how many bytes to pad  </span></span><br><span class="line"><span class="comment"> \* @return the new file size. It can be the same as currentSize if no  </span></span><br><span class="line"><span class="comment"> \* padding was done.  </span></span><br><span class="line"><span class="comment"> \* @throws IOException  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="type">static</span> <span class="type">long</span> <span class="title">padLogFile</span><span class="params">(FileOutputStream f,<span class="type">long</span> currentSize,  </span></span></span><br><span class="line"><span class="params"><span class="function"> <span class="type">long</span> preAllocSize)</span> throws IOException</span>{  </span><br><span class="line"> <span class="type">long</span> position = f.<span class="built_in">getChannel</span>().<span class="built_in">position</span>();  </span><br><span class="line"> <span class="comment">//判断当前的文件空间是否马上(差4kb)就要写满  </span></span><br><span class="line"> <span class="keyword">if</span> (position + <span class="number">4096</span> &gt;= currentSize) {  </span><br><span class="line"> currentSize = currentSize + preAllocSize;  </span><br><span class="line"> fill.<span class="built_in">position</span>(<span class="number">0</span>);  </span><br><span class="line"> <span class="comment">//预分配一个新的64M空间的文件  </span></span><br><span class="line"> f.<span class="built_in">getChannel</span>().<span class="built_in">write</span>(fill, currentSize-fill.<span class="built_in">remaining</span>());  </span><br><span class="line"> }  </span><br><span class="line"> <span class="keyword">return</span> currentSize;  </span><br><span class="line"> }  </span><br></pre></td></tr></tbody></table></figure><h3 id="3-省去更新metadata信息"><a href="#3-省去更新metadata信息" class="headerlink" title="3.省去更新metadata信息"></a><a href="#3-%E7%9C%81%E5%8E%BB%E6%9B%B4%E6%96%B0metadata%E4%BF%A1%E6%81%AF" title="3.省去更新metadata信息"></a>3.省去更新metadata信息</h3><figure class="highlight processing"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/*  </span></span><br><span class="line"><span class="comment"> * commit the logs. make sure that evertyhing hits the  </span></span><br><span class="line"><span class="comment"> * disk  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"> <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">commit</span>() <span class="keyword">throws</span> IOException {  </span><br><span class="line"> <span class="keyword">if</span> (logStream != <span class="literal">null</span>) {  </span><br><span class="line"> logStream.<span class="property">flush</span>();  </span><br><span class="line"> }  </span><br><span class="line"> <span class="keyword">for</span> (FileOutputStream <span class="built_in">log</span> : streamsToFlush) {  </span><br><span class="line"> <span class="built_in">log</span>.<span class="property">flush</span>();  </span><br><span class="line"> <span class="keyword">if</span> (forceSync) {  </span><br><span class="line"> <span class="type">long</span> startSyncNS = System.<span class="property">nanoTime</span>();  </span><br><span class="line"> <span class="comment">//FileChannel.force直写数据，不更新metadata，少一次磁盘寻道操作，优化写速度  </span></span><br><span class="line"> <span class="built_in">log</span>.<span class="property">getChannel</span>().<span class="property">force</span>(<span class="literal">false</span>);  </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><h2 id="Mysql的磁盘写优化"><a href="#Mysql的磁盘写优化" class="headerlink" title="Mysql的磁盘写优化"></a><a href="#Mysql%E7%9A%84%E7%A3%81%E7%9B%98%E5%86%99%E4%BC%98%E5%8C%96" title="Mysql的磁盘写优化"></a>Mysql的磁盘写优化</h2><h3 id="1-group-commit"><a href="#1-group-commit" class="headerlink" title="1.group commit"></a><a href="#1-group-commit" title="1.group commit"></a>1.group commit</h3><p>mysql 中binlog的写入同样是每条事务的落盘，多个mysql 线程都同时在处理事务，怎么保障写binlog时不会冲突、乱序呢。这里边就需要一个锁(queue锁)，拿到锁的线程将事务写进一个统一的落盘事务queue，写入后释放锁，其他的thread可以继续写入新的事务。如下代码所示:</p><p>代码摘自:<br><a href="https://github.com/percona/percona-server/blob/1b5dff5b9e5f8c797cfed966c73fbbf6d45cbd59/sql/log.cc">https://github.com/percona/percona-server/blob/1b5dff5b9e5f8c797cfed966c73fbbf6d45cbd59/sql/log.cc</a></p><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">//拿到queue锁  </span></span><br><span class="line">mysql<span class="constructor">_mutex_lock(&amp;LOCK_group_commit_queue)</span>;  </span><br><span class="line">group_commit_entry \*orig_queue= group_commit_queue;  </span><br><span class="line">entry-&gt;next= orig_queue;  </span><br><span class="line"> <span class="comment">//追加本次事务  </span></span><br><span class="line">group_commit_queue= entry;  </span><br><span class="line"><span class="constructor">DEBUG_SYNC(<span class="params">entry</span>-&gt;<span class="params">thd</span>, <span class="string">"commit_group_commit_queue"</span>)</span>;  </span><br><span class="line"><span class="comment">//释放锁  </span></span><br><span class="line">mysql<span class="constructor">_mutex_unlock(&amp;LOCK_group_commit_queue)</span>;  </span><br></pre></td></tr></tbody></table></figure><p>如果这条线程发现自己是第一个初始化quque的，那么他自动变为group commit leader线程，他要负责将queue的内容最终落盘到binlog文件里去。</p><figure class="highlight scss"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/*  </span></span><br><span class="line"><span class="comment"> The first in the queue handle group commit for all; the others just wait  </span></span><br><span class="line"><span class="comment"> to be signalled when group commit is done.  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"> if (orig_queue != NULL)  </span><br><span class="line"> entry-&gt;thd-&gt;<span class="built_in">wait_for_wakeup_ready</span>();  </span><br><span class="line"> else <span class="comment">//我是group commit leader  </span></span><br><span class="line"> <span class="built_in">trx_group_commit_leader</span>(entry);  </span><br></pre></td></tr></tbody></table></figure><p>leader线程会将queue里的内容先拷贝到自己的thread local queue里，然后再将自己thread local queue里的内容写进磁盘</p><p>落盘到binlog文件里的操作:</p><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/*  </span></span><br><span class="line"><span class="comment"> Lock the LOCK_log(), and once we get it, collect any additional writes  </span></span><br><span class="line"><span class="comment"> that queued up while we were waiting.  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"> <span class="comment">//获取bin log文件锁  </span></span><br><span class="line"> mysql<span class="constructor">_mutex_lock(&amp;LOCK_log)</span>;  </span><br><span class="line"> <span class="constructor">DEBUG_SYNC(<span class="params">leader</span>-&gt;<span class="params">thd</span>, <span class="string">"commit_after_get_LOCK_log"</span>)</span>;  </span><br><span class="line"> <span class="comment">//再次获取queue锁  </span></span><br><span class="line"> mysql<span class="constructor">_mutex_lock(&amp;LOCK_group_commit_queue)</span>;  </span><br><span class="line"> <span class="comment">//copy queue到thread local 里的queue里  </span></span><br><span class="line"> current= group_commit_queue;  </span><br><span class="line"> <span class="comment">//清空原来的queue  </span></span><br><span class="line"> group_commit_queue= NULL;  </span><br><span class="line"> <span class="comment">//释放queue锁  </span></span><br><span class="line"> mysql<span class="constructor">_mutex_unlock(&amp;LOCK_group_commit_queue)</span>;  </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>由上可以看出，mysql的事务写入也是批量的，通过中间的queue(mysql group commit queue)来实现批量的积攒，最终一次落盘操作。</p><h2 id="Kafka的磁盘读写优化"><a href="#Kafka的磁盘读写优化" class="headerlink" title="Kafka的磁盘读写优化"></a><a href="#Kafka%E7%9A%84%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96" title="Kafka的磁盘读写优化"></a>Kafka的磁盘读写优化</h2><h3 id="1-page-cache的使用"><a href="#1-page-cache的使用" class="headerlink" title="1.page cache的使用"></a><a href="#1-page-cache%E7%9A%84%E4%BD%BF%E7%94%A8" title="1.page cache的使用"></a>1.page cache的使用</h3><p>Kafka主要用磁盘来存储消息，他对磁盘的使用优化技术用的很多，第一个就是pageCache的使用，kafka默认是不强刷磁盘的，所有的消息全部写入pageCache内，让操作系统来管理刷盘策略。但是kafka仍然提供了两个控制参数，多长时间需要刷一次盘，收到多少条消息后需要刷一次盘，如下代码：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> <span class="keyword">public</span> <span class="type">static</span> <span class="keyword">final</span> <span class="type">String</span> FLUSH_MESSAGES_INTERVAL_CONFIG = <span class="string">"flush.messages"</span>;  </span><br><span class="line"> <span class="comment">//注释中可以看出，不建议设置，让操作系统使用后台线程flush  </span></span><br><span class="line"> <span class="keyword">public</span> <span class="type">static</span> <span class="keyword">final</span> <span class="type">String</span> FLUSH_MESSAGES_INTERVAL_DOC = <span class="string">"This setting allows specifying an interval at "</span> +  </span><br><span class="line"> <span class="string">"which we will force an fsync of data written to the log. For example if this was set to 1 "</span> +  </span><br><span class="line"> <span class="string">"we would fsync after every message; if it were 5 we would fsync after every five messages. "</span> +  </span><br><span class="line"> <span class="string">"In general we recommend you not set this and use replication for durability and allow the "</span> +  </span><br><span class="line"> <span class="string">"operating system's background flush capabilities as it is more efficient. This setting can "</span> +  </span><br><span class="line"> <span class="string">"be overridden on a per-topic basis (see &lt;a href=\\"</span><span class="meta">#topicconfigs\\<span class="string">"&gt;the per-topic configuration section&lt;/a&gt;)."</span>;  </span></span><br><span class="line">  </span><br><span class="line"> <span class="keyword">public</span> <span class="type">static</span> <span class="keyword">final</span> <span class="type">String</span> FLUSH_MS_CONFIG = <span class="string">"flush.ms"</span>;  </span><br><span class="line"> <span class="comment">//注释中可以看出，不建议设置，让操作系统使用后台线程flush  </span></span><br><span class="line"> <span class="keyword">public</span> <span class="type">static</span> <span class="keyword">final</span> <span class="type">String</span> FLUSH_MS_DOC = <span class="string">"This setting allows specifying a time interval at which we will "</span> +  </span><br><span class="line"> <span class="string">"force an fsync of data written to the log. For example if this was set to 1000 "</span> +  </span><br><span class="line"> <span class="string">"we would fsync after 1000 ms had passed. In general we recommend you not set "</span> +  </span><br><span class="line"> <span class="string">"this and use replication for durability and allow the operating system's background "</span> +  </span><br><span class="line"> <span class="string">"flush capabilities as it is more efficient."</span>;  </span><br><span class="line">   </span><br><span class="line">  </span><br><span class="line"> <span class="comment">//到达配置时间后，强制刷盘   </span></span><br><span class="line"><span class="keyword">if</span> (unflushedMessages &gt;= config.flushInterval)  </span><br><span class="line"> <span class="built_in">flush</span>()  </span><br><span class="line"> <span class="comment">//xxxx  </span></span><br><span class="line">  </span><br><span class="line"> <span class="comment">/*  </span></span><br><span class="line"><span class="comment"> * Commit all written data to the physical disk  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">flush</span><span class="params">()</span> throws IOException </span>{  </span><br><span class="line"> <span class="comment">//强制刷盘，包括元数据也刷进磁盘  </span></span><br><span class="line"> channel.force(<span class="literal">true</span>);  </span><br><span class="line"> }  </span><br></pre></td></tr></tbody></table></figure><h3 id="2-zeroCopy技术的使用"><a href="#2-zeroCopy技术的使用" class="headerlink" title="2. zeroCopy技术的使用"></a><a href="#2-zeroCopy%E6%8A%80%E6%9C%AF%E7%9A%84%E4%BD%BF%E7%94%A8" title="2. zeroCopy技术的使用"></a>2. zeroCopy技术的使用</h3><p>kafka在消费者拉取消息时，需要将磁盘的数据发给消费者，这时就是用”sendFile”的zero copy概念，相关代码如下(截取自PlaintextTransportLayer.java):</p><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">@Override  </span><br><span class="line">public long transfer<span class="constructor">From(FileChannel <span class="params">fileChannel</span>, <span class="params">long</span> <span class="params">position</span>, <span class="params">long</span> <span class="params">count</span>)</span> throws IOException {  </span><br><span class="line"> <span class="comment">//将文件内容写入网络socket，zero copy  </span></span><br><span class="line"> return fileChannel.transfer<span class="constructor">To(<span class="params">position</span>, <span class="params">count</span>, <span class="params">socketChannel</span>)</span>;  </span><br><span class="line">}  </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><h3 id="3-文件预分配"><a href="#3-文件预分配" class="headerlink" title="3.文件预分配"></a><a href="#3-%E6%96%87%E4%BB%B6%E9%A2%84%E5%88%86%E9%85%8D" title="3.文件预分配"></a>3.文件预分配</h3><p>(详细内容，参见上面zookeeper-文件预分配技术)，kafka记录消息的文件称之为segement，在创建这样的文件时也是用了 文件预分配技术优化，相关代码如下(截取自Log.scala):</p><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (logSegments.isEmpty) {  </span><br><span class="line"> <span class="comment">// no existing segments, create a new mutable segment beginning at logStartOffset  </span></span><br><span class="line"> <span class="built_in">addSegment</span>(LogSegment<span class="selector-class">.open</span>(dir = dir,  </span><br><span class="line"> baseOffset = logStartOffset,  </span><br><span class="line"> config,  </span><br><span class="line"> <span class="selector-tag">time</span> = <span class="selector-tag">time</span>,  </span><br><span class="line"> fileAlreadyExists = false,  </span><br><span class="line"> initFileSize = this<span class="selector-class">.initFileSize</span>,  </span><br><span class="line"> <span class="comment">//预分配文件大小  </span></span><br><span class="line"> preallocate = config.preallocate))  </span><br><span class="line">}  </span><br></pre></td></tr></tbody></table></figure><h3 id="4-mmap技术"><a href="#4-mmap技术" class="headerlink" title="4. mmap技术"></a><a href="#4-mmap%E6%8A%80%E6%9C%AF" title="4. mmap技术"></a>4. mmap技术</h3><p>内存映射文件，如上边基础知识所述，通过内存来映射磁盘上的数据文件，达到较快的读写速度。kafka通过mmap来读写index文件，相关代码如下(截取自AbstractIndex.scala):</p><figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractIndex\</span>[<span class="type">K</span>, <span class="type">V</span>\](<span class="params">@volatile var file: <span class="type">File</span>, val baseOffset: <span class="type">Long</span>,  </span></span></span><br><span class="line"><span class="params"><span class="class"> val maxIndexSize: <span class="type">Int</span> = -1, val writable: <span class="type">Boolean</span></span>) <span class="keyword">extends</span> <span class="title">Closeable</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>{  </span><br><span class="line">​  </span><br><span class="line"> <span class="comment">// Length of the index file  </span></span><br><span class="line"> <span class="meta">@volatile</span>  </span><br><span class="line"> <span class="keyword">private</span> <span class="keyword">var</span> _length: <span class="type">Long</span> = _  </span><br><span class="line"> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">entrySize</span></span>: <span class="type">Int</span>  </span><br><span class="line">​  </span><br><span class="line"> <span class="comment">/*  </span></span><br><span class="line"><span class="comment"> Kafka mmaps index files into memory, and all the read / write operations of the index is through OS page cache. This  </span></span><br><span class="line"><span class="comment"> avoids blocked disk I/O in most cases.  </span></span><br><span class="line"><span class="comment">​  </span></span><br><span class="line"><span class="comment"> To the extent of our knowledge, all the modern operating systems use LRU policy or its variants to manage page  </span></span><br><span class="line"><span class="comment"> cache. Kafka always appends to the end of the index file, and almost all the index lookups (typically from in-sync  </span></span><br><span class="line"><span class="comment"> followers or consumers) are very close to the end of the index. So, the LRU cache replacement policy should work very  </span></span><br><span class="line"><span class="comment"> well with Kafka's index access pattern.  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line">   </span><br><span class="line"> <span class="meta">@volatile</span>  </span><br><span class="line"> <span class="keyword">protected</span> <span class="keyword">var</span> mmap: <span class="type">MappedByteBuffer</span> = {  </span><br><span class="line"> <span class="keyword">val</span> newlyCreated = file.createNewFile()  </span><br><span class="line"> <span class="comment">//创建RandomAccessFile  </span></span><br><span class="line"> <span class="keyword">val</span> raf = <span class="keyword">if</span> (writable) <span class="keyword">new</span> <span class="type">RandomAccessFile</span>(file, <span class="string">"rw"</span>) <span class="keyword">else</span> <span class="keyword">new</span> <span class="type">RandomAccessFile</span>(file, <span class="string">"r"</span>)  </span><br><span class="line"> </span><br><span class="line"> <span class="comment">//开始map 文件  </span></span><br><span class="line"> <span class="keyword">if</span> (writable)  </span><br><span class="line"> raf.getChannel.map(<span class="type">FileChannel</span>.<span class="type">MapMode</span>.<span class="type">READ_WRITE</span>, <span class="number">0</span>, _length)  </span><br><span class="line"> <span class="keyword">else</span>  </span><br><span class="line"> raf.getChannel.map(<span class="type">FileChannel</span>.<span class="type">MapMode</span>.<span class="type">READ_ONLY</span>, <span class="number">0</span>, _length)  </span><br><span class="line"> </span><br><span class="line"> }  </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>另外一个有趣的地方是kafka的munmap方法，实际上调用的是DirectByteBuffer的cleanr方法来关闭文件映射，使用方式比较hack。代码如下(截取自MappedByteBuffers.java):</p><figure class="highlight pgsql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">private static MethodHandle unmapJava7Or8(MethodHandles.Lookup lookup) throws ReflectiveOperationException {  </span><br><span class="line"> <span class="comment">/* "Compile" a MethodHandle that is roughly equivalent to the following lambda:  </span></span><br><span class="line"><span class="comment"> *  </span></span><br><span class="line"><span class="comment"> * (ByteBuffer buffer) -&gt; {  </span></span><br><span class="line"><span class="comment"> *   sun.misc.Cleaner cleaner = ((java.nio.DirectByteBuffer) byteBuffer).cleaner();  </span></span><br><span class="line"><span class="comment"> *   if (nonNull(cleaner))  </span></span><br><span class="line"><span class="comment"> *     cleaner.clean();  </span></span><br><span class="line"><span class="comment"> *   else  </span></span><br><span class="line"><span class="comment"> *     noop(cleaner); // the noop is needed because MethodHandles#guardWithTest always needs both if and else  </span></span><br><span class="line"><span class="comment"> * }  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"> <span class="keyword">Class</span>&lt;?&gt; directBufferClass = <span class="keyword">Class</span>.forName("java.nio.DirectByteBuffer");  </span><br><span class="line"> <span class="keyword">Method</span> m = directBufferClass.getMethod("cleaner");  </span><br><span class="line"> m.setAccessible(<span class="keyword">true</span>);  </span><br><span class="line"> MethodHandle directBufferCleanerMethod = lookup.unreflect(m);  </span><br><span class="line"> <span class="keyword">Class</span>&lt;?&gt; cleanerClass = directBufferCleanerMethod.<span class="keyword">type</span>().returnType();  </span><br><span class="line"> MethodHandle cleanMethod = lookup.findVirtual(cleanerClass, "clean", methodType(<span class="type">void</span>.<span class="keyword">class</span>));  </span><br><span class="line"> MethodHandle nonNullTest = lookup.findStatic(MappedByteBuffers.<span class="keyword">class</span>, "nonNull",  </span><br><span class="line"> methodType(<span class="type">boolean</span>.<span class="keyword">class</span>, <span class="keyword">Object</span>.<span class="keyword">class</span>)).asType(methodType(<span class="type">boolean</span>.<span class="keyword">class</span>, cleanerClass));  </span><br><span class="line"> MethodHandle noop = dropArguments(<span class="keyword">constant</span>(<span class="type">Void</span>.<span class="keyword">class</span>, <span class="keyword">null</span>).asType(methodType(<span class="type">void</span>.<span class="keyword">class</span>)), <span class="number">0</span>, cleanerClass);  </span><br><span class="line"> MethodHandle unmapper = filterReturnValue(directBufferCleanerMethod, guardWithTest(nonNullTest, cleanMethod, noop))  </span><br><span class="line"> .asType(methodType(<span class="type">void</span>.<span class="keyword">class</span>, ByteBuffer.<span class="keyword">class</span>));  </span><br><span class="line"> <span class="keyword">return</span> unmapper;  </span><br><span class="line"> }  </span><br></pre></td></tr></tbody></table></figure><p>参考:</p><ol><li>nachoparker 2018 <a href="https://ownyourbits.com/2018/05/02/understanding-disk-usage-in-linux/">https://ownyourbits.com/2018/05/02/understanding-disk-usage-in-linux/</a></li><li>Lokesh Gupta , <a href="https://howtodoinjava.com/java/io/how-java-io-works-internally-at-lower-level/">https://howtodoinjava.com/java/io/how-java-io-works-internally-at-lower-level/</a></li><li>Shawn Xu, <a href="https://medium.com/@xunnan.xu/its-all-about-buffers-zero-copy-mmap-and-java-nio-50f2a1bfc05c">https://medium.com/@xunnan.xu/its-all-about-buffers-zero-copy-mmap-and-java-nio-50f2a1bfc05c</a></li><li><a href="https://stackoverflow.com/questions/8263995/standardopenoption-sync-vs-standardopenoption-dsync">https://stackoverflow.com/questions/8263995/standardopenoption-sync-vs-standardopenoption-dsync</a></li><li><a href="https://stackoverflow.com/questions/4072878/i-o-concept-flush-vs-sync">https://stackoverflow.com/questions/4072878/i-o-concept-flush-vs-sync</a></li></ol>]]></content>
    
    
    <summary type="html">本文对linux下磁盘的读写优化技术做了一个搜底和总览，包括基本的文件读写知识，磁盘，page cache ，zeror copy，mmap等知识，还对zookeeper 、kafka 、mysql 在使用磁盘读写文件时的优化技术做了分析。</summary>
    
    
    
    <category term="磁盘读写优化" scheme="https://www.wangjunfei.com/categories/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96/"/>
    
    
    <category term="kafka" scheme="https://www.wangjunfei.com/tags/kafka/"/>
    
    <category term="zookeeper" scheme="https://www.wangjunfei.com/tags/zookeeper/"/>
    
    <category term="磁盘读写优化" scheme="https://www.wangjunfei.com/tags/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E4%BC%98%E5%8C%96/"/>
    
    <category term="mysql" scheme="https://www.wangjunfei.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>一致性算法研究(三)Kafka</title>
    <link href="https://www.wangjunfei.com/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/"/>
    <id>https://www.wangjunfei.com/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/</id>
    <published>2020-02-26T13:36:47.000Z</published>
    <updated>2022-02-11T04:02:51.082Z</updated>
    
    <content type="html"><![CDATA[<p><span class="github-emoji" style="display:inline;vertical-align:middle"><span>⚠</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 原创文章，转载请注明出处</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><a href="#%E6%91%98%E8%A6%81" title="摘要"></a>摘要</h2><p>一致性算法是分布式系统中的一个重要协议，是分布式数据库、Kafka、Zookeeper的基本协议。但这些协议晦涩难懂，对初学者需要耗费大量时间研究，本系列文章，是对一致性算法的一个大搜底和总览，通过对paper和技术资料的阅读，总结出一个简单易懂的学习材料，供其他人方便理解和学习。</p><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a><a href="#%E5%85%B3%E9%94%AE%E8%AF%8D" title="关键词"></a>关键词</h2><p>consensus algorithm(一致性算法) 分布式系统 一致性算法 Paxos Raft ZooKeeper ZAB</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a><a href="#%E8%83%8C%E6%99%AF" title="背景"></a>背景</h2><p>在谈到分布式系统时，很难不提及的产品除了ZooKeeper之外，另外一个就是Kafka. Apache Kafka是一个典型的分布式系统，整个系统从外围看，非常像我们说明共识问题时的例子 :</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/replication.svg" title="distrabute replication"></p><p>S1-S5是Kafka整个集群，client 1 是生产端，client 2是消费端。整个集群支持消息的写入和读取，并且能保持不丢消息，不乱序。本节内容，我们一起来看下Kafka是怎么解决分布式场景下的共识问题的。</p><h2 id="Kafka基本知识"><a href="#Kafka基本知识" class="headerlink" title="Kafka基本知识"></a><a href="#Kafka%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86" title="Kafka基本知识"></a>Kafka基本知识</h2><p>一个Kafka集群有若干台机器组成，一个集群可以运营成百上千个队列，一个队列可以有几个分区，比如下图所示，有3台机器(BrokerA、BrokerB、BrokerC)组成的一个集群，有两个topic： TopicA 和 TopicB。</p><p>TopicA有3个分区，分别标为重蓝色，重黄色，重粉色。3个分区平均分布在3台机器上，一台机器上一个。分区存储着队列的消息信息，在这个例子里，topicA有3个分区，消息也分3部分，分别存储在这3个分区上，但是Kafka集群为了规避单点风险，每个分区又会有一个或多个副本，副本数量可以自己定义，一般是1-3 个副本，1个副本的话是有单点风险的，2个副本容忍1个集群有1台机器宕机的情况下，队列仍然高可用，不影响消息的收发，3副本容忍2台机器同时宕机。所以，有f+1个副本的kafka topic容忍f个副本的机器同时宕机。</p><p>下图示例，topicA有3个分区，每个分区有3个副本，3个副本会平均分布在3台服务器上，比如topicA分区1主副本在BrokerA上，从副本rep1和rep2分别在BrokerB和BrokerC上，从副本会不断同步主副本的数据，和主副本保持一致，当主副本所在的机器宕机后，两个从副本所在的机器会在剩余的两个副本之间选出一个副本作为主副本，继续消息的收发，保持系统高可用。topicB有2个分区，只有一个副本。</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/kafka.svg" title="kafka"></p><p>客户端有两个clientA 和 clientB。Kafka集群在接收客户端发送消息或读取消息的请求时，只会将请求发送给每个分区的主分区所在的服务器来处理。比如发送消息时，客户端将消息内容发送给topicA分区1的主分区所在的服务器BrokerA，由于分区1的副本rep1/rep2(replica 1和replica 2 下同)分别在BrokerB和BrokerC上，BrokerB和BrokerC上分别驻留一个消息复制器，负责把BrokerA上topicA主分区的消息拉给自身所在的从副本rep1和rep2上。</p><p>消息复制器在每台broker上都有一个，分别启动线程去其他服务器拉自己感兴趣的分区主本消息。</p><h2 id="共识问题"><a href="#共识问题" class="headerlink" title="共识问题"></a><a href="#%E5%85%B1%E8%AF%86%E9%97%AE%E9%A2%98" title="共识问题"></a>共识问题</h2><p>上边讲到topicA有3个分区，每个分区有3个副本，这样的队列容忍集群内同时有2台服务器宕机的情况下保持高可用。每个分区的3个副本平均分布在3台服务器上，那么问题来了，这3个副本怎么保持一致呢？</p><p>如下图所示，生产端在发送一条消息”id=101”后，消息发送到了分区的“主本“机器BrokerA上，消息的两个副本分别在Broker B和Broker C上，由上边所讲，Broker B和Broker C依赖本机的“消息复制器”将消息复制到本机副本中。如果”Client生产端“配置发送策略为”Ack=-1”，那么这条消息只有在Broker B和Broker C两台机器复制完成后，才算发送成功。这就保证了“消息如果发送成功”，那么其他副本一定是接收到消息了。</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/msg_replicate.svg" title="kafka message replication"></p><p>但是，中间过程中的机器宕机等情况时，怎么来保证一致性呢？ 这个问题，kafka交给了zookeeper来解决。kafka集群启动时，会依靠zookeeper来选举一个集群的主节点服务器(controller)，controller来管理整个集群，比如队列的创建、删除，队列分区的选主，如前边所说的，topicA有3个分区，每个分区有3个副本(replica)，在创建每个分区时，kafka会使用zookeeper来选举一个分区副本的主(leader)。</p><p>一个集群内有上千个队列，每个队列都有数十个甚至数百个分区，每个分区又会有若干个副本，多个副本之间谁是leader副本？这些信息称之为metadata，kafka全部储存在了zookeeper上。</p><p>所以机器宕机时，controller和leader replica的选举任务都交给了zookeeper来完成，那么这时集群内机器之间的一致性，分区副本之间的一致性，这些共识问题都交给了zookeeper来解决。有了zookeeper，集群内每个机器不会对谁是controller再产生分歧，有了controller，一个集群就一个统一的“负责人”。同时，每个分区的副本之间使用zookeeper来选主，也会产生一个“负责人”，所有机器，多个副本之间都交由这些负责人来协调，不会再产生分歧，而且不会脑裂。</p><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a><a href="#%E7%BB%86%E8%8A%82" title="细节"></a>细节</h2><p>如下图所示，假设brokerA是当前集群的controller，当brokerA宕机后，其他broker马上会通过zookeeper来感知到，在brokerB/brokerC来选取一个新的controller出来。这个过程是通过抢占zookeeper的临时节点来实现的，因此共识问题、一致性问题都由zookeeper来保障。</p><p>同样切换的还有分区的leader，比如topicA分区1的leader原来在brokerA上，当brokerA宕机后，topicA分区1会在rep1和rep2之间选取一个新的分区leader，如下图所示，原来的分区1的rep1变成了新的分区leader，可以继续接受客户端的读写请求了。</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/brokerA_down.svg" title="brokerA down"></p><p>在选取新的分区副本leader 时，kafka会优先选取消息数量和主本一样的副本，怎么实现的呢？</p><p>正常运行时，有3个副本的分区，kafka维持一个ISR(In sync replica)的概念，如果3个副本的消息量在一定时间内是一样的，那这三个副本就都在ISR内。如果某个副本的消息，在指定的时间内，没有同主本消息保持一致，这个副本就会被踢出ISR。如果3个副本里，主本一直接收消息，2个副本都在一定的时间内，没能跟上主本的消息数量，这时ISR缩减为主本一个，这时主本如果宕机会有丢消息的风险。因此，kafka有一个专门的设置，min ISR(in sync replica)数量，如果数量低于一定的值，kafka 集群就不再接收消息，因为这时集群是有丢消息的风险。这也是可用性(A)和一致性(C)之间的一个选择。</p><p>ISR的信息同样存储在zookeeper中，由zookeeper来保障信息的一致性。在客户端发送一条消息后，需要ISR里的各replica都确认收到消息后才能算成功，如下图所示:</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/kafka_commit.svg" title="kafka commit msg"></p><p>与下图zookeeper的消息接收不一样，zookeeper只需要多数(quorum)确认收到即可：</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%89-Kafka/zk_commit.svg" title="zookeeper commit msg"></p><p>Kafka这中可以配置的确认机制，相比zookeeper会比较灵活一些，比如有9个机器组成的集群，zookeeper需要5个机器确认收到消息，而kafka只需要配置2或3即可保证消息不丢失，减少leader副本因等待接收ack而消耗的时间。</p><p>但在集群quorum比较小的情况，zookeeper的确认机制是比较占优势的。比如，当zookeeper的quorum是3的时候，如上图的情况，leader节点只需要收到任意一个follower的ack即可算发送成功，但是kafka需要等待两个副本都收到消息后，才能算发送成功。在这种场景下，zookeeper的确认机制是占优势的。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考:"></a><a href="#%E5%8F%82%E8%80%83" title="参考:"></a>参考:</h2><ol><li><a href="https://www.confluent.io/blog/distributed-consensus-reloaded-apache-zookeeper-and-replication-in-kafka/">https://www.confluent.io/blog/distributed-consensus-reloaded-apache-zookeeper-and-replication-in-kafka/</a></li><li><a href="https://www.semanticscholar.org/paper/Zab%3A-High-performance-broadcast-for-primary-backup-Junqueira-Reed/b02c6b00bd5dbdbd951fddb00b906c82fa80f0b3">https://www.semanticscholar.org/paper/Zab%3A-High-performance-broadcast-for-primary-backup-Junqueira-Reed/b02c6b00bd5dbdbd951fddb00b906c82fa80f0b3</a></li></ol>]]></content>
    
    
    <summary type="html">一致性算法是分布式系统中的一个重要协议，是分布式数据库、Kafka、Zookeeper的基本协议。但这些协议晦涩难懂，对初学者需要耗费大量时间研究，本系列文章，是对一致性算法的一个大搜底和总览，通过对paper和技术资料的阅读，总结出一个简单易懂的学习材料，供其他人方便理解和学习。</summary>
    
    
    
    <category term="分布式技术" scheme="https://www.wangjunfei.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="kafka" scheme="https://www.wangjunfei.com/tags/kafka/"/>
    
    <category term="分布式技术" scheme="https://www.wangjunfei.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"/>
    
    <category term="zookeeper" scheme="https://www.wangjunfei.com/tags/zookeeper/"/>
    
    <category term="consensus algorithm" scheme="https://www.wangjunfei.com/tags/consensus-algorithm/"/>
    
    <category term="zab" scheme="https://www.wangjunfei.com/tags/zab/"/>
    
    <category term="一致性算法" scheme="https://www.wangjunfei.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>一致性算法研究(二)ZooKeeper ZAB协议</title>
    <link href="https://www.wangjunfei.com/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/"/>
    <id>https://www.wangjunfei.com/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/</id>
    <published>2020-02-26T13:36:37.000Z</published>
    <updated>2022-02-11T04:02:25.242Z</updated>
    
    <content type="html"><![CDATA[<p><span class="github-emoji" style="display:inline;vertical-align:middle"><span>⚠</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 原创文章，转载请注明出处</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><a href="#%E6%91%98%E8%A6%81" title="摘要"></a>摘要</h2><p>一致性算法是分布式系统中的一个重要算法，是分布式数据库、Kafka、Zookeeper的基本协议。但这些协议晦涩难懂，对初学者需要耗费大量时间研究，本系列文章，是对一致性算法的一个大搜底和总览，通过对paper和技术资料的阅读，总结出一个简单易懂的学习材料，供其他人方便理解和学习。</p><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a><a href="#%E5%85%B3%E9%94%AE%E8%AF%8D" title="关键词"></a>关键词</h2><p>consensus algorithm(一致性算法) 分布式系统 分布式协议 Paxos Raft ZooKeeper ZAB</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a><a href="#%E8%83%8C%E6%99%AF" title="背景"></a>背景</h2><p>Zookeeper是大家工作中经常用到的分布式组件，用来处理分布式场景下一致性问题。按理说Zookeeper使用paxos来解决共识问题，是顺利成章的，但zookeeper确是借鉴了Paxos协议，发明了自己的ZAB(Zookeeper Atomic Broadcast protocal简称ZAB)协议来解决共识问题。Paxos、ZAB、Raft这个几个协议都认为自己是一个独立的一致性算法，但有人却说，世界上只有一个一致性算法，那就是Paxos，其他协议都是它的变种。这种理论争论暂且不提，我们来研究下具体协议的真实工程实践，毕竟Zookeeper在实际工程实践中，是一个成功的案例。</p><h2 id="问题原型"><a href="#问题原型" class="headerlink" title="问题原型"></a><a href="#%E9%97%AE%E9%A2%98%E5%8E%9F%E5%9E%8B" title="问题原型"></a>问题原型</h2><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/consensus_problem.svg" title="Consensus Problem"></p><p>在上一篇Paxos研究中，提到了共识问题。其中一个例子，讲在一个分布式系统中，client端往系统写数据，server端接受数据，同时提供读服务。为了让系统的吞吐量高，希望所有的节点都提供写和读服务。要达到这样的效果，显然需要数据在集群内各节点做复制，否则无法读到。要解决这样的分布式数据复制，有个哥么写了一篇论文，说有两种方法：第一使用一个replication state machine(复制型的有限状态机)。第二种方法，使用一个primary-backup 主备系统。Zookeeper也是一个分布式系统，问题场景和上边的图形很相似，但Zookeeper说自己属于第二种方法，Paxos属于第一种。这个问题，我们暂时先知道即可，关于具体的复制有限状态机(replication state machine)和主备系统(primary-backup)系统的区别，我会在以后的纯理论研究中去分析。下边我们来研究zookeeper怎么来具体解决共识问题。</p><h2 id="Paxos实际应用中的缺陷"><a href="#Paxos实际应用中的缺陷" class="headerlink" title="Paxos实际应用中的缺陷"></a><a href="#Paxos%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E7%BC%BA%E9%99%B7" title="Paxos实际应用中的缺陷"></a>Paxos实际应用中的缺陷</h2><p>Paxos只确只要有足够的节点在工作，系统最终能选出一个议案，但有以下缺陷：</p><ol><li><p>不保序</p></li><li><p>容忍丢失消息</p></li></ol><p>例如在以下的特定场景中，有3个独立的Proposer: P1,P2,P3，三个acceptor，P1,P2运行过程中，先后宕机。  </p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/paxos_problem.svg" title="Paxos的问题"></p><p>通过上图可以看出</p><ol><li><p>客户端提案的顺序按编号应该是27-A，28-B，29-C，但最终应用后确是27-C，28-B，29-D，</p></li><li><p>提案A丢失。</p></li></ol><h2 id="Zookeeper基础知识"><a href="#Zookeeper基础知识" class="headerlink" title="Zookeeper基础知识"></a><a href="#Zookeeper%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86" title="Zookeeper基础知识"></a>Zookeeper基础知识</h2><p>Zookeeper解决了上边所说的两个问题，他使用了Primary-backup的方案来保障所有的server状态一致。在这样的系统下，所有的客户端请求都转发给一个server，这个server称为primary，在处理完这个请求后，将结果广播给其他所有的server，这个广播协议称为ZAB()。在primary宕机后，其他server会执行一个recovery的过程，选举一个新的primary出来，在新primary履职前，必须统一所有server的状态，让大家对当前的数据状态保持一致。  </p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/zab.svg" title="ZAB"></p><h3 id="1-Requests-Transactions-Identifiers-zxid"><a href="#1-Requests-Transactions-Identifiers-zxid" class="headerlink" title="1: Requests,Transactions,Identifiers(zxid)"></a><a href="#1-Requests-Transactions-Identifiers-zxid" title="1: Requests,Transactions,Identifiers(zxid)"></a>1: Requests,Transactions,Identifiers(zxid)</h3><p>zookeeper中exists、getData、getChildren等读操作，都是本地处理的，无论是leader或follower或observer都可以就地处理，所以读操作都是比较快的。</p><p>create/delete/setData等都是写操作，写操作都会forward给leader处理，相比读操作会较慢。每个写操作都称为一个transaction，client发起一个事务(写操作)，zookeeper会将事务转发给zookeeper leader来处理。</p><p>每个transaction包含两个值: 新value和一个version，比如&lt;1,1&gt;，客户端发起这个事务，如果最终被提交的话，server端会替换节点为新的value和version，而不是去增加原value的值。</p><p>每个事务都是原子操作，value和version都会被更新，不会出现一个更新了，而另外一个没更新。</p><p>所有的事务都是幂等的，可以执行一次或多次，但前提是每次执行都是按照相同的顺序执行。</p><p>当leadrer生成一个事务时，会产生一个transaction ID，叫做zxid，zxid标识唯一一个事务。zxid（64位）包含两部分epoch(位) + counter（32位），epoch部分是一个server 履职leader期间的一个标识，counter部分是递增的，每收到一个事务就会加1。leader广播这样的事务，其他follower来接收。这样有一个好处，就是当leader宕机后，新leader选举时可以比较各server接收到的zxid，看谁的zxid更大,这样选举时就知道谁接收的transaction比较多了。 。</p><h3 id="2：Zk集群leader选举"><a href="#2：Zk集群leader选举" class="headerlink" title="2：Zk集群leader选举"></a><a href="#2%EF%BC%9AZk%E9%9B%86%E7%BE%A4leader%E9%80%89%E4%B8%BE" title="2：Zk集群leader选举"></a>2：Zk集群leader选举</h3><p>leader是一个集群(ensemble: Leader+Follower)选举出来的一个主，负责协调整个集群的事物. leader会处理改变集群状态的操作(create/deate/setData)，把每个操作转换成一个transaction，发起proposel给follower，accept后按顺序commit。</p><p>要选举一个leader，一个集群必须有法定人数(quorum:超过一半的人数)的节点支持他，而且quorum数量必须是奇数，否则会产生脑裂。</p><p>一个刚启动的节点状态处于Looking状态，他必须选取一个leader或寻找一个已存在。如果没有leader，集群会选择一个leader，被选出的leader会处于leading状态，其他结点会处于following状态。</p><p>选举leader时，使用的选举协议比较简单，所有节点都会发出notification消息，notification消息包含server id (sid)和最近一次commit的zxid(实际上是epoch和一个counter).</p><p>每个server在选举时，会执行以下步骤:</p><ol><li><p>假如voteId，voteZxid是当前节点收到的选举消息，myZxid和 mySid是当前节点自己的值</p></li><li><p>如果voteZxid &gt; myZxid 或 voteZxid = myZxid，但是voteId &gt; mySid，把当前收到的voteZxid和voteId保留。</p></li><li><p>否则把自己的myVoteid和myZxid赋值给VoteZxid和VoteId。</p><p>简单来讲，拥有最大zxid的节点会赢得选举，如果大家都拥有最大zxid，服务器sid最大的获选</p></li></ol><p>一旦某个server接收到了达到法定数量(quorum)的选举，他就声明获选。获选的server会行使leader角色，否则他变成follower，连接当前的leader节点，一旦连接上后，必须接收完来自leader的同步信息，他才能开始处理请求</p><ol><li><p>下边展示了一个“正常“的leader选举过程：</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/leader_elect.svg" title="Zookeeper Leader选举"></p></li><li><p>下边这个因为网络延迟，造成的一个“非正常”选举过程</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/msg_delay.svg" title="Zookeeper 选举中的消息延迟"></p></li><li><p>如果S2稍微等待长一些的话，就可以一次选成功，省去中间的“无用功”<br>zookeeper设置了一个固定长度的时间200ms，节点必须等待这么长时间才能进行选举，这个时间远远大于正常情况下的网络之间的延迟</p></li></ol><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/elect_delay.svg" title="延迟等待"></p><h2 id="Zookeeper中事务的提交"><a href="#Zookeeper中事务的提交" class="headerlink" title="Zookeeper中事务的提交"></a><a href="#Zookeeper%E4%B8%AD%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%8F%90%E4%BA%A4" title="Zookeeper中事务的提交"></a>Zookeeper中事务的提交</h2><h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a><a href="#%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B" title="基本流程"></a>基本流程</h3><p>Follower在接受到写请求后，会将请求转发给集群leader，leader会将请求转换成事务，在集群内进行提交和广播，当然这需要一个协调过程。过程中，leader和follower之间的交互，使用的是zab协议。</p><p>假设现在有一个正常的集群，集群有一个leader，ZAB提交一个事务的过程如下:</p><ol><li>leader发送一个proposal消息p，给所有的followers</li><li>收到消息p后，follower返回leader一个ack，告诉leader，他已经接受了这个协议</li><li>如果leader收到了仲裁数量的ack，则通知followers提交commit这个事务</li></ol><p>如下图所示:</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/zk_transaction.svg" title="ZooKeeper中的事务"></p><p>第二步时，follower需要检查这个proposal是否来自于leader，而且ack和commit事务必须按照leader广播的顺序。</p><h3 id="事务日志和快照"><a href="#事务日志和快照" class="headerlink" title="事务日志和快照"></a><a href="#%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E5%92%8C%E5%BF%AB%E7%85%A7" title="事务日志和快照"></a>事务日志和快照</h3><p>Zookeeper在运行中，会生成两个文件，一个是事务log文件，一个是snapShot快照文件。事务log文件是zookeeper在接收事务的proposal时，记录在磁盘上的append only文件，snapShot文件是zookeeper内存数据库的快照文件。snapShot文件会频繁生成，但是server是一直运行状态的，而且在生成快照时，还会有新的事务进来，所以在某一刻，快照和zookeeper的内存数据库并不是完全一样的。不过这没关系，在生成快照时，zookeeper会记录快照开始前的最后一个zxid，当zookeeper server重启时，为了恢复内存数据库，他会载入snapShot时，重新播放(replay)事务log文件来补充快照生成中或生成后，没有记录下的事务。</p><p>为了保障数据的一致性，zookeeper要求follower在接收proposal后必须真实落盘(不能只是写入磁盘缓存disk cache)才能ack，但一个事务一次写盘，显然是不高效的，因此zookeepr在写磁盘时使用了group commit和padding的方式写盘，多条事务只有一次写盘操作。</p><h2 id="ZAB协议对消息顺序和消息不丢失的保障"><a href="#ZAB协议对消息顺序和消息不丢失的保障" class="headerlink" title="ZAB协议对消息顺序和消息不丢失的保障"></a><a href="#ZAB%E5%8D%8F%E8%AE%AE%E5%AF%B9%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E5%92%8C%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84%E4%BF%9D%E9%9A%9C" title="ZAB协议对消息顺序和消息不丢失的保障"></a>ZAB协议对消息顺序和消息不丢失的保障</h2><p>ZAB 保障了一些重要的原则:</p><ol><li><p>如果leader广播事务时是先T后T’，那么每个server必须先commit T后再commit T’.</p></li><li><p>如果有一个server提交事务是按照T/T’顺序,那么其他所有的server必须先提交T，后提交T’.</p></li></ol><p><strong>第一条原则保障了事务是按相同的顺序投递到其他server的(保序)，第二条原则保障了任一server不跳过事务(不丢失消息)。</strong></p><p>Zookeeper使用Tcp协议在Server之间通信，保证了消息的严格有序(FIFO)。同时，所有的请求都会按顺序先发给Leader，Leader使用两阶段提交方式来处理(先Propose和后Commit)，在commit之前，必须拥有足够仲裁数量的机器先接受消息，在接收消息后，follower会将消息存储在磁盘上(以zxid形式append Log)，这保障了事务的严格有序。</p><p>在实现ZAB广播协议里，最难的是处理双leader，比如老的leader发送的心跳延迟或丢失，都会造成follower认为leader已经宕机，促使他们选举一个新的leader。双leader会造成server提交事务时顺序发生变化，或者跳过事务。</p><p>要解决这个问题，ZAB保障:</p><ol><li>一个获选的leader一定要commit所有最终会被提交的事务，在广播新时代事务之前。</li><li>任何时候，不会有两个server都拥有仲裁数量的支持者</li></ol><p>为了保障第一条，一个当选的leader不会行使职权，直到仲裁数量server对他的初始状态达成一致，这个过程称之为同步(Synchronization)。 初始状态必须包含所有之前已经提交的事务，而且也包含之前最终会被commit但是还未commit的事务。为了保障第二条，是使用了一个技巧，就是两次形成的仲裁必定都包含同一个server。下图说明了这两点：</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/leader_trans.svg" title="leader切换"></p><ol><li>Server 3就是两次仲裁的交叉Server，原集群有他，新的leader的集群也有他</li><li>发生切主前，形成仲裁数量的Server是Server(1-5)。发生切主后仲裁数量的server是1-3(3&gt;5/2)，他们支持Server 3，但Server 5已经没有足够数量的仲裁Server支持他了，只有Server 4和他本身。</li><li>在Server 1-3之间发生leader选举时，因为Server 3多接受了一个事务(1,1)，所以的他的 zxid会比其他两个Server大，所以他必定会别选取为Leader。Server 3被Server 2和Server1 选取为leader后，形成一个法定人数仲裁群(quorum)，之后新的仲裁群会忽略掉原集群leader的所有消息。</li><li>事务&lt;1,1&gt;被Server 3和Server 4接收到，并返回了Ack，和Server5 自身ack自己，促成了一个多数(quorum)Ack，所以事务&lt;1,1&gt;最终应该被提交。在新的Leader集群里，事务&lt;1,1&gt;在Server 3上有记录，server 3会最终提交这个事务。</li><li>如果事务&lt;1,1&gt;在leader(Server 5)宕机前，proposal没有广播到达具有法定人数的servers上，那么这个条事务有可能最终被提交，也有可能被丢失，取决于广播到的server是否会参与新的leader选举。但这条事务因为没有达到法定人数的ack，所以leader还是返回给客户端请求处理失败的，防止客户端丢失这条消息。</li></ol><p>在时代交替时，如果follower和leader的事务差异不大，leader是可以发差异化事务包给follower补齐。如果差异很大，那么leader就会发整个snapShot给follower，这会加大集群恢复的时间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><a href="#%E6%80%BB%E7%BB%93" title="总结"></a>总结</h2><h3 id="ZAB优势"><a href="#ZAB优势" class="headerlink" title="ZAB优势"></a><a href="#ZAB%E4%BC%98%E5%8A%BF" title="ZAB优势"></a>ZAB优势</h3><p>从整个zookeeper全局来看，ZAB保证了以下2个特性:</p><ol><li>可靠的消息投递<br>如果一个消息被投递到一个server，那么其他server最终也将会有这条消息。相比Paxos，消息被投递到一个Server后，因为系统之间延时等问题，有可能丢失掉。</li><li>完全有序<br>如果client投递a,b两条消息按a先于b的顺序，那么所有server收到的消息顺序同样也是a先于b.</li></ol><p>依靠这两个特性,zookeeper能保障整个集群中状态的一致性。</p><h3 id="ZAB问题"><a href="#ZAB问题" class="headerlink" title="ZAB问题"></a><a href="#ZAB%E9%97%AE%E9%A2%98" title="ZAB问题"></a>ZAB问题</h3><ol><li>从客户端看到的不一致问题<br>因为在广播commit的阶段，leader和各follower之间有网络延迟，到达follower时先后时间点是不一样的，这就注定了有些follower是比其他更快的读取到最新的数据。</li><li>一个client两个链接，造成的消息不守序<br>在一个client端建立一条跟zookeeper的链接时，消息按严格有序的方式投递到leader，并且按照严格的顺序被广播给各follower。但如果一个客户端机器建立两个链接时，发送给两个链接的消息是不能保序的。</li><li>重复消息投递的可能性<br>在上边ZAB保序的讨论例子里，如果事务&lt;1,1&gt;在leader宕机前没有被commit，而且接收到proposal的follower也不确定是哪几台，那么新的leader选举时，包含新proposal日志的server不一定参与集群选举，如果参与的话，该条日志就会最终被zookeeper集群commit，如果没有参与，那么这条事务就丢失了。虽然这两种情况，都是在client端确定本次请求失败时发生的，但前者在server端该条事务确实被记录下来了，如果client补发他认为“失败”的这条事务，那么这条请求是被重复投递了。</li></ol><p>但在zookeeper集群内部来看，通过使用ZAB，能保障所有的客户端能观察到所有的数据更新事件，每个server都不会遗漏一个事件，而且是按一致的顺序来执行。但不一定是在同一时刻都看到相同的事件执行状态(因为上边所说的第一条原因)。</p><h2 id="ZooKeeper的吞吐量测试"><a href="#ZooKeeper的吞吐量测试" class="headerlink" title="ZooKeeper的吞吐量测试"></a><a href="#ZooKeeper%E7%9A%84%E5%90%9E%E5%90%90%E9%87%8F%E6%B5%8B%E8%AF%95" title="ZooKeeper的吞吐量测试"></a>ZooKeeper的吞吐量测试</h2><p>下图是一个性能测试，消息大小是1024个字节，竖轴是吞吐量，横轴是一个zookeeper集群的个数。<br>机器配置: 双cpu，4核处理器 Xeon 2.5GH，16G RAM, 1T SATA disk.</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%BA%8C-ZooKeeper-ZAB%E5%8D%8F%E8%AE%AE/benchmark.png" title="Zookeeper性能测试"></p><h3 id="图中曲线说明"><a href="#图中曲线说明" class="headerlink" title="图中曲线说明:"></a><a href="#%E5%9B%BE%E4%B8%AD%E6%9B%B2%E7%BA%BF%E8%AF%B4%E6%98%8E" title="图中曲线说明:"></a>图中曲线说明:</h3><ol><li>Net only: 不落盘，只有网络处理</li><li>Net+Disk: 网络请求处理，增加落盘写事务log文件</li><li>Net+Disk(no write cache): 网络请求处理</li><li>Net cap: 理论纯网卡测试网络吞吐量</li></ol><p>从图中可以看到：</p><ol><li>在disk cache被关闭后，zookeeper变成IO bound了</li><li>随着集群机器数量的增加，ops也开始降低，因为受限于leader的网卡瓶颈，leader需要复制数据到其他机器(follower或observer)。</li></ol><p>参考:</p><ol><li>ZooKeeper: Distributed Process Coordination /Flavio Junqueira and Benjamin Reed 2013</li><li><a href="https://www.semanticscholar.org/paper/Zab%3A-High-performance-broadcast-for-primary-backup-Junqueira-Reed/b02c6b00bd5dbdbd951fddb00b906c82fa80f0b3">https://www.semanticscholar.org/paper/Zab%3A-High-performance-broadcast-for-primary-backup-Junqueira-Reed/b02c6b00bd5dbdbd951fddb00b906c82fa80f0b3</a></li><li><a href="https://dl.acm.org/doi/10.1145/1529974.1529978">https://dl.acm.org/doi/10.1145/1529974.1529978</a></li></ol>]]></content>
    
    
    <summary type="html">一致性算法是分布式系统中的一个重要算法，是分布式数据库、Kafka、Zookeeper的基本协议。但这些协议晦涩难懂，对初学者需要耗费大量时间研究，本系列文章，是对一致性算法的一个大 搜底和总览，通过对paper和技术资料的阅读，总结出一个简单易懂的学习材料，供其他人方便理解和学习。</summary>
    
    
    
    <category term="分布式技术" scheme="https://www.wangjunfei.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="kafka" scheme="https://www.wangjunfei.com/tags/kafka/"/>
    
    <category term="分布式技术" scheme="https://www.wangjunfei.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"/>
    
    <category term="zookeeper" scheme="https://www.wangjunfei.com/tags/zookeeper/"/>
    
    <category term="consensus algorithm" scheme="https://www.wangjunfei.com/tags/consensus-algorithm/"/>
    
    <category term="zab" scheme="https://www.wangjunfei.com/tags/zab/"/>
    
    <category term="分布式协议" scheme="https://www.wangjunfei.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>一致性算法研究(一)Paxos</title>
    <link href="https://www.wangjunfei.com/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/"/>
    <id>https://www.wangjunfei.com/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/</id>
    <published>2020-02-26T13:35:30.000Z</published>
    <updated>2022-02-11T04:01:59.770Z</updated>
    
    <content type="html"><![CDATA[<p> <span class="github-emoji" style="display:inline;vertical-align:middle"><span>⚠</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 原创文章，转载请注明出处</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><a href="#%E6%91%98%E8%A6%81" title="摘要"></a>摘要</h2><p>一致性算法是分布式系统中的一个重要算法，是分布式数据库、Kafka、Zookeeper的基本协议。但这些协议晦涩难懂，对初学者需要耗费大量时间研究，本系列文章，是对一致性算法的一个大搜底和总览，通过对paper和技术资料的阅读，总结出一个简单易懂的学习材料，供其他人方便理解和学习。</p><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a><a href="#%E5%85%B3%E9%94%AE%E8%AF%8D" title="关键词"></a>关键词</h2><p>consensus algorithm(一致性算法) 分布式系统 分布式协议 Paxos Raft ZooKeeper ZAB</p><h2 id="共识问题"><a href="#共识问题" class="headerlink" title="共识问题"></a><a href="#%E5%85%B1%E8%AF%86%E9%97%AE%E9%A2%98" title="共识问题"></a>共识问题</h2><p>假如你有多个服务器，想让他们在某件事情上达成一致，这就是共识，共识意思是大家都对某事统一认可的。</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/consensus_problem.svg" title="图片信息描述"></p><p>如上图所示，有5个服务器，每个服务器上有一个processor，这些Processor要对一件事情达成共识。</p><p>共识问题在分布式系统中非常常见，比如多个服务器都有权限访问某个资源，怎么决定让哪个服务器去访问(互斥锁)？同等地位的多个服务器，哪个服务器去做master(leader选举问题)?多个服务器之间，怎么就一些事件的发生顺序达成一致性(有序复制问题)？</p><p>互斥锁和leader选举问题，大家经常使用zookeeper就很容易理解，比如通过抢占临时节点来选举leader,或获取互斥锁。</p><p>有序复制的问题，可以举个例子，比如有几台服务器组成的集群，这个集群提供读和写服务。客户端发送写请求，集群服务器能接受写的数据，并且自动复制数据到集群内的其他机器上，当某台机器宕机后，可以保持集群高可用，类似kafka集群.同时集群内每台服务器都可以提供读请求，以使整个集群提供高并发读服务。为了让集群正常工作，所有服务器必须将接收到的写请求能同步给其他服务器，实现所有服务器读一致性。</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/replicate_stat_ma.svg" title="复制状态机"></p><p>通常有两个方法达到这个目的：第一，集中所有写请求到其中的一台，这台机器作为协调器，他会保障所有的写请求按顺序的复制给其他服务器。</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/leader_cord.svg" title="leader协调"></p><p>第二，把所有的写请求发送给一个系统，这个系统协调所有的写请求落盘并且按顺序同步给其他服务器。</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/run_cons_p.svg" title="运行一致性算法"></p><p>第一种方法其实是通过共识算法选取一个leader，leader来处理和协调所有的写请求，第二种方法是运行一个共识算法系统，通过运行共识算法来确保所有机器按一定的顺序来记录客户端的写请求。</p><p>所以，共识算法用一句话来总结: 一个或多个系统提议一个或多个值(或议案)，怎么让所有的服务器对选取哪个值(或议案)达成一致。</p><h2 id="一致性算法里的一些概念"><a href="#一致性算法里的一些概念" class="headerlink" title="一致性算法里的一些概念"></a><a href="#%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E9%87%8C%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5" title="一致性算法里的一些概念"></a>一致性算法里的一些概念</h2><ol><li>议案、值(Value)</li><li>提议(Propose)</li><li>选取(choose/decide)</li><li>进程(processor):代表共识算法里的一个参与方，实际意义是参与方服务器上的一个进程</li></ol><h2 id="一致性算法的运行环境"><a href="#一致性算法的运行环境" class="headerlink" title="一致性算法的运行环境"></a><a href="#%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%9A%84%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83" title="一致性算法的运行环境"></a>一致性算法的运行环境</h2><ol><li>Processors<ol><li>processor 运行速度不固定，有些运行快，有些运行慢</li><li>processor 有可能宕机</li><li>拥有存储的 processor 在宕机后，有可能携带状态再次加入协议运行</li><li>processor 不会欺骗、共谋或颠覆一致性算法</li></ol></li><li>网络<ol><li>processor 可以向任何的processor发送消息</li><li>消息发送是异步的，可能需要一定的时间</li><li>消息可能丢失、乱序或重复</li><li>消息在传递过程中不会被破坏掉</li></ol></li><li>processor的数量<ol><li>通常，一个共识算法正常运行，需要n=2F + 1个processor，才能容忍F个processor同时宕机</li></ol></li></ol><h2 id="一致性算法的基本属性"><a href="#一致性算法的基本属性" class="headerlink" title="一致性算法的基本属性"></a><a href="#%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B1%9E%E6%80%A7" title="一致性算法的基本属性"></a>一致性算法的基本属性</h2><ol><li>Validity(有效性): 只有被提议的值才会被选取，不能选取一个未被提议的值.</li><li>Uniform Agreement(一致性): 两个服务器不会选取不同的值</li><li>Integrity: 每个服务器选取值的时候只会选取一次</li><li>Termination: 所有的服务器最终都会选取一个值</li></ol><h2 id="一致性算法-paxos"><a href="#一致性算法-paxos" class="headerlink" title="一致性算法-paxos"></a><a href="#%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95-paxos" title="一致性算法-paxos"></a>一致性算法-paxos</h2><p>paxos 就是一个一致性算法，用来解决上边所说的共识问题，通过运行paxos算法在一个分布式系统之间达成一致性。在这个系统内，客户端可以提交一个或多个值(value)，paxos算法促使整个系统最终选取一个大家都最终认可的值(value)。</p><p>paxos算法分为basic paxos和muti-paxos，一般大家说paxos都指的是basic paxos.Basic paxos运行一次只产生一个值(或议案)，如果需要重复运行的话，就会产生一连串的值，这就变成了muti-paxos.</p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/paxos.svg" title="Paxos"></p><p>paxos将系统中的服务器分为三个角色,在实际运行中，一个processor有可能担任多个角色，者不影响协议的正确运行。</p><ol><li>proposers 议案提出者<ol><li>整个协议的主动方，提出一个提案供大家通过</li><li>处理客户端(client)请求</li></ol></li><li>Acceptors 议案审议者<ol><li>被动方：对proposer的提案做响应</li><li>对proposer的响应代表一次投票</li><li>存储被选中的议案</li></ol></li><li>Learners 议案学习接收者</li></ol><h2 id="paxos运行方式"><a href="#paxos运行方式" class="headerlink" title="paxos运行方式"></a><a href="#paxos%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F" title="paxos运行方式"></a>paxos运行方式</h2><p>客户端(client)发起一个请求给任何一个proposer，proposer和acceptor运行一个两阶段协商，决定最终的选择值。paxos是多数派获胜原则，只要系统中超过50%的人同意，议案就会通过，这个原则保证系统不会出现脑裂的场景。通常，共识算法要求系统里有n=2F+1个参与者，这样的系统能满足F个参与者宕机。</p><p>在详细了解paxos算法之前，我们先来看下如果不使用paxos怎么来达成一致性:</p><p><strong><em>在这个例子里，每个server既是proposer又是acceptor，具有双重角色。</em></strong></p><h3 id="1-使用一个acceptor"><a href="#1-使用一个acceptor" class="headerlink" title="1.使用一个acceptor"></a><a href="#1-%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AAacceptor" title="1.使用一个acceptor"></a>1.使用一个acceptor</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/single_ac.svg" title="Single Acceptor"></p><ol><li>让一个机器来做选择，避免冲突和重复</li><li>存在单点问题，如果机器宕机，则系统无法运行</li><li>解决方法：使用多个acceptor(3,5..等奇数)，多数派原则（2/3，3/5，4/7），只要集群中多数机器选择了值v，那么v就确定为最终选择值,如果一个acceptor宕机，其他acceptor仍能记住这个值v，集群仍然能工作</li></ol><h3 id="改进1-增加多个acceptor"><a href="#改进1-增加多个acceptor" class="headerlink" title="改进1: 增加多个acceptor"></a><a href="#%E6%94%B9%E8%BF%9B1-%E5%A2%9E%E5%8A%A0%E5%A4%9A%E4%B8%AAacceptor" title="改进1: 增加多个acceptor"></a>改进1: 增加多个acceptor</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/split_vote.svg" title="Split Vote"></p><p>1. 多个acceptor，每个server都接受第一个被提议的值，从而达成多数派原则</p><ol start="2"><li><p>产生脑裂，没有一个值是多数派选择的(3/5)，这意味着acceptor必要的时需要更改他所接受的值，而且需要经过多轮投票才能达成一致.（Accepted不是choosen，只有被多数派选择的才成为choosen）</p></li><li><p>改进：Acceptor必须接受多个不同 的值，但最终值选定一个</p></li></ol><h3 id="改进2-Acceptor在多轮投票时，需要更改自己的值"><a href="#改进2-Acceptor在多轮投票时，需要更改自己的值" class="headerlink" title="改进2: Acceptor在多轮投票时，需要更改自己的值"></a><a href="#%E6%94%B9%E8%BF%9B2-Acceptor%E5%9C%A8%E5%A4%9A%E8%BD%AE%E6%8A%95%E7%A5%A8%E6%97%B6%EF%BC%8C%E9%9C%80%E8%A6%81%E6%9B%B4%E6%94%B9%E8%87%AA%E5%B7%B1%E7%9A%84%E5%80%BC" title="改进2: Acceptor在多轮投票时，需要更改自己的值"></a>改进2: Acceptor在多轮投票时，需要更改自己的值</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/conf_choc.svg" title="Conflicting Choices"></p><ol><li>先后接受不同的值，最终会产生冲突</li><li>加强：新的proposer(S5)提议之前必须看看有没有acceptor已经接受了其他server提交过议案，如果有的话，必须放弃自己的议案，提议原有的议案。(必须是个两阶段过程，第一阶段看是否有已经提的议案，第二阶段提自己的议案)</li></ol><h3 id="改进3-proposer提案时看看是否有其他议案已经被接受了"><a href="#改进3-proposer提案时看看是否有其他议案已经被接受了" class="headerlink" title="改进3: proposer提案时看看是否有其他议案已经被接受了"></a><a href="#%E6%94%B9%E8%BF%9B3-proposer%E6%8F%90%E6%A1%88%E6%97%B6%E7%9C%8B%E7%9C%8B%E6%98%AF%E5%90%A6%E6%9C%89%E5%85%B6%E4%BB%96%E8%AE%AE%E6%A1%88%E5%B7%B2%E7%BB%8F%E8%A2%AB%E6%8E%A5%E5%8F%97%E4%BA%86" title="改进3: proposer提案时看看是否有其他议案已经被接受了"></a>改进3: proposer提案时看看是否有其他议案已经被接受了</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/conf_choc2.svg" title="Conflicting Choices"></p><p>1. 一旦整个系统(多数派)已经选中(chosen)一个议案，其他竞争的提议必须退出，S3已经接受了blue的提案，他必须拒绝”red”提案，</p><ol start="2"><li>提案必须有一个顺序，新的提案优于旧的提案，</li></ol><h3 id="改进4-提议必须有一个选后顺序，新的议案优先于旧的提议"><a href="#改进4-提议必须有一个选后顺序，新的议案优先于旧的提议" class="headerlink" title="改进4: 提议必须有一个选后顺序，新的议案优先于旧的提议"></a><a href="#%E6%94%B9%E8%BF%9B4-%E6%8F%90%E8%AE%AE%E5%BF%85%E9%A1%BB%E6%9C%89%E4%B8%80%E4%B8%AA%E9%80%89%E5%90%8E%E9%A1%BA%E5%BA%8F%EF%BC%8C%E6%96%B0%E7%9A%84%E8%AE%AE%E6%A1%88%E4%BC%98%E5%85%88%E4%BA%8E%E6%97%A7%E7%9A%84%E6%8F%90%E8%AE%AE" title="改进4: 提议必须有一个选后顺序，新的议案优先于旧的提议"></a>改进4: 提议必须有一个选后顺序，新的议案优先于旧的提议</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/conf_choc3.svg" title="Conflicting Choices"></p><ol><li>给提议编一个唯一的提议遍号，编号大的提议具有优先权，acceptor在收到编号大的提议时，必须舍弃编号小的提议</li><li>提案者每轮提的提议编号，必须是它所使用过、或见过的最大编号</li></ol><h3 id="改进4-继续"><a href="#改进4-继续" class="headerlink" title="改进4-继续"></a><a href="#%E6%94%B9%E8%BF%9B4-%E7%BB%A7%E7%BB%AD" title="改进4-继续"></a>改进4-继续</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/proposal_num.svg" title="Proposal Number"></p><ol><li>怎么产生一个唯一的编号？使用（提案轮数+serverID)</li><li>每个服务器都存储一个他所见到过的最大轮的议案编号</li><li>每轮提议案时都将此编号增加一下，同时附加上本机的编号</li><li>服务器宕机、或重启时，不能再使用原来的议案编号</li></ol><h3 id="7-总结Paxos是一个两阶段协议"><a href="#7-总结Paxos是一个两阶段协议" class="headerlink" title="7.总结Paxos是一个两阶段协议"></a><a href="#7-%E6%80%BB%E7%BB%93Paxos%E6%98%AF%E4%B8%80%E4%B8%AA%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%8D%8F%E8%AE%AE" title="7.总结Paxos是一个两阶段协议"></a>7.总结Paxos是一个两阶段协议</h3><ol><li>第一阶段: 广播Prepare请求(RPC请求)<ol><li>找到有没有已经被选择(Chosen)的值</li><li>停止老的还未被Chosen的议案</li></ol></li><li>第二阶段:广播Accept提案请求(RPC请求)<ol><li>广播一个议案，让Acceptor接受一个值，让多数派通过这个议案，达到最终选定一个议案</li></ol></li></ol><h3 id="一张图看完整个Paxos运行过程"><a href="#一张图看完整个Paxos运行过程" class="headerlink" title="一张图看完整个Paxos运行过程"></a><a href="#%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%9C%8B%E5%AE%8C%E6%95%B4%E4%B8%AAPaxos%E8%BF%90%E8%A1%8C%E8%BF%87%E7%A8%8B" title="一张图看完整个Paxos运行过程"></a>一张图看完整个Paxos运行过程</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/paxos_one_page.svg" title="Whole Paxos Process In One Page"></p><h2 id="Basic-Paxos-分析-提案之间的竞争"><a href="#Basic-Paxos-分析-提案之间的竞争" class="headerlink" title="Basic Paxos 分析: 提案之间的竞争"></a><a href="#Basic-Paxos-%E5%88%86%E6%9E%90-%E6%8F%90%E6%A1%88%E4%B9%8B%E9%97%B4%E7%9A%84%E7%AB%9E%E4%BA%89" title="Basic Paxos 分析: 提案之间的竞争"></a>Basic Paxos 分析: 提案之间的竞争</h2><h3 id="场景一-老提案已经通过，新提案会找到它，并接收它"><a href="#场景一-老提案已经通过，新提案会找到它，并接收它" class="headerlink" title="场景一: 老提案已经通过，新提案会找到它，并接收它"></a><a href="#%E5%9C%BA%E6%99%AF%E4%B8%80-%E8%80%81%E6%8F%90%E6%A1%88%E5%B7%B2%E7%BB%8F%E9%80%9A%E8%BF%87%EF%BC%8C%E6%96%B0%E6%8F%90%E6%A1%88%E4%BC%9A%E6%89%BE%E5%88%B0%E5%AE%83%EF%BC%8C%E5%B9%B6%E6%8E%A5%E6%94%B6%E5%AE%83" title="场景一: 老提案已经通过，新提案会找到它，并接收它"></a>场景一: 老提案已经通过，新提案会找到它，并接收它</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/prev_chose.svg" title="Proposal Number"></p><h3 id="场景二-老提案还未完全被接受，新提案看到了，并开始使用它，两个proposer都会成功"><a href="#场景二-老提案还未完全被接受，新提案看到了，并开始使用它，两个proposer都会成功" class="headerlink" title="场景二: 老提案还未完全被接受，新提案看到了，并开始使用它，两个proposer都会成功"></a><a href="#%E5%9C%BA%E6%99%AF%E4%BA%8C-%E8%80%81%E6%8F%90%E6%A1%88%E8%BF%98%E6%9C%AA%E5%AE%8C%E5%85%A8%E8%A2%AB%E6%8E%A5%E5%8F%97%EF%BC%8C%E6%96%B0%E6%8F%90%E6%A1%88%E7%9C%8B%E5%88%B0%E4%BA%86%EF%BC%8C%E5%B9%B6%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8%E5%AE%83%EF%BC%8C%E4%B8%A4%E4%B8%AAproposer%E9%83%BD%E4%BC%9A%E6%88%90%E5%8A%9F" title="场景二: 老提案还未完全被接受，新提案看到了，并开始使用它，两个proposer都会成功"></a>场景二: 老提案还未完全被接受，新提案看到了，并开始使用它，两个proposer都会成功</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/new_see.svg" title="Proposal Number"></p><h3 id="场景三-老提案还未完全被接受，新提案没找到它：老提案被block，新proposer用它自己的议案"><a href="#场景三-老提案还未完全被接受，新提案没找到它：老提案被block，新proposer用它自己的议案" class="headerlink" title="场景三: 老提案还未完全被接受，新提案没找到它：老提案被block，新proposer用它自己的议案"></a><a href="#%E5%9C%BA%E6%99%AF%E4%B8%89-%E8%80%81%E6%8F%90%E6%A1%88%E8%BF%98%E6%9C%AA%E5%AE%8C%E5%85%A8%E8%A2%AB%E6%8E%A5%E5%8F%97%EF%BC%8C%E6%96%B0%E6%8F%90%E6%A1%88%E6%B2%A1%E6%89%BE%E5%88%B0%E5%AE%83%EF%BC%9A%E8%80%81%E6%8F%90%E6%A1%88%E8%A2%ABblock%EF%BC%8C%E6%96%B0proposer%E7%94%A8%E5%AE%83%E8%87%AA%E5%B7%B1%E7%9A%84%E8%AE%AE%E6%A1%88" title="场景三: 老提案还未完全被接受，新提案没找到它：老提案被block，新proposer用它自己的议案"></a>场景三: 老提案还未完全被接受，新提案没找到它：老提案被block，新proposer用它自己的议案</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/lost_prev.svg" title="Proposal Number"></p><h3 id="场景四-两个竞争型的议案，甚至可以产生活锁"><a href="#场景四-两个竞争型的议案，甚至可以产生活锁" class="headerlink" title="场景四: 两个竞争型的议案，甚至可以产生活锁"></a><a href="#%E5%9C%BA%E6%99%AF%E5%9B%9B-%E4%B8%A4%E4%B8%AA%E7%AB%9E%E4%BA%89%E5%9E%8B%E7%9A%84%E8%AE%AE%E6%A1%88%EF%BC%8C%E7%94%9A%E8%87%B3%E5%8F%AF%E4%BB%A5%E4%BA%A7%E7%94%9F%E6%B4%BB%E9%94%81" title="场景四: 两个竞争型的议案，甚至可以产生活锁"></a>场景四: 两个竞争型的议案，甚至可以产生活锁</h3><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/live_lock.svg" title="Proposal Number"></p><p>解决方法：1. proposer在重新提案之前，可以等待一个随机时间，给其他proposer完成accept的机会2. Muti-Paxos可以选择一个leader，省去第一阶段，直接进入accept阶段</p><h2 id="Basic-Paxos-其他要点"><a href="#Basic-Paxos-其他要点" class="headerlink" title="Basic Paxos 其他要点"></a><a href="#Basic-Paxos-%E5%85%B6%E4%BB%96%E8%A6%81%E7%82%B9" title="Basic Paxos 其他要点"></a>Basic Paxos 其他要点</h2><ol><li>只有提案者(proposer)知道哪个议案通过了</li><li>如果其他的server需要知道，他们必须自己提一个议案来运行一次paxos，才能知道</li></ol><h2 id="Basic-Paxos-容灾"><a href="#Basic-Paxos-容灾" class="headerlink" title="Basic Paxos 容灾"></a><a href="#Basic-Paxos-%E5%AE%B9%E7%81%BE" title="Basic Paxos 容灾"></a>Basic Paxos 容灾</h2><p>Proposer、Acceptor在不同的时间宕机  </p><p><img src="/2020/02/26/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6-%E4%B8%80-Paxos/ha.svg" title="Proposal Number"></p><ol><li>Proposer在提案之前宕机了<ol><li>任何事情也没做，相当于什么事情也没发生</li></ol></li><li>Proposer在Prepare之后宕机了<ol><li>acceptor接收到prepare消息，没有收到后续的accept请求，其他的proposer可以运行更高编号的提案继续下去</li><li>如果proposer在acceptor接收accept的过程中宕机了，那么只要有一个acceptor接收到了，后续的proposer看到后，会将这个提案继续下去，参照上边的场景二。如果没看到，就会miss掉，老的提案被block，新提案获得通过，参照场景三。</li></ol></li><li>Acceptor在Accept之前宕机了<br>只要集群内存在多数派的accetpor，整个系统就能运行下去</li><li>Accetpor在Accept之后宕机了<br>只要集群内存在多数派的accetpor，整个系统就能运行下去</li></ol><h2 id="参考-Basic-Paxos-详细运行过程"><a href="#参考-Basic-Paxos-详细运行过程" class="headerlink" title="参考: Basic Paxos 详细运行过程"></a><a href="#%E5%8F%82%E8%80%83-Basic-Paxos-%E8%AF%A6%E7%BB%86%E8%BF%90%E8%A1%8C%E8%BF%87%E7%A8%8B" title="参考: Basic Paxos 详细运行过程"></a>参考: Basic Paxos 详细运行过程</h2><p>完整的协议运行过程，可以总结为两阶段和3p1a：</p><h3 id="一阶段a-Proposer-PREPARE"><a href="#一阶段a-Proposer-PREPARE" class="headerlink" title="一阶段a: Proposer (PREPARE)"></a><a href="#%E4%B8%80%E9%98%B6%E6%AE%B5a-Proposer-PREPARE" title="一阶段a: Proposer (PREPARE)"></a>一阶段a: Proposer (PREPARE)</h3><p>proposer 发出一个prepare消息，消息包含一个值，这个值对于这个proposer来说是唯一的,不重复的，每次prepare可以递增来保证唯一</p><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ID</span> = cnt++;  </span><br><span class="line"><span class="attribute">send</span> PREPARE(ID)  </span><br></pre></td></tr></tbody></table></figure><h3 id="一阶段b-Acceptor-PROMISE"><a href="#一阶段b-Acceptor-PROMISE" class="headerlink" title="一阶段b: Acceptor (PROMISE)"></a><a href="#%E4%B8%80%E9%98%B6%E6%AE%B5b-Acceptor-PROMISE" title="一阶段b: Acceptor (PROMISE)"></a>一阶段b: Acceptor (PROMISE)</h3><p>acceptor在收到prepare message后的处理逻辑</p><figure class="highlight sqf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ID &lt;= <span class="built_in">max</span>\<span class="variable">_id</span>)  </span><br><span class="line"> <span class="keyword">do</span> <span class="built_in">not</span> respond (<span class="built_in">or</span> respond <span class="keyword">with</span> a <span class="string">"fail"</span> message)  </span><br><span class="line"><span class="keyword">else</span>  </span><br><span class="line"> <span class="built_in">max</span>\<span class="variable">_id</span> \= ID     <span class="comment">// 存储目前我见到的最大的ID  </span></span><br><span class="line"> <span class="keyword">if</span> (proposal\<span class="variable">_accepted</span> == <span class="literal">true</span>) <span class="comment">// 是否之前已经接受了某个值？  </span></span><br><span class="line"> respond: PROMISE(ID, accepted\<span class="variable">_ID</span>, accepted\<span class="variable">_VALUE</span>)  </span><br><span class="line"> <span class="keyword">else</span>  </span><br><span class="line"> respond: PROMISE(ID)  </span><br></pre></td></tr></tbody></table></figure><h3 id="二阶段a-Proposer-PROPOSE"><a href="#二阶段a-Proposer-PROPOSE" class="headerlink" title="二阶段a: Proposer (PROPOSE)"></a><a href="#%E4%BA%8C%E9%98%B6%E6%AE%B5a-Proposer-PROPOSE" title="二阶段a: Proposer (PROPOSE)"></a>二阶段a: Proposer (PROPOSE)</h3><p>Proposer检查所有acceptor的响应，检查之前是否有已经被接受(accepted)的值，<br>我(Proposer)是否接收到多数acceptor的promise响应？</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> yes  </span><br><span class="line"><span class="built_in">do</span> <span class="keyword">any</span> responses contain accepted values (<span class="built_in">from</span> other proposals)?  </span><br><span class="line"><span class="keyword">if</span> yes  </span><br><span class="line">val = accepted\_VALUE   <span class="comment"> // 改变议案为某个acceptor之前已经接受的议案  </span></span><br><span class="line"><span class="keyword">if</span> no  </span><br><span class="line">val = VALUE    <span class="comment"> // 可以使用原有的议案  </span></span><br><span class="line"><span class="built_in">send</span> PROPOSE(ID, val) <span class="built_in">to</span> <span class="keyword">at</span> least <span class="keyword">a</span> majority <span class="keyword">of</span> acceptors  </span><br></pre></td></tr></tbody></table></figure><h3 id="二阶段b-Acceptor-ACCEPT"><a href="#二阶段b-Acceptor-ACCEPT" class="headerlink" title="二阶段b: Acceptor (ACCEPT)"></a><a href="#%E4%BA%8C%E9%98%B6%E6%AE%B5b-Acceptor-ACCEPT" title="二阶段b: Acceptor (ACCEPT)"></a>二阶段b: Acceptor (ACCEPT)</h3><p>每个acceptor接收到一个从Proposer发来的 PROPOSE(ID, VALUE)请求，如果这个请求的ID是我见过或处理过的最大ID，那么我就接受这个值(议案)，同时返回这个议案给proposer和所有的learner.</p><figure class="highlight sqf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ID &gt;= <span class="built_in">max</span>\<span class="variable">_id</span>)  <span class="comment">// 这是我见过的最大ID么?  </span></span><br><span class="line"> proposal\<span class="variable">_accepted</span> = <span class="literal">true</span>     <span class="comment">// 记录下来，我们接受了一个议案  </span></span><br><span class="line"> accepted\<span class="variable">_ID</span> = ID             <span class="comment">// 保存提案编号  </span></span><br><span class="line"> accepted\<span class="variable">_VALUE</span> = VALUE       <span class="comment">// 保存议案  </span></span><br><span class="line"> respond: ACCEPTED(ID, VALUE) <span class="keyword">to</span> the proposer <span class="built_in">and</span> all learners  </span><br><span class="line"><span class="keyword">else</span>  </span><br><span class="line"> <span class="keyword">do</span> <span class="built_in">not</span> respond (<span class="built_in">or</span> respond <span class="keyword">with</span> a <span class="string">"fail"</span> message)  </span><br></pre></td></tr></tbody></table></figure><p>如果大多数acceptor都接受了这个值(议案)，那么最终就达成了一致性，选取这个值(议案)</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><a href="#%E5%8F%82%E8%80%83" title="参考"></a>参考</h2><ol><li><a href="https://www.youtube.com/watch?v=JEpsBg0AO6o&amp;t=1931s">Diego Ongaro，2013，Paxos Lecture</a></li><li>Paul Krzyzanowski, 2018, <a href="https://www.cs.rutgers.edu/~pxk/417/notes/paxos.html">https://www.cs.rutgers.edu/~pxk/417/notes/paxos.html</a></li><li>Leslie Lamport, 2011, Paxos Made Simple</li></ol>]]></content>
    
    
    <summary type="html">一致性算法是分布式系统中的一个重要算法，是分布式数据库、Kafka、Zookeeper的基本协议。但这些协议晦涩难懂，对初学者需要耗费大量时间研究，本系列文章，是对一致性算法的一个大搜底和总览，通过对paper和技术资料的阅读，总结出一个简单易懂的学习材料，供其他人方便理解和学习。本章重点来研究下Paxos协议，理解Paxos算法的形成及场景分析。</summary>
    
    
    
    <category term="分布式技术" scheme="https://www.wangjunfei.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="kafka" scheme="https://www.wangjunfei.com/tags/kafka/"/>
    
    <category term="分布式技术" scheme="https://www.wangjunfei.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"/>
    
    <category term="zookeeper" scheme="https://www.wangjunfei.com/tags/zookeeper/"/>
    
    <category term="consensus algorithm" scheme="https://www.wangjunfei.com/tags/consensus-algorithm/"/>
    
    <category term="zab" scheme="https://www.wangjunfei.com/tags/zab/"/>
    
    <category term="分布式协议" scheme="https://www.wangjunfei.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>【转】学渣和学霸的区别</title>
    <link href="https://www.wangjunfei.com/2019/11/22/%E3%80%90%E8%BD%AC%E3%80%91%E5%AD%A6%E6%B8%A3%E5%92%8C%E5%AD%A6%E9%9C%B8%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://www.wangjunfei.com/2019/11/22/%E3%80%90%E8%BD%AC%E3%80%91%E5%AD%A6%E6%B8%A3%E5%92%8C%E5%AD%A6%E9%9C%B8%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2019-11-22T06:44:20.000Z</published>
    <updated>2022-02-11T03:33:37.344Z</updated>
    
    <content type="html"><![CDATA[<p>作者：ZTang<br>链接：<a href="https://www.zhihu.com/question/20985248/answer/27521164">https://www.zhihu.com/question/20985248/answer/27521164</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><p>学渣有两种：一种是愤世嫉俗，反感考试，感觉自己是金子却没被人发现，自己是千里马却没遇上伯乐的青年，或者已经灰心丧气，放弃努力的青年。。这样和学霸基本没有可比性了。当然还有另一种就是</p><p>“伪学霸”，也就是有着当学霸的心，却得不到学霸考的成绩。这种要比第一种学渣要有前途，但是这些伪学霸可能犯了一个大忌，就是用错误地方自我满足的方式代表自己的努力程度，于是有一种自己始终在努力的错觉，但实际上并没有什么实质性的提分效果。具体的错误自满的方式可能有以下几种：</p><p>1、没有明确的任务目标，用“心理满足”代表努力程度——有的“伪学霸”在衡量自己是否“努力”的时候，参考的标准不是自己“该做多少事”，而是“能做多少事”，即心理满足了，做到不想做为止。这些同学往往缺少一个客观尺度的制约——任务目标。于是他们学习的初衷，便成了告诉自己，或者让自己相信“我今天努力学习了”“我今天竭尽全力了”，让自己获得心理上的安慰与满足，而不是真正地按部就班投入到了有计划的学习当中，于是往往觉得自己的学习过程很充实，但其实离应该完成的任务数量，应该学习到的层次还差了很远。比如同学A在背单词的时候，背到困倦时，便以为自己竭尽了全力，并停止了背词；而同学B在背单词的时候，每天要求自己背完2个List为止。一般而言，同学B的成果会更显著，而同学A不但背的慢，还由于用心理满足蒙蔽了事实，误以为自己很努力。毕竟大部分人都是有惰性的，也是易于满足的，如果没有一个目标，或者时间表的制约，就很难维持自己初始的热情，很难完成应完成的任务。</p><p>2、只求寻找经验，不去切身实践，用“经验满足”代表努力程度——一些“伪学霸”有这样一个特点：到处咨询，到处上课，到处寻求好的学习方法，好的单词书，好的参考资料，好的老师等等，于是便以为自己“走上了提分大道”。提到该怎么去做，这些同学往往是烂熟于心，但是没有付出实际行动。也就是说，这些同学始终在做一件事情：寻求经验。把寻求经验的过程误认为是努力的过程，知道的经验多了，自己也就满足了。但是这种同学就好比知道全世界所有的水源，但是不迈出步子打水一样，最后的结果就是两手空空。知道再多的好的方法，不去实践，不去制定计划完成，那么自己的能力积淀终究为零，还会很容易地自我满足，感觉自己一直在“努力”。</p><p>3、浮于表面，不愿深究，用“数量满足”代表努力程度——很多“伪学霸”刷题如流水，背词一本又一本，原著一册又一册，但是始终分数不见起效。主要原因是，这些同学只注重了数量，用足够的数量来告诉自己“我努力了”。比如做了很多题，却没有弄懂自己所做题的错因，甚至会为了加速和凑数，有意避开自己不愿练习的科目，或者对难的题型视而不见。又比如背了很多本单词书，但每一本都只背了一遍，努力多意味着背词数量多。这样的想法是有违学习本质的。学透要比学多更为重要，无论对于考试还是对于知识应用都是如此。</p><p>4、为做出姿态而学习，从未真正投入，用“交代满足”和“虚荣满足”代表努力程度——很多“伪学霸”常常在学习时出现这样一个现象：当家长、老师走近或者相熟的同学走近时，就投入到学习中，翻翻书本，读读单词，当老师或家长离开后，就又开始做与学习无关的事情。长久以来，这些同学在老师和家长的眼里很有可能是一个很用功的同学，但是实际上这个“用功”只是用以满足对长辈的交代或者同龄人间做出“爱学习”的姿态而已，而其本人并未真正投入到了学习当中。这就与一些学神级别的同学的做法恰恰相反，这些同学从不在乎自己学习需要被谁看到，甚至不希望别人看到自己学习，只把学习当成自己的事情。这样就更有助于投入到学习当中。</p><p>5、与积极性低于自己的同学进行比较，用“差距满足”代表努力程度——有的“伪学霸”在学习的时候，往往会和一些学习积极性低于自己的同学进行比较，比如看到那位同学不学习，而自己在学习，于是就产生了“我比他努力”的心态，但是这些“伪学霸”选择了错误的参考系，如果换一个参考对象，与那些整日浸泡在书海中的真学霸相比，那么自己做出的努力就会变得非常渺小。因此，选择的参考系如果比自己的积极性要低，就会让自己产生自己“比常人都努力”的错觉，导致自己跟不上真学霸的进程。</p>]]></content>
    
    
    <summary type="html">学渣有两种：一种是愤世嫉俗，反感考试，感觉自己是金子却没被人发现，自己是千里马却没遇上伯乐的青年，或者已经灰心丧气，放弃努力的青年。。这样和学霸基本没有可比性了。当然还有另一种就是</summary>
    
    
    
    <category term="务虚-交流沟通" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E4%BA%A4%E6%B5%81%E6%B2%9F%E9%80%9A/"/>
    
    
    <category term="务虚" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A/"/>
    
    <category term="协作" scheme="https://www.wangjunfei.com/tags/%E5%8D%8F%E4%BD%9C/"/>
    
    <category term="软素质" scheme="https://www.wangjunfei.com/tags/%E8%BD%AF%E7%B4%A0%E8%B4%A8/"/>
    
  </entry>
  
  <entry>
    <title>【转】跨部门协作</title>
    <link href="https://www.wangjunfei.com/2019/11/18/%E3%80%90%E8%BD%AC%E3%80%91%E8%B7%A8%E9%83%A8%E9%97%A8%E5%8D%8F%E4%BD%9C/"/>
    <id>https://www.wangjunfei.com/2019/11/18/%E3%80%90%E8%BD%AC%E3%80%91%E8%B7%A8%E9%83%A8%E9%97%A8%E5%8D%8F%E4%BD%9C/</id>
    <published>2019-11-18T09:56:24.000Z</published>
    <updated>2022-02-11T03:33:19.243Z</updated>
    
    <content type="html"><![CDATA[<p>职场新人切忌耍小聪明，借势压人，盲目求全。知乎上只要你政治正确就无所畏惧，职场中你的出发点再好，做错事还是要挨骂挨罚，做错人还是要被记恨排挤。反之，如果自己多干点活不推工作，多吃点亏不怕担责，不端很高给人肯定，愿意帮你的人会越来越多。</p><span id="more"></span><p>转自: <a href="https://zhuanlan.zhihu.com/p/27234918">https://zhuanlan.zhihu.com/p/27234918</a></p><p>三个关键步骤，第一步就可以拿60分，第二部可以拿80分，第三部可以拿120分。</p><p>对一般人来说第一步就够了，已经可以解决绝大多数问题。</p><p>一、正确表达需求</p><ol><li><p>了解对方需求。将欲取之，必思与之，任何能够成功争取资源工作方式的逻辑起点都是对方的需求，对方的职位KPI是什么，对方的个人偏好是什么，对方的工作的状态如何，你的需求需要对方的工作时间如何，你能给对方提供什么。这些都搞清楚了，问题就解决了一大半。</p></li><li><p>理解对方难处。协作部门积极推进，很可能因为需要支持的工作很多，或者从他的角度来看这项工作不重要。不要急于打官腔，讲道理，先试着站在对方立场，理解对方的难处。首先理解对方的难处，才可能让对方你倾听你的需求。</p></li><li><p>需求区分优先级。如果所有事情都重要，就说明所有事情都不重要，如果所有事情都是紧急，就说明没有事情紧急。我们了解对方的处境、理解对方的难处，就是为了正确的表达自己的需求优先级，哪些是需要今天做的，哪些是本周，哪些事根本不急，如果空了顺手最，只有尊重对方的工作和时间才会获得别人的尊重。这一点是跨部门协作中最重要的一点，也完全体现了管理者的责任感和领导力。</p></li><li><p>心怀感恩，给予承诺。怀有感恩之心，无论这是否是份内的工作，也无论对方的动机是什么，只要对我提供了帮助，这人情我认，也会在力所能及的情况下进行回馈。</p></li></ol><p>其中最重要的是，第三点。问题中，“需要其他部门提供的支持常常被拖延”，这就是典型的错误表达，如果常常被拖延还没什么大影响，或者说明这项工作不重要，或者说明提出的需求就有问题。</p><p>二、过程跟踪推进</p><ol><li>异常处理，协同推进。约定好定期沟通进展，当出现异常，应该主动站出来协调资源，给予支持。</li><li>及时沟通，调整进度。当自己工作进度或优先级有调整时，应及时沟通协同部门，进行相应调整，保持同步。</li><li>分配工作，不分配责任。对方答应配合工作，不代表我们就可以当做把球扔出去，完全不需要管。要记住，锅还在我们身上。</li></ol><p>我们定期跟踪进度，协助调动资源，同步调整进度，最重要的如果因为各种各样的意外原因最终仍然没有完成任务，我们要站出来承担责任。肩膀硬一点，没有人会愿意和随时扔锅的人共事，别断了自己后路。</p><p>三、给予正向反馈</p><ol><li>过程中给予肯定。无论过程中我们付出多少努力，无论对方付出几分的努力，必须给予完全的认可。</li><li>在公开场合给予肯定。没和我一起共事的人无法评价，但是某某在我的这个项目确实展现了扎实的基本功和对工作的责任感。</li><li>在对方上司和公司高管面前给予肯定。这个项目能做好，某某同事的支持非常重要，其他人我不知道，但是某某确实沟通清晰，效率极高。</li></ol><p>之前在，初入职场的新人，什么行为或者话会让老员工反感？ 说：不要讲道理，要谈感情。</p><p>职场新人切忌耍小聪明，借势压人，盲目求全。知乎上只要你政治正确就无所畏惧，职场中你的出发点再好，做错事还是要挨骂挨罚，做错人还是要被记恨排挤。反之，如果自己多干点活不推工作，多吃点亏不怕担责，不端很高给人肯定，愿意帮你的人会越来越多。</p><p>职场中，有人的路会越走越宽，四处多是相助的贵人；有人的路会越走越窄，满眼都是挡路的高墙。</p><p>你的职场道路会怎么走呢？</p>]]></content>
    
    
    <summary type="html">不怕担责，不断给人肯定，愿意帮你的人会越来越多。</summary>
    
    
    
    <category term="务虚-交流沟通" scheme="https://www.wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E4%BA%A4%E6%B5%81%E6%B2%9F%E9%80%9A/"/>
    
    
    <category term="务虚" scheme="https://www.wangjunfei.com/tags/%E5%8A%A1%E8%99%9A/"/>
    
    <category term="协作" scheme="https://www.wangjunfei.com/tags/%E5%8D%8F%E4%BD%9C/"/>
    
    <category term="软素质" scheme="https://www.wangjunfei.com/tags/%E8%BD%AF%E7%B4%A0%E8%B4%A8/"/>
    
  </entry>
  
</feed>
