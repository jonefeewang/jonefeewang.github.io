<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王军飞的随笔</title>
  
  <subtitle>always be the best</subtitle>
  <link href="https://wangjunfei.com/atom.xml" rel="self"/>
  
  <link href="https://wangjunfei.com/"/>
  <updated>2025-04-14T07:14:28.856Z</updated>
  <id>https://wangjunfei.com/</id>
  
  <author>
    <name>王军飞</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Announcing Stonemq: A high-performance and efficient message queue developed in Rust</title>
    <link href="https://wangjunfei.com/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/"/>
    <id>https://wangjunfei.com/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/</id>
    <published>2025-02-10T04:44:36.000Z</published>
    <updated>2025-04-14T07:14:28.856Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR:"></a><strong>TL;DR:</strong></h2><p>1.<strong>Codebase</strong>: <a href="https://github.com/jonefeewang/stonemq">https://github.com/jonefeewang/stonemq</a>  </p><p>2.<strong>Current Features (v0.1.0)</strong>:  </p><ul><li>Supports single-node message sending and receiving.  </li><li>Implements group consumption functionality.  </li><li>Fully compatible with Kafka’s client-server communication protocol, enabling seamless client-side migration without requiring modifications.</li></ul><p>3.<strong>Goal</strong>:  </p><ul><li>Aims to replace Kafka’s server-side functionality in massive-scale queue cluster.  </li><li>Focused on reducing operational costs while improving efficiency.</li></ul><p>4.<strong>Technology</strong>:  </p><ul><li>Entirely developed in <strong>Rust</strong>.  </li><li>Utilizes <strong>Rust Async</strong> and <strong>Tokio</strong> to achieve high performance, concurrency, and scalability.</li></ul><p>5.<strong>Preliminary Performance Testing</strong>:  </p><ul><li><p><strong>Setup</strong>: The comparison between Kafka 2.6.0 and StoneMQ (v0.1.0) was conducted using Kafka 2.6.0’s built-in client producer benchmark tool. The tests were conducted on an Apple 2023 MacBook Pro (12 CPU cores, 18 GPU cores, 512GB SSD), with both systems operating in <strong>single-node, single-replica mode</strong>. You can reproduce these tests by building the project locally and modifying StoneMQ’s configuration file. For detailed instructions, refer to the project’s <strong>README</strong> file.</p></li><li><p><strong>Results</strong>:  </p><ul><li><p>Kafka’s performance exhibited noticeable fluctuations as the number of partitions increased, while StoneMQ maintained stable performance.  </p></li><li><p><strong>Memory Usage</strong>:  </p><ul><li>Kafka consumed over <strong>400 MB</strong> of memory with 1,000 partitions.  </li><li>StoneMQ used only <strong>44 MB</strong> under the same conditions.</li></ul></li><li><p><strong>Note</strong>: The comparison is not entirely fair, as the test machine lacked dual-disk support. Consequently, StoneMQ’s splitting tasks were not enabled during testing, and queue data was not written to disk.</p><p><img src="/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/2p.svg"><br><img src="/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/10p.svg"><br><img src="/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/100p.svg"><br><img src="/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/1000p.svg"></p></li></ul></li></ul><p>Stonemq aims to outperform Kafka in scenarios with massive-scale queue clusters, delivering enhanced performance and efficiency to achieve cost reduction and operational optimization.</p><p>In use cases involving large clusters with countless queues—particularly in enterprise business services and public cloud services—there can be tens of thousands of partitions and partition leaders. Regardless of whether the queues contain messages, the volume of messages, or the flow rate, the presence or absence of active consumers in each partition poses a significant burden for cluster operators. Partition growth negatively impacts cluster throughput, while node failures or restarts often result in partition leader and controller switching, creating critical operational challenges. Stonemq addresses these inefficiencies.</p><p>Cluster performance should remain consistent regardless of partition growth. Queues with varying traffic volumes need consolidation to enable more efficient message flow—akin to containerized shipping for multiple clients. This is precisely the vision of Stonemq. While solutions like Pulsar utilize journaling for centralized message handling, Stonemq seeks to retain Kafka’s replication , which simplifies and standardizes cluster operation and maintenance.We believe this protocol is both straightforward and highly efficient, forming the backbone of our solution.Additionally, by reusing Kafka’s client-server communication protocol, StoneMQ ensures seamless migration without requiring any changes to the user’s client applications. This approach significantly reduces adoption costs for users, enabling a smooth transition to StoneMQ while retaining the familiar and reliable interface they are accustomed to. </p><h2 id="Why-Another-Message-Queue"><a href="#Why-Another-Message-Queue" class="headerlink" title="Why Another Message Queue?"></a>Why Another Message Queue?</h2><p>Why create a new “wheel”?  </p><p>Apache Kafka and Apache Pulsar are both outstanding message queue solutions, widely adopted by major tech companies. Examples include Mafka (built on Kafka), DDMQ (built on Pulsar), and cloud service providers like Alibaba Cloud and Tencent Cloud (TDMQ), which have developed excellent products based on these technologies.  </p><p>However, based on my years of experience in message queue development (having led the development of Mafka for over 4 years and DDMQ for more than 1 year), as well as my expertise in managing and operating large enterprise clusters (exceeding 4,000 virtual machines or containers) with 99.999% availability, I believe these products are not without significant flaws. It is entirely possible to create a better solution.  </p><p>Kafka’s high throughput and low latency are exceptional. Its distributed design is highly reasonable, and its underlying principles are relatively simple, making it an excellent platform for enterprise-level secondary development. With the integration of auxiliary systems, it’s possible to build highly available enterprise-grade clusters. For a detailed analysis of Kafka’s strengths and weaknesses, you can refer to my earlier blog post on industry research into message queues. Here, I’ll briefly summarize some key points.  </p><h3 id="Pros-of-Kafka"><a href="#Pros-of-Kafka" class="headerlink" title="Pros of Kafka:"></a>Pros of Kafka:</h3><ol><li><p><strong>High Throughput and Low Latency</strong>:<br>Kafka excels in throughput and latency due to its use of sequential file I/O for reading and writing messages. This efficient approach achieves exceptional performance with high speeds and minimal delay.  </p></li><li><p><strong>High Availability and Reliability</strong>:<br>Kafka employs a distributed system with multiple replicas for each partition. In the event of a node failure, a new leader replica is quickly chosen using Zookeeper’s consistency mechanism, ensuring uninterrupted availability (up to n-1 nodes when replicas = n). With settings like ack=-1 and minInsyncIRS &gt;=2, a message is considered sent only when all replicas are updated, maintaining high reliability by ensuring sufficient synchronized replicas at all times.  </p></li><li><p><strong>Simple Scaling and Maintenance</strong>:<br>All machines within the cluster are treated equally, enabling straightforward scaling options. Adding or removing machines can be easily managed by triggering data rebalancing processes.  </p></li><li><p><strong>No Java GC-related Issues</strong>:<br>As Kafka writes message data directly to disk, without storing or caching it in memory, it minimizes Java memory usage. This avoids the common garbage collection (GC) problems encountered with Java-based systems.</p></li></ol><h3 id="Cons-of-Kafka"><a href="#Cons-of-Kafka" class="headerlink" title="Cons of Kafka:"></a>Cons of Kafka:</h3><ol><li><p><strong>System Complexity</strong>:<br>Kafka’s distributed multi-active mechanism introduces complexity, particularly around intra-cluster communication, leader election, partition leader management, topic lifecycle management, and message cleanup. These inter-node RPCs and consistency mechanisms across a complex distributed system create challenges in local data maintenance and pose significant bug risks.</p></li><li><p><strong>Tight Coupling Between Consumers and Partitions</strong>:<br>Kafka enforces a rigid one-to-one relationship between a single consumer and a partition. To increase consumption capacity, you must add more partitions, but this increases partition count, intensifying the cluster’s load and management complexity. This lack of flexibility constrains operational scalability.</p></li><li><p><strong>Dependence on Zookeeper, Increasing Maintenance Costs</strong>:<br>Kafka offloads cluster-wide leader election and consistency management to Zookeeper, necessitating its deployment alongside Kafka. This dependence on an additional component increases system complexity and incurs higher operational and maintenance costs.</p></li></ol><p>In addition to the architectural analysis above, several issues become glaringly apparent when deploying large-scale clusters in real-world production environments:</p><h3 id="Exponential-Growth-of-Partitions-and-Replicas"><a href="#Exponential-Growth-of-Partitions-and-Replicas" class="headerlink" title="Exponential Growth of Partitions and Replicas:"></a>Exponential Growth of Partitions and Replicas:</h3><ol><li><p><strong>Traffic Isolation Leading to Rapid Growth</strong>:<br>To meet business demands, traffic isolation has become a standard requirement in the industry. This often includes isolating environments (e.g., prod, stage, release) or adopting regional/zone-based isolation (commonly termed “set-based” in many companies). A straightforward and efficient way to achieve this is by leveraging queues to simulate separation. However, in a unified company-wide cluster, this requirement is used by various departments, both large and small, leading to exponential proliferation of queues. This queue expansion results in a corresponding increase in partitions, which subsequently causes a multipliers-level surge in replica counts.</p></li><li><p><strong>Consumption Model Leading to Growth</strong>:<br>Kafka’s consumption model enforces that a queue’s partition can only be consumed by a single consumer. When users produce messages using hash keys or when the number of consumers increases, additional partitions must be created to accommodate new consumers. In such scenarios, partition resource consumption does not stem from increased traffic but simply from the growing number of consumers. This tight coupling between the number of consumers and partitions significantly drives up partition counts.</p></li></ol><p>The exponential growth of partitions and replicas leads directly to an increase in the number of fragmented files being written, compounding performance issues. For instance, if a single machine hosts over 3,000 partitions, with three replicas managed, this often approaches 10,000 partitions. This has several critical repercussions:</p><ol><li><p><strong>Disk Random I/O caused by Fragmented Files</strong>:<br>Writing thousands of fragmented files concurrently poses significant challenges. Leader replicas directly influence client-side sending latency as they are written, while follower replica writes—especially with ack=-1 settings—also impact leader latencies. Even during client-side reads (limited to leader replicas), the increased partition count exacerbates random read problems. It’s important to note that even with SSDs, excessive random I/O severely reduces disk performance.  </p></li><li><p><strong>Page Cache Pollution</strong>:<br>This issue is inherent to Kafka and escalates sharply with the growth of replica counts on a single machine. Both reads and writes rely on the page cache, but since page cache size is limited, an increase in fragmented files results in heightened contention for cache resources, degrading performance.  </p></li><li><p><strong>Flush IOPS Costs During Log Segment Rolls</strong>:<br>Even though these fragmented files are not flushed during writes—relying on follower replicas for durability—Kafka performs a flush when log segments are rolled. This flush operation directly consumes IOPS.</p></li></ol><h3 id="Interaction-Between-Large-and-Small-Queues"><a href="#Interaction-Between-Large-and-Small-Queues" class="headerlink" title="Interaction Between Large and Small Queues:"></a>Interaction Between Large and Small Queues:</h3><p>When two queues with dramatically different traffic patterns (e.g., one with 10x or more throughput than the other) coexist, this imbalance becomes problematic. Large queues require more consumers, which further increases the number of partitions and replicas, ultimately impacting the latency and performance of smaller queues.</p><h3 id="Unexpected-Backlogs-and-Reprocessing"><a href="#Unexpected-Backlogs-and-Reprocessing" class="headerlink" title="Unexpected Backlogs and Reprocessing:"></a>Unexpected Backlogs and Reprocessing:</h3><p>This issue typically arises when slow-consuming queues suddenly resume consumption. If the necessary hot data is no longer in the page cache, data must be fetched from disk, consuming significant IOPS. This behavior disrupts the system’s performance and can lead to unexpected delays.</p><h3 id="Poor-Controllability-of-Page-Cache"><a href="#Poor-Controllability-of-Page-Cache" class="headerlink" title="Poor Controllability of Page Cache:"></a>Poor Controllability of Page Cache:</h3><p>Since page cache is managed by the operating system, there is minimal control available to users. Configurations are typically limited to tuning parameters like dirty page ratios or flush intervals, without granular control. Users seeking control over caching must resort to application-side caching. However, Java-based languages (such as Java, Scala, or Groovy) often lack the efficiency of system programming languages like C, C++, or Rust when managing memory caches. This inefficiency can result in complications such as memory leaks or Out of Memory (OOM) errors, further deteriorating system reliability.</p><p>Pulsar is another highly popular message queue product with a large and active community. The advantages and disadvantages of Pulsar’s architectural design have been discussed in detail in my previous blog, and a brief summary is provided below:</p><h3 id="Pros-of-Pulsar"><a href="#Pros-of-Pulsar" class="headerlink" title="Pros of Pulsar:"></a>Pros of Pulsar:</h3><ol><li><p><strong>Reduced Latency from Slow Nodes</strong>:<br>Pulsar allows messages to be stored on the fastest two nodes, avoiding the latency impact caused by slower nodes during writes.</p></li><li><p><strong>Efficient Cluster Scalability</strong>:<br>When new Bookie nodes are added, they can quickly become part of the Qw (quorum write) group to receive messages, enabling rapid cluster expansion.</p></li><li><p><strong>No Risk of Split-Brain</strong>:<br>Since Pulsar’s architecture lacks the concept of a leader, it avoids the risk of split-brain scenarios caused by network partitioning, which Kafka is susceptible to.</p></li></ol><h3 id="Cons-of-Pulsar"><a href="#Cons-of-Pulsar" class="headerlink" title="Cons of Pulsar:"></a>Cons of Pulsar:</h3><ol><li><p><strong>Complex Architecture</strong>:<br>Pulsar’s architecture consists of three components: Pulsar, BookKeeper, and RocksDB. Data is distributed across these components, increasing complexity.</p></li><li><p><strong>Complex Data Storage Model</strong>:<br>The smallest storage unit, a fragment, can have its Qa (quorum acknowledgement) spread across multiple Bookies. This results in a massive number of fragmented and scattered fragments throughout the cluster, making maintenance highly complex. Additionally, reading data requires hopping across multiple machines, leading to lower efficiency.</p></li><li><p><strong>Strong Dependency on Zookeeper</strong>:<br>Metadata such as the relationship between ledgers and fragments and their storage locations is stored in Zookeeper. If a Bookie cannot connect to Zookeeper, it stops accepting writes and restarts to maintain consistency. This means that if several nodes or all nodes lose connection to Zookeeper, or if Zookeeper itself fails, the entire cluster becomes non-operational.  </p></li><li><p><strong>Inefficient Disk Usage</strong>:<br>Unlike Kafka, BookKeeper does not rely on page cache for writes. Instead, it performs group commits with forced disk flushes. During reads, it relies on file indexing for random reads, which results in overall lower disk efficiency.</p></li><li><p><strong>Data Recovery After Node Failure</strong>:<br>When a Bookie node fails, a significant amount of data must still be moved to create new replicas for disaster recovery. While this is similar to Kafka, Pulsar performs better in that incremental data is not at risk. After a single-node failure, Pulsar can quickly form a new replica group, whereas Kafka must redistribute replicas, leaving both incremental and historical data with reduced redundancy until recovery is complete.</p></li></ol><h3 id="Pulsar-Issues-in-Real-World-Production-Environments"><a href="#Pulsar-Issues-in-Real-World-Production-Environments" class="headerlink" title="Pulsar Issues in Real-World Production Environments:"></a>Pulsar Issues in Real-World Production Environments:</h3><ol><li><p><strong>Strong Dependency on Zookeeper</strong>:<br>This has been extensively discussed in my previous blog, “Pulsar and the Problem of Removing Zookeeper”. Pulsar’s reliance on Zookeeper is deeply ingrained in its architecture. To ensure consistency, BookKeeper prevents two clients from writing to the same ledger simultaneously. This consistency is enforced by the client relying on Zookeeper’s global coordination capabilities. This dependency is far stronger than Kafka’s reliance on Zookeeper. In Kafka, consistency is managed by electing a single controller node during initialization, which oversees cluster-wide operations. As long as the controller remains operational, Kafka can temporarily function without Zookeeper (albeit with some minor limitations, such as delayed leaderAndIsr notifications and broker state updates). This makes Kafka’s dependency on Zookeeper much less critical in comparison.</p></li><li><p><strong>Memory Leaks and OOM Issues</strong>:<br>Both Pulsar brokers and BookKeeper heavily rely on in-memory caching to improve message read and write efficiency. Many of these caches use off-heap memory. During machine upgrades or maintenance, even small memory leaks can accumulate over time, causing off-heap memory usage to gradually rise and eventually lead to OOM errors. Identifying these memory leaks and performing upgrades and fixes requires significant effort.</p></li><li><p><strong>Loose Architecture with Multiple Components</strong>:<br>Compared to Kafka, Pulsar’s architecture is far more fragmented and challenging to maintain. Pulsar requires familiarity with multiple systems, including Pulsar Broker, BookKeeper, BookKeeper Client (a critical component), and RocksDB. This increases development costs significantly. Similarly, operational and maintenance costs are higher, as these systems require coordinated upgrades and maintenance. In contrast, Kafka’s single distributed system is far simpler. While Kafka’s distributed design is complex, it is well-structured and easier to follow, resulting in much lower maintenance overhead. By comparison, Kafka feels like a paradise in terms of simplicity and manageability.</p></li></ol><p>So, after all this discussion, is there truly a perfect message queue system that can combine the advantages of these technologies while eliminating their disadvantages? Throughout my years of development and maintenance experience, I have constantly pondered this question: can we do better?  </p><p>Kafka, after version 1.0, shifted its focus towards stream processing, tiered storage, and cloud-native capabilities, yet made very little substantial progress in its core architecture. Similarly, Pulsar has been chasing stream processing and cloud-native trends, while recent efforts have centered on removing its dependency on Zookeeper. These directions, however, are driven by market and capital pressures. But does this mean the architectural evolution of message queue systems has already reached its limit?  </p><p>It was with this question in mind that the idea for <strong>StoneMQ</strong> was born.</p><h2 id="Conceptual-Design"><a href="#Conceptual-Design" class="headerlink" title="Conceptual Design"></a>Conceptual Design</h2><p> The primary architecture is outlined in the diagram below:  </p><p><img src="/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/concept.jpg"></p><p>The entire system is designed with a <strong>read-write separation</strong> architecture. As shown in the diagram, it is a distributed system consisting of multiple brokers (e.g., broker1, broker2, broker3). Each broker contains two disks: <code>/disk1</code> (write disk) and <code>/disk2</code> (read disk).  </p><p>On the write disk (<code>/disk1</code>), partitions such as <code>wq1</code> (write queue 1), <code>wq2</code>, and <code>wq3</code> are hosted. For instance, <code>wq1_r1</code> is the replica of <code>wq1</code> on broker2, and <code>wq1_r2</code> is the replica on broker3. Similarly, <code>wq2</code> and <code>wq3</code> follow the same pattern. Primary partitions (leaders) are marked in green, while replicas (followers) are marked in white. Messages are written to the leader partition, and replication works similarly to Kafka, with leader and follower replicas synchronizing data.  </p><p>However, the system limits the total number of partitions to a small, fixed number (e.g., 10 or 20). All queues write their messages into these limited partitions, distributing both write and read responsibilities across all brokers. Writes are concentrated on <code>/disk1</code>, while <code>/disk2</code> is reserved for reads. The write partitions are asynchronously split into physical queues for long-term storage by a background <strong>splitter</strong> process. Periodic checkpoints ensure that split messages are written into actual physical queue files on the read disk, which are rolled based on time or size.  </p><p>The write disk serves as a <strong>short-term storage</strong> layer, facilitating efficient writes and replication between primary and replica partitions. Meanwhile, the read disk functions as the <strong>long-term storage</strong> layer, storing messages in their final physical queues. This separation ensures that writes and replications are optimized for throughput, while reads are handled independently.  </p><h3 id="Key-Design-Inspirations-and-Benefits"><a href="#Key-Design-Inspirations-and-Benefits" class="headerlink" title="Key Design Inspirations and Benefits:"></a>Key Design Inspirations and Benefits:</h3><ol><li><p><strong>Kafka-inspired Write and Replication Mechanism</strong>:<br>By adopting Kafka’s leader-follower replication model, the system ensures high availability and fault tolerance. However, to address Kafka’s scalability challenges caused by excessive partition growth, all queues are consolidated into a limited number of partitions. This reduces the overall partition count in the cluster, significantly improving write and replication throughput.</p></li><li><p><strong>Pulsar-inspired Read-Write Separation</strong>:<br>The system separates read and write operations across two disks. Write operations are concentrated on the write disk (<code>/disk1</code>), while read operations are handled by the read disk (<code>/disk2</code>). This separation eliminates the mutual interference between reads and writes, ensuring that write throughput is unaffected by read operations and vice versa.  </p></li><li><p><strong>Optimized Partition Management</strong>:<br>By consolidating all queues into a small number of partitions for writes, the system avoids the exponential growth of partitions and replicas caused by traffic isolation or consumption model requirements. This design prevents the cluster from being overwhelmed by excessive replica counts, fragmented files, and random I/O issues.</p></li><li><p><strong>Improved Consumer Experience</strong>:<br>On the read disk, messages are split into their respective physical queues, presenting real partitions to consumers. This ensures that consumer read operations (e.g., page cache contention or slow consumer IOPS usage) only impact message consumption, not the write path.</p></li><li><p><strong>Rust Implementation</strong>:<br>To address memory leaks and Java GC-related issues, the entire system is implemented in <strong>Rust</strong>. Rust provides memory safety, prevents common bugs like null pointer dereferences, and eliminates garbage collection overhead. This reduces the system’s memory footprint, freeing up more memory for use as read and write caches.</p></li></ol><h3 id="Why-Rust"><a href="#Why-Rust" class="headerlink" title="Why Rust?"></a>Why Rust?</h3><p>Given the increasing adoption of Rust in modern infrastructure projects (e.g., AWS foundational systems, Google Android team, Microsoft investments, and its inclusion in the Linux kernel), it is clear that Rust is a wise choice for building high-performance, reliable systems. Unlike C/C++, Rust offers memory safety without compromising performance, making it an ideal language for this project. By leveraging Rust, the system minimizes memory-related issues and maximizes resource efficiency, ensuring a robust and scalable message queue system.</p><h2 id="Detailed-Design"><a href="#Detailed-Design" class="headerlink" title="Detailed Design"></a>Detailed Design</h2><h2 id="1-Message-Writing"><a href="#1-Message-Writing" class="headerlink" title="1. Message Writing"></a>1. Message Writing</h2><h3 id="Multi-Machine-Cluster"><a href="#Multi-Machine-Cluster" class="headerlink" title="Multi-Machine Cluster"></a>Multi-Machine Cluster</h3><p><img src="/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/partition_repica.jpg" alt="partition_repica"><br>The cluster consists of multiple machines, typically 5, 10, or more. <strong>Zookeeper</strong> is used for leader election, selecting the <strong>controller</strong> for the cluster and the <strong>leader replicas</strong> for partitions. Metadata is stored in a relational database or a key-value store (KV). Each machine in the cluster maintains the following components:</p><ol><li><p><strong>Two Physical Disks</strong>: </p><ul><li><strong>Write Disk</strong>: Handles all write operations and replication.</li><li><strong>Read Disk</strong>: Stores long-term data and serves consumer read requests.</li></ul></li><li><p><strong>Limited Partitions per Machine</strong>:<br>Each machine hosts 3-5 write partitions, which are replicated across the cluster to ensure fault tolerance.</p></li></ol><h3 id="Design-Principles"><a href="#Design-Principles" class="headerlink" title="Design Principles"></a>Design Principles</h3><ul><li><p><strong>Leverage Kafka’s Replication Protocol</strong>:<br>Kafka’s replication protocol is simple, reliable, and elegantly designed. StoneMQ adopts a similar approach for write replication.</p></li><li><p><strong>Avoid Excessive Complexity</strong>:<br>The underlying architecture of StoneMQ is designed to remain straightforward and maintainable.</p></li></ul><h3 id="Core-Concepts"><a href="#Core-Concepts" class="headerlink" title="Core Concepts"></a>Core Concepts</h3><ol><li><p><strong>Partition and Replica Management</strong>:  </p><ul><li>Each machine hosts <strong>leader partitions</strong> (e.g., <code>a1</code>, <code>a2</code>, <code>b1</code>, <code>b2</code>) and <strong>replica partitions</strong>.  </li><li>Write partitions on the <strong>write disk</strong> replicate data using a protocol similar to Kafka.  </li><li>Read partitions on the <strong>read disk</strong> are managed by a <strong>splitter thread</strong>, which splits write queues into physical queues and restores the original partition and replica structure.</li></ul></li><li><p><strong>Replication and ISR</strong>:  </p><ul><li>The <strong>ISR (In-Sync Replica)</strong> concept is adopted from Kafka to ensure replication consistency.  </li><li>Unlike Kafka, there is no <strong>HW (High Watermark)</strong> concept on the write disk, as it is not used for reads. The splitter process directly reads from the <strong>LEO (Log End Offset)</strong>.</li></ul></li><li><p><strong>Read Disk Synchronization</strong>:  </p><ul><li>The splitter thread processes data at different speeds for primary and replica partitions.  </li><li>During leader failover, if a replica partition has slower splitting speeds, it must ensure that it can still serve the required offsets.  </li><li>When a replica fetches data, it can communicate its splitting progress to determine whether backpressure is needed.</li></ul></li><li><p><strong>Crash Recovery</strong>:  </p><ul><li>After a machine restarts, the <strong>read replica</strong> must synchronize with the primary replica to recover any uncommitted partition files.</li></ul></li><li><p><strong>Partition Distribution</strong>:  </p><ul><li>The number of partitions for a topic should be large enough to evenly distribute write traffic across all machines.  </li><li>StoneMQ avoids the issue of replica explosion on write partitions by consolidating multiple partitions into a limited number of write queues.  </li><li>Even with a high number of real topic partitions, the system efficiently manages replication without excessive overhead.</li></ul></li><li><p><strong>Simplified Write Queue Design</strong>:  </p><ul><li>Write queues do not require <strong>time index</strong> </li><li>The splitting process from write queues to read queues is inspired by Pulsar’s <strong>journal</strong> and <strong>entry log</strong> concept.</li></ul></li></ol><h3 id="Write-and-Split-Process"><a href="#Write-and-Split-Process" class="headerlink" title="Write and Split Process"></a>Write and Split Process</h3><ol><li><p><strong>Write Disk Operations</strong>:  </p><ul><li>Producers send messages to the <strong>write partitions</strong> on the write disk.  </li><li>Messages are replicated to follower replicas using a Kafka-like protocol.  </li><li>The write disk only serves as short-term storage for incoming messages and replication.</li></ul></li><li><p><strong>Splitter Thread</strong>:  </p><ul><li>The splitter thread periodically reads from the write queues on the write disk and splits data into <strong>read partitions</strong> on the read disk.  </li><li>Splitting is asynchronous and checkpointed to ensure fault tolerance.  </li><li>Data is written to physical queue files on the read disk, which are rolled based on time or size.</li></ul></li><li><p><strong>Read Disk Operations</strong>:  </p><ul><li>The read disk serves as long-term storage and handles all consumer read requests.  </li><li>It restores the original partitioning structure of the topic, ensuring that consumers see the expected partition layout.  </li><li>The read disk’s separation ensures that consumer activity does not interfere with write operations.</li></ul></li></ol><h3 id="Advantages-of-the-Design"><a href="#Advantages-of-the-Design" class="headerlink" title="Advantages of the Design"></a>Advantages of the Design</h3><ol><li><strong>Scalable Partition Management</strong>:  <ul><li>By consolidating multiple topic partitions into a limited number of write partitions, the system avoids the performance degradation caused by excessive partition growth, a common issue in Kafka.  </li><li>The actual number of topic partitions can be large without impacting write throughput or replica overhead.</li></ul></li><li><strong>Read-Write Separation</strong>:  <ul><li>Writes are isolated on the write disk, while reads are handled independently on the read disk.  </li><li>This separation ensures that consumer activity (e.g., slow consumers, high IOPS usage) does not affect message ingestion or replication.</li></ul></li><li><strong>Fault Tolerance</strong>:  <ul><li>The ISR mechanism ensures data consistency during replication.  </li><li>Crash recovery mechanisms allow replicas to synchronize and restore uncommitted data after machine restarts.</li></ul></li><li><strong>Efficient Resource Utilization</strong>:  <ul><li>The system avoids replica proliferation by consolidating write partitions.  </li><li>Splitting data into read partitions ensures optimal long-term storage and read performance.</li></ul></li></ol><h3 id="Key-Challenges-and-Solutions"><a href="#Key-Challenges-and-Solutions" class="headerlink" title="Key Challenges and Solutions"></a>Key Challenges and Solutions</h3><ol><li><p><strong>Split Speed Discrepancies Between Primary and Replica Partitions</strong>:  </p><ul><li>During leader failover, slower replica splitting speeds may cause data availability issues.  </li><li>Solution: Replicas communicate their splitting progress, and backpressure mechanisms ensure that consumers do not request unavailable offsets.</li></ul></li><li><p><strong>Crash Recovery for Read Partitions</strong>:  </p><ul><li>Read replicas must recover uncommitted partition files from the primary replica.  </li><li>Solution: Implement efficient synchronization protocols for restoring missing data.</li></ul></li><li><p><strong>Scalability with Large Topic Partition Counts</strong>:  </p><ul><li>While the system consolidates write partitions, it must still handle large numbers of topic partitions for reads.  </li><li>Solution: The read disk restores the original partition layout, ensuring that consumers see the expected structure without impacting write performance.</li></ul></li></ol><p>This design combines the best aspects of Kafka’s replication protocol and Pulsar’s journal-entry log architecture to create a scalable, efficient, and fault-tolerant message queue system.</p><h2 id="2-Crash-Recovery-Design"><a href="#2-Crash-Recovery-Design" class="headerlink" title="2. Crash Recovery Design"></a>2. Crash Recovery Design</h2><p>Crash recovery in StoneMQ is designed to ensure data consistency and minimize data loss while maintaining high performance. The recovery process involves both <strong>journal log</strong> and <strong>queue log</strong> restoration, with mechanisms in place to handle various failure scenarios. Below is the detailed recovery strategy:</p><p><img src="/2025/02/10/Announcing-Stonemq-A-high-performance-and-efficient-message-queue-developed-in-Rust/checkpoints.png"></p><h3 id="1-Leader-Failure-Recovery"><a href="#1-Leader-Failure-Recovery" class="headerlink" title="1. Leader Failure Recovery"></a>1. Leader Failure Recovery</h3><ul><li>When a <strong>leader partition</strong> crashes, one of its <strong>follower replicas</strong> is elected as the new leader using Zookeeper’s election mechanism.</li><li>The new leader takes over write and replication responsibilities, ensuring minimal disruption to the system.</li></ul><h3 id="2-Machine-Crash-Recovery"><a href="#2-Machine-Crash-Recovery" class="headerlink" title="2. Machine Crash Recovery"></a>2. Machine Crash Recovery</h3><p>When a machine crashes and restarts, the recovery process involves the following steps:</p><h4 id="Step-1-Restore-Journal-Log"><a href="#Step-1-Restore-Journal-Log" class="headerlink" title="Step 1: Restore Journal Log"></a>Step 1: Restore Journal Log</h4><ol><li><p><strong>Journal Log Characteristics</strong>:  </p><ul><li>The journal log is a short-term, write-ahead log that uses Kafka’s replication protocol.  </li><li>Due to the dual-write mechanism (at least two replicas), the journal log is highly reliable and unlikely to lose data.</li></ul></li><li><p><strong>Recovery Process</strong>:  </p><ul><li>The journal log recovery point is independent of the queue log and is maintained separately.  </li><li>The system uses the <strong>recovery point</strong> to determine where to resume fetching data from the primary replica.  </li><li>Once the journal log is fully restored, the system proceeds to queue log recovery.</li></ul></li></ol><h4 id="Step-2-Restore-Queue-Log"><a href="#Step-2-Restore-Queue-Log" class="headerlink" title="Step 2: Restore Queue Log"></a>Step 2: Restore Queue Log</h4><ol><li><p><strong>Queue Log Characteristics</strong>:  </p><ul><li>The queue log represents the long-term storage on the read disk.  </li><li>During normal operation, the queue log periodically flushes its data and records the <strong>physical position</strong> in the journal log.</li></ul></li><li><p><strong>Recovery Process</strong>:  </p><ul><li>The recovery point for the queue log is the last recorded physical position in the journal log.  </li><li>The system begins restoring the queue log from this position, ensuring that all data is consistent with the journal log.</li></ul></li></ol><h4 id="Key-Features"><a href="#Key-Features" class="headerlink" title="Key Features:"></a><strong>Key Features</strong>:</h4><ul><li><strong>Dual-Writing Guarantees</strong>:<br>The dual-write mechanism ensures that the journal log is always available for recovery, even if the queue log is partially lost.  </li><li><strong>Separation of Recovery Points</strong>:  <ul><li>Each log (journal and queue) maintains its own recovery point for independent restoration.  </li><li>This modular approach simplifies the recovery process and reduces interdependencies.</li></ul></li></ul><h3 id="3-Handling-Single-Machine-Mode"><a href="#3-Handling-Single-Machine-Mode" class="headerlink" title="3. Handling Single-Machine Mode"></a>3. Handling Single-Machine Mode</h3><p>In single-machine mode, the journal log is more vulnerable to data loss because there are no replicas. To mitigate this risk, the following temporary solution is implemented:</p><ol><li><p><strong>Synchronized Flushing</strong>:  </p><ul><li>Whenever the queue log flushes its data, the journal log is flushed as well.  </li><li>This ensures that the journal log is always consistent with the queue log.</li></ul></li><li><p><strong>Performance Considerations</strong>:  </p><ul><li>This approach is only a temporary solution for single-machine mode. Once dual-machine replication is enabled, the journal log flush frequency returns to normal.  </li><li>In practice, the journal log is already flushed more frequently than the queue log, so the performance impact is minimal.</li></ul></li></ol><h3 id="4-Checkpoint-Management"><a href="#4-Checkpoint-Management" class="headerlink" title="4. Checkpoint Management"></a>4. Checkpoint Management</h3><ol><li><p><strong>Checkpoint Definition</strong>:  </p><ul><li>A <strong>checkpoint</strong> is a record stored at the end of each journal log segment. It maps the physical positions of all corresponding queue logs.  </li><li>Checkpoints are used to synchronize journal and queue log recovery.</li></ul></li><li><p><strong>Queue Log Checkpoints</strong>:  </p><ul><li>Each time the queue log rolls to a new segment, it flushes its data and updates the recovery point.  </li><li>The system periodically persists these recovery points to ensure they are available during crash recovery.</li></ul></li><li><p><strong>Journal Log Checkpoints</strong>:  </p><ul><li>The journal log periodically deletes expired segments based on the <strong>minimum recovery checkpoint</strong> across all queue logs.  </li><li>This ensures that the journal log does not grow indefinitely and only retains relevant data for recovery.</li></ul></li><li><p><strong>Handling Long-Idle Queue Logs</strong>:  </p><ul><li>If a queue log does not roll for an extended period (e.g., no new messages are added), the <strong>checkpoint monitoring thread</strong> periodically forces a roll.  </li><li>This ensures that recovery points remain up-to-date and prevents the journal log from retaining unnecessary data.</li></ul></li></ol><h3 id="5-Summary-of-Recovery-Workflow"><a href="#5-Summary-of-Recovery-Workflow" class="headerlink" title="5. Summary of Recovery Workflow"></a>5. Summary of Recovery Workflow</h3><ol><li><p><strong>Crash Detection</strong>:  </p><ul><li>Upon detecting a machine crash, the system identifies the affected partitions and begins the recovery process.</li></ul></li><li><p><strong>Journal Log Recovery</strong>:  </p><ul><li>Restore the journal log using the replication protocol.  </li><li>Use the journal log recovery point to fetch missing data from the leader replica.</li></ul></li><li><p><strong>Queue Log Recovery</strong>:  </p><ul><li>Restore the queue log by reading from the journal log starting at the last recorded physical position.  </li><li>Synchronize the queue log with the journal log to ensure consistency.</li></ul></li><li><p><strong>Checkpoint Synchronization</strong>:  </p><ul><li>Use checkpoints to align recovery progress between journal and queue logs.  </li><li>Periodically update and persist checkpoints during normal operation to simplify recovery.</li></ul></li></ol><h3 id="6-Advantages-of-the-Design"><a href="#6-Advantages-of-the-Design" class="headerlink" title="6. Advantages of the Design"></a>6. Advantages of the Design</h3><ol><li><p><strong>Fault Tolerance</strong>:  </p><ul><li>The dual-write mechanism ensures that the journal log is always available, even during partial failures.  </li><li>Independent recovery points for journal and queue logs provide modularity and robustness.</li></ul></li><li><p><strong>Minimal Data Loss</strong>:  </p><ul><li>By flushing the queue log and journal log together in single-machine mode, the risk of data loss is minimized.  </li><li>Checkpoints ensure that recovery always starts from a consistent state.</li></ul></li><li><p><strong>Efficient Log Management</strong>:  </p><ul><li>The journal log automatically deletes expired segments based on the minimum recovery checkpoint, preventing unnecessary growth.  </li><li>Idle queue logs are periodically rolled to keep checkpoints up-to-date.</li></ul></li><li><p><strong>Scalability</strong>:  </p><ul><li>The recovery process scales well in multi-machine clusters due to the separation of journal and queue log recovery.  </li><li>Recovery is optimized for both single-machine and multi-machine deployments.</li></ul></li></ol><h3 id="7-Open-Questions-and-Future-Enhancements"><a href="#7-Open-Questions-and-Future-Enhancements" class="headerlink" title="7. Open Questions and Future Enhancements"></a>7. Open Questions and Future Enhancements</h3><ol><li><p><strong>Optimizing Single-Machine Mode</strong>:  </p><ul><li>Explore more efficient ways to handle journal log durability without frequent flushes in single-machine mode.</li></ul></li><li><p><strong>Dynamic Checkpoint Management</strong>:  </p><ul><li>Investigate adaptive checkpointing strategies to balance recovery speed and runtime performance.</li></ul></li><li><p><strong>Enhanced Monitoring</strong>:  </p><ul><li>Implement detailed monitoring and alerting for checkpoint progress, journal log growth, and recovery performance.</li></ul></li></ol><p>This crash recovery design ensures data durability, fault tolerance, and efficient log management, making StoneMQ highly resilient to failures.</p>]]></content>
    
    
    <summary type="html">Announcing Stonemq: A high-performance and efficient message queue developed in Rust</summary>
    
    
    
    
    <category term="Message Queue" scheme="https://wangjunfei.com/tags/Message-Queue/"/>
    
    <category term="Rust" scheme="https://wangjunfei.com/tags/Rust/"/>
    
    <category term="Kafka" scheme="https://wangjunfei.com/tags/Kafka/"/>
    
    <category term="Pulsar" scheme="https://wangjunfei.com/tags/Pulsar/"/>
    
    <category term="StoneMQ" scheme="https://wangjunfei.com/tags/StoneMQ/"/>
    
  </entry>
  
  <entry>
    <title>Apache Pulsar的存储模型</title>
    <link href="https://wangjunfei.com/2023/12/25/Apache-Pulsar%E7%9A%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B/"/>
    <id>https://wangjunfei.com/2023/12/25/Apache-Pulsar%E7%9A%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B/</id>
    <published>2023-12-25T09:13:00.000Z</published>
    <updated>2024-03-24T00:58:30.775Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>Pulsar实际上是三个组件的组合体Apache Pulsar+Apache Bookkeeper+RocksDB。 Bookkeeper是负责消息的存储，Pulsar负责队列和消费的概念模型塑造，RocksDB是Bookkeeper内部用来存储kv索引用的，相关的概念介绍，可以参考下我之前的博客:<a href="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/" title="消息队列业界调研">&lt;&lt;消息队列业界调研&gt;&gt;</a>。本篇来详细分析一下Pulsar的消息存储模型。</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>其实说到底，Pulsar的消息存储最底层就是ledger，这个概念也是Bookkeeper中的概念，ledger由很多小段的segement组成，这些segment在bookkeeper中称之为entry log，所以要彻底说清楚Pulsar的存储，还得由Bookkeeper来说起。entry log是什么？是不同的entry写到一个文件里，这里的entry可以理解为消息，一个entry从属于某一个ledger。所以，反过来说，一个ledger由entry组成，不同的ledger在存储时都写入了一个称为entry log的文件里。</p><p>Bookkeeper本身是一个有限的流式数据存储，这里说的有限是对应与Kafka的无限流式数据存储。kafka中一个log流是有开始没有结束，一个log代表一个topic的一个partition，只要队列有消息，这个流就不会终结，永远存储在这个log文件里(具体文件会滚动，但存储的都是这个partition的消息)。而bookkeeper则不同，它是一个有限的流式存储，一个ledger代表队列的一个partion数据，他有开始也有结束，开始就是有消息生产就有了开始，结束时是当消息的生产者掉线了，死机了，或是生产这主动关闭了，这时就是这个ledger的终点，这时候ledger会被关闭掉，如果下一个生产者继续往这个partition里生产，则需要创建一个新的ledger。在整个ledger的生命周期内，它只有三种状态，open/in_recovery/(fenced)closed，</p><ul><li>open：在正常接收生产的消息数据</li><li>in_recovery: 读取客户端在试图恢复之前未被复制到所有WQ的消息，这时停止接受新的消息数据。</li><li>(fenced)/closed: 恢复完数据后，客户端关闭这个ledger，不再接受任何新的消息数据。</li></ul><p>bookkeeper对生产端有两个严格的要求:</p><ol><li>第一个是任何时间段必须只能由一个客户端在生产，这也就是为什么pulsar里bundle只能被一个broker负责，不能由不同的 broker同时负责，那样就会有两个生产端同时生产了，会产生脑裂，违反了bookkeeper的要求。</li><li>第二个是生产时必须提供一个顺序的entryId，也就是消息Id，这个限制是方便对ledger内的fragment的进行按顺序的消息管理，比如0-100的fragemnt的ensemble是(B1,B2,B3)，100-500的ensemble是(B2,B3,B4)，如果entryId不是顺序产生的，这个fragment是无法归类的，到底哪一段，哪一个范围的entry是哪些ensemble负责的。确定ensemble的信息非常重要，因为消息在读取的时候，需要这个信息，比如要读取entryId是233的消息，有了这个fragment信息，我就知道从哪个bookkeeper机器上读取了。</li></ol><p>再说回到pulsar，因为bookkeeper只提供了ledger这个概念，根本没有消息队列里的topic/group/cursor这些概念，直接拿到pulsar里使用是无法使用的，所以pulsar在ledger的基础之上封装了一次，将topic的partiton封装为一个ledger，在pulsar内部叫做managedLedger，一个partition包含多个ledger，因为上边讲到ledger是一个有限数据流，因为broker死机，或者entry log的size达到上限，都需要结束这个ledger，重新create一个。所以，在puslar里，一个多partiton的topic，每个partition其实是多个ledger组成的，这些信息存储在zk的目录上，具体参考我之前的博客<a href="/2023/06/15/Apache-pulsar%E5%AF%B9zookeeper%E7%9A%84%E4%BE%9D%E8%B5%96%E5%92%8C%E5%8E%BB%E9%99%A4%E5%88%86%E6%9E%90-%E4%B8%80/" title="Apache pulsar对zookeeper的依赖和去除分析(一)">&lt;&lt;Apache pulsar对zookeeper的依赖和去除分析(一)&gt;&gt;</a>。</p><p>所以，pulsar自身并没有存储消息数据，所有的消息数据，都被存放到了bookkeeper上，所有抽象出来的topic/group/cursor元信息内容都被存储到了zk上，它自己本身是无状态的。</p><h1 id="Bookkeeper存储的设计和实现"><a href="#Bookkeeper存储的设计和实现" class="headerlink" title="Bookkeeper存储的设计和实现"></a>Bookkeeper存储的设计和实现</h1><p>bookkeeper生成的物理文件有三种，一个是journal，一个就是entry log，一个是logmark文件</p><ul><li>journal：类似zookeeper中的transaction log，或者是write log，短期存储，，会按照大小分割和滚动,所有ledger发送的消息都会在这里实际落盘后，才会ack客户端成功。</li><li>entry log: 实际存储entry的文件，是一个长期存储，所有的ledger都会写到一个entry文件内部，相同ledger的entry会做排序，方便读取的时候顺序读取相同ledger的entry。(实际内部还有另外一个实现option，每个ledger一个entry log，不过因为ledger很多，这样会产生很多碎文件)</li><li>logmark文件：标注journal文件内一个位置点，比如是哪个journal文件内的哪个offset点。</li></ul><p>每个ledger还有一个masterKey，它是一个ledger的访问口令，在ledger生成时会指定一个，以后ledger的访问都会在请求中校验这个key。</p><h2 id="entry的写入逻辑"><a href="#entry的写入逻辑" class="headerlink" title="entry的写入逻辑"></a>entry的写入逻辑</h2><p>Bookkeeper使用Netty，netty worker thead解析到是addEntry(添加一条消息)请求后，交由write thread pool来处理具体的entry插入。write thread pool是一个ordered Excutor线程池，所谓ordered Executor，意思所有属于同一个ledger的entry 插入都会交由同一个固定的线程去负责执行，以减少乱序和并发。每个ordered thread的任务池大小，以及write thread pool大小都可以在配置文件中设置。由此可见bookkeeper在插入entry时，并没有批量插入的接口，orderedExcutor的固定线程在执行queue中的任务时，虽然是批量获取，执行时仍然是一个一个的执行插入，并没有类似kafka中的批量消息插入。</p><p>ordered executor在执行具体某个ledger的entry插入任务时，分两步进行，第一步是插入EntryLog，第二步是插入Jornal，在jornal插入并刷盘后，再回调entry的插入成功逻辑，ack客户端插入成功。</p><p>插入entryLog时，实际上第一步先插入到WriteCache内，这是一个分段cache，有两个，一个是当前正在被使用的(active)，另一个是当前正在被flush到磁盘上(in_flush)。active的就是平常entry先插入到这里，in_flush的是正在flush WriteCache内的entry到磁盘上，flush完成后这个cache会被清空，等待active的cache插满之后，和它做个交换，以保障正常的插入流程能继续进行，当然如果flush的慢的话，也会形成反压，导致WriteCache的插入被block，进而导致插入请求超时。同时， active 的WriteCache插满之后，会做checkpoint，所谓的checkpoint就是一个时间点，这个时间点会在Journal内做个标记，标记一下Journal最后一次flush 磁盘时插入的entry所在的journal文件id和position，称为LogMark,就是上边讲的log mark文件存储的内容，在WriteCache内的数据被flush到磁盘后，entry log会通知jounal，当前时间点之前的entry已经完全flush到磁盘上了，不需要journal内的数据了，可以将刚才做的checkpoint之前的记录删除掉，腾出磁盘空间。</p><p>由此可见，entry的插入，在Jornal之内是同步插入的，而entrylog则是异步插入的, Jornal保障数据持久化之后，会ack客户端插入成功。entrylog虽然是异步插入，但是可以通过write cache类形成对客户端的反压，block 所有entry的插入请求。Journal有了checkpoint之后，在单台bookkeeper宕机时，因为entry log是异步flush磁盘的，有可能部分entry还未flush而丢失，这时，就可以根据checkpoint从journal内做一次replay，把丢失的entry给找回来。</p><p>entry在插入entry log时，会保留位置信息，也就是所在entry log文件的id，和position，位置信息的key是ledger id+ entry id, value是 entry log文件的id和文件内position组合起来的一个lang值，将这个key value pair保存到rocks db内(或index文件内，见下文)。</p><h3 id="WriteCache的实现原理"><a href="#WriteCache的实现原理" class="headerlink" title="WriteCache的实现原理"></a>WriteCache的实现原理</h3><p>bookkeeper的配置文件内，会设置最大Write Cache大小，每段Cache的段大小，因为在内部，整个缓存区域是被分成段来缓存的，bookkeeper默认设置每段缓存的大小是1G，所以如果总缓存大小是2G的话，每段大小是1个G。<br>使用分段来缓存具有很多优势:</p><ol><li>提高读写速度，因为每段的缓存更小，可以更快的定位entry所在的位置，进行快速读取</li><li>方便并发控制，这个原理跟java语言中的ConcurrentHashMap类似，不再赘述</li><li>还可以减少内存碎片，因为每个小段可以作为整体来分配和回收，整体利用，减少了碎片的形成。</li></ol><p>在写入Cache时，会先计算一个全局offset，设置size大小为align64，就是接近64的最小倍数，防止在CPU L1 Cache产生线程竞争。为什么是64？因为java中Long型的长度是64位，使用Long型来计算Bits码，防止Cache最小段大小超过Long型所能表示的最大值。然后使用Bits码和掩码，快速定位到应该放到哪一段，和段内的offset(这个算法是存储系统经常使用的方法)。</p><p>Cache 内部保存了一个HashMap，是一个(ledgerId,entryId)到(offset,size)的映射，注意这里的offset是全局offset，size是这个entry的大小字节数量。</p><p>读取cache内的某个entry的时候，使用全局offset反算出entry所在的段和位置。</p><h3 id="entry-log文件"><a href="#entry-log文件" class="headerlink" title="entry log文件"></a>entry log文件</h3><p>默认的entry logger 是使用java的文件I/O来写entry log文件，bookkeeper额外提供了使用JNI来写文件的DirectEntryLogger实现，来加快文件写的速度。使用java文件I/O实现的entry logger还有两种方式，一种是将entry log全部写进一个文件中，另外一种是每个ledger一个entry log，前者是默认的。</p><p>entry log文件存储的管理，由bookkeeper内部抽象出来的LedgerStorage来管理，这个接口有3种实现:</p><ol><li><p>InterleavedLedgerStorage 没有使用内存缓存最近插入的entry，entry在写入和读取直接进行文件操作。索引存储使用了多页的jvm直接内存来缓存，缓存的数据是ledger id+ entry id -&gt; entry log id 和 entry log内 position组合成的long型数据</p></li><li><p>SortedLedgerStorage  是InterleavedLedgerStorage的扩展，在它的基础上加了一层最近插入的entry内存缓存，缓存内部使用跳表map来实现，一共两个，一个作为当前在插入的缓存，另外一个作为后台flush entry到文件时使用，flush完成后，缓存清空，等待active的写满之后与它做交换。</p></li><li><p>DbLedgerStrage 使用WriteCache和ReadCache来缓存最近写入的entry和最近读取的entry，索引存储使用rocksDB来做kv存储，所以取名DBLedgerStorage，也是上面两节讲到的entry插入流程中使用到的。每次WriteCache写满之后，触发Journal checkpoint，然后触发ledgerStorage checkpoint， ledgerStoarge checkpoint时会flush数据到磁盘，然后通知checkpoint source自身已完成，这时checkpoint source是Jornal，journal收到通知后，删除旧的journal日志。(DbLedger Storage的set checkpointer()方法是空的，虽然传进来的SyncThread但是没设置，所以在dbledgerStorage内，syncThread并未起到作用。)</p></li></ol><h3 id="journla的写入"><a href="#journla的写入" class="headerlink" title="journla的写入"></a>journla的写入</h3><p>entry交给journal后会暂存在journal的缓冲队列中，交由 journal的专用thread来驱动写入文件，到达一定条件后flush文件到到磁盘上，最后再ack entry的插入操作算成功。jornal触发批量刷盘的条件:</p><ol><li>group commit等待的时间超过了设定的时间 </li><li>缓存的entry数量超过了设定的值</li><li>缓存queue内元素暂时为空<br>当这些条件中的某一个达到时，一般会生成一个forcewrite request，放到force write thread的任务队列里，这个thread会一直运行，只要队列内有请求就会执行flush操作。执行的第一步先flush journal文件到此盘，然后挨个回调被flush 的entry的回调函数，在回调函数内，ack给客户端entry插入成功。</li></ol><p>syncthread<br>这是一条独立运行的thread，他会定期运行，先对ledger storage进行checkpoint，其实就是flush active write cache内的entry到磁盘，，然后通知jornal的,让journal删除checkpoint之前的文件，清理空间。</p><h2 id="entry的读取"><a href="#entry的读取" class="headerlink" title="entry的读取"></a>entry的读取</h2><p>Netty worker thread在解析到是read entry操作时，会交由专门的read thread pool处理读取请求。如果是long poll read会交由专门的long poll thread pool来处理，如果请求的header内包含priority &gt;0，则表示是一条high priority read请求，会交由专门的high priority pool来完成，以保证高优先级任务能顺利完成。<br>entry读取的请求实际上包含了多种请求:</p><figure class="highlight abnf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ReadRequest{</span><br><span class="line">    enum Flag{</span><br><span class="line">        FENCE_LEDGER<span class="operator">=</span><span class="number">1</span><span class="comment">;</span></span><br><span class="line">        ENTRY_PIGGYBACK<span class="operator">=</span><span class="number">2</span><span class="comment">;</span></span><br><span class="line">    }</span><br><span class="line">    Optional Flag flag<span class="operator">=</span><span class="number">100</span><span class="comment">;</span></span><br><span class="line">    required int64 ledgerId<span class="operator">=</span><span class="number">1</span><span class="comment">;</span></span><br><span class="line">    required int64 entryId<span class="operator">=</span><span class="number">2</span><span class="comment">;</span></span><br><span class="line">    optional bytes masterKey<span class="operator">=</span><span class="number">3</span><span class="comment">;</span></span><br><span class="line">    optional int64 previousLAC<span class="operator">=</span><span class="number">4</span><span class="comment">;</span></span><br><span class="line">    optional int64 timeOut<span class="operator">=</span><span class="number">5</span><span class="comment">;</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>1.可以fence一个ledger<br>2.也可以正常读取一个entry<br>3.如果带有previousLAC，则是一个longpoll操作，超时时间是请求里带的超时时间，请求的超时计算使用的是netty自带的hash时间轮</p><p>在读取entry时，ledger storage先从write cache内查找要读取的entry，然后再查找read cache内，最后没有的话会去读取磁盘，将读取到entry添加到read cache 内，并额外顺序读取额外的一批entry到read cache内，此处并未交由异步线程去读取，可能会影响真正需要的entry的读取速度。</p><h3 id="readCache的实现"><a href="#readCache的实现" class="headerlink" title="readCache的实现"></a>readCache的实现</h3><p>read cache的默认大小是jvm可用堆外内存的1/4，额外预读entry大小不会超过read cache的一半，这也是防止一次预读不会占用太多空间。read cache内部也是将可用内存划分为几段来使用，具体优势跟write cache一样，它是一个环形存储，默认使用新的覆盖旧的缓存，这也是因为消息队列的特点，消息顺序消费，默认先淘汰旧的entry。</p><h2 id="ledger的清理"><a href="#ledger的清理" class="headerlink" title="ledger的清理"></a>ledger的清理</h2><p>bookkeeper本身是不带entry清理功能的，你只能主动删除ledger，删除ledger接口内部只会删除保存在zk上ledger的metadata数据，bookkeeper内部有一个GarbageCollector，会定期删除entry log内被删除ledger的实际数据。相对于pulsar来说，pulsar本身增加了队列的保存期限语义，队列被删除、或者保存超期，pulsar会主动调用bookeeper删除ledger。</p><h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><ol><li><p>Pulsar声称自己是原生的存算分离架构，不同于kafka的存储+计算，其实这么一看，也是不得已而为之，因为bookkeeper和pulsar两个组件并不是一起发明的，pulsar只是借用了bookkeeper做存储，自己抽象出了一些消息队列的概念，拼装起来成为一个消息队列，其实质存储实际是靠bookkeeper来完成的。</p></li><li><p>bookkeeper借鉴了LSM tree架构，journal相当于write ahead log， write/read cache类似与借鉴了MemTable，而entry log类似与SSTable，这种结构天然是为了高效写入数据而生。journal和entry log文件的写入，都是大块数据的写入，多个队列掺杂在一起，文件不会因为队列增多，队列partition增多而放大，出现像kafka一样的大量碎片文件，从而降低了集群的写入量。虽然bookkeeper建议双盘配置，journal使用ssd磁盘，entry log使用另外一块磁盘，实际entry log的写入也会反压单机的写入速度，即便journal这时有冗余的iops，也是无可奈何，没办法接收更多的写入请求。</p></li><li><p>journal文件写入使用了group commit来硬刷磁盘， entry log文件的写入轻度使用了page cache，在flush时仍然会被异步刷到磁盘上。不像kafka一样，完全使用page cache，其实这也是kafka无奈之举，天量的topic和partition产生的replica文件的写入，如果都去靠磁盘flush来保障持久性，磁盘IO性能势必会直线下降，只能避免主动flush，交由操作系统的page cache 自动来管理，但page cache的不可控性，大量小碎文件带来的磁盘碎片，多至数万个replica的复制，即便是SSD磁盘组成的集群，性能也会直线下降。</p></li><li><p>一致性方面，bookkeeper自身只是一个无脑存储单元，ledger的副本，都是靠bookkeeper的客户端来完成，由客户端按照bookkeeper集群当前的数量，以及客户端的配置，临时生成ensemble，来完成多副本的保障，所以一致性，持久性都是靠客户端来完成，中间主要靠pulsar这个客户端来管理。而Kafka是靠自身的多副本主动复制机制来完成的，服务端自己来完成。相对来说，kafka的一致性和持久性会更统一一些，逻辑都在一块，而pulsar比较分散，需要客户端来主导，bookkeeper服务端来配合完成。</p></li><li><p>上边说到bookkeeper是一个有限数据流，当单机宕机后，客户端会主动再已启动一个预设定数量的ensemble，继续完成消息数据的而写入，而且副本数量没有少，比如EM设定3，WQ设定3，AQ设定2，副本数量是3个，当一台机器宕机后，如果集群有冗余，客户端可以快速形成一个新的同等ensemble，因为它的数据流是分段形成的，新的段(ledger)不必一直设定在原有的机器上，可以很快在替代机器上生成。<br>而kafka不行，因为是无限数据流，集群宕机一台后，副本数量少一个，不能很快形成一个新的替代replica，必须替换机器，重新reassign partition leader和follower，来搬运历史数据，相对来说速度比较慢，会有一个较长的副本缺少的空窗期。</p></li></ol>]]></content>
    
    
    <summary type="html">本文分析了Apache pulsar的底层存储模型</summary>
    
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Apache Pulsar" scheme="https://wangjunfei.com/tags/Apache-Pulsar/"/>
    
    <category term="Apache Bookkeeper" scheme="https://wangjunfei.com/tags/Apache-Bookkeeper/"/>
    
    <category term="Apache Kafka" scheme="https://wangjunfei.com/tags/Apache-Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Apache pulsar对zookeeper的依赖和去除分析(二)</title>
    <link href="https://wangjunfei.com/2023/09/15/Apache-pulsar%E5%AF%B9zookeeper%E7%9A%84%E4%BE%9D%E8%B5%96%E5%92%8C%E5%8E%BB%E9%99%A4%E5%88%86%E6%9E%90-%E4%BA%8C/"/>
    <id>https://wangjunfei.com/2023/09/15/Apache-pulsar%E5%AF%B9zookeeper%E7%9A%84%E4%BE%9D%E8%B5%96%E5%92%8C%E5%8E%BB%E9%99%A4%E5%88%86%E6%9E%90-%E4%BA%8C/</id>
    <published>2023-09-15T04:13:00.000Z</published>
    <updated>2024-03-24T00:58:30.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Apache pulsar是近年来国内比较时髦的消息队列，而且是开源的产品，有不少国内的互联网公司都开始了使用了。针对开源的几个消息队列产品比较，可以参看我之前的一篇博客<a href="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/" title="消息队列业界调研">&lt;&lt;消息队列业界调研&gt;&gt;</a>。Pulsar为什么现在比较火，说白了是搭上了”云原生”这趟车。在当今时代，任何互联网技术，特别是基础组件，如果没云原生化，出门别人都不好意思给你打招呼。特别是从2021年开始， 突然一切互联网技术都需要”云原生”了，其中隐情也是各有使然，当然这是另一个话题。(关于我在美团时负责的消息队列Mafka云原生化分析，可以参考我的这篇博客和 <a href="/2021/07/14/Mafka-LRP/" title="Mafka消息队列长期发展计划">&lt;&lt;消息队列Mafka列长期发展计划&gt;&gt;</a> 和 <a href="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/" title="Mafka全链路弹性伸缩演进策略">&lt;&lt;消息队列Mafka全链路弹性伸缩演进策略&gt;&gt;</a>  )Pulsar因为其”天然”的存算分离架构，和云原生讲究的弹性伸缩性(scalability)，品性特别符合，自然受到了大家特别的追捧。</p><p>关于pulsar架构的评价，可以参考我之前写的这篇博客<a href="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/" title="消息队列业界调研">&lt;&lt;消息队列业界调研&gt;&gt;</a>。本系列文章主要分析下pulsar对zookeeper的依赖，因为在当前的架构下(本篇以pulsar 2.8版本分析)，pulsar对zookeeper是强依赖关系，说白了就是zookeeper一旦挂掉，pulsar整个集群也就挂掉了。因为之前我也有一篇博客分析kafka 去除zookeeper依赖<a href="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/" title="Kafka去Zookeeper揭秘">&lt;&lt;揭秘Kafka去Zookeeper技术&gt;&gt;</a>，本篇分析下bookkeeper对zookeeper的依赖，以及如何去除。因为涉及的内容比较多，会分为三篇博客来写，第一篇分析pulsar本身，即pulsar broker，第二篇分析 bookkeeper对zookeeper的依赖，就是本篇内容，第三篇 是临时加的，因为2023年5月份，pulsar官方出了一个类似kafka kraft的一致性组件(<a href="https://streamnative.io/blog/moving-toward-zookeeper-less-apache-pulsar" title="moving-toward-zookeeper-less-apache-pulsar">moving-toward-zookeeper-less-apache-pulsar</a>)来去除pulsar对zookeeper的依赖，第三篇会重点分析下这个组件。</p><h1 id="架构简介"><a href="#架构简介" class="headerlink" title="架构简介"></a>架构简介</h1><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>在讨论细节之前先来重温下pulsar的架构，pulsar架构的详细介绍，可以参考我之前的博客<a href="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/" title="消息队列业界调研">&lt;&lt;消息队列业界调研&gt;&gt;</a>一文<br><img src="/2023/09/15/Apache-pulsar%E5%AF%B9zookeeper%E7%9A%84%E4%BE%9D%E8%B5%96%E5%92%8C%E5%8E%BB%E9%99%A4%E5%88%86%E6%9E%90-%E4%BA%8C/pic5.svg"></p><ol><li>整个pulsar 分为broker和bookkeeper两大部分</li><li>broker 和 bookkeeper都依赖 zookeeper来做元数据存储</li><li>broker是无状态的计算层(有部分配置缓存和消息数据缓存)</li><li>bookkeeper是存储层, bookkeeper实际上是apache的另一个开源项目</li></ol><h2 id="先来看几个几个名词概念"><a href="#先来看几个几个名词概念" class="headerlink" title="先来看几个几个名词概念"></a>先来看几个几个名词概念</h2><ol><li><p>ledger<br>  ledger是bookkeeper中概念，代表一个流水账，一个ledger其实就是 pulsar中topic的一个partition。但是在bookkeeper内部实现里，ledger其实是一个虚拟的概念，没有物理实体或文件实体。它有多个sgement组成，因为bookkeeper把多个leger写入到同一个entry log内，不同的legder会相互间隔相连，属于同一个legder的entry会排列在一起。entry log会不断滚动，生产一段一段的文件，每一段称为一个sgement。</p></li><li><p>journal<br>   bookkeeper中的物理文件，journal是短暂存储.在接收到客户端的发送的消息后，先写入write cache，然后再异步落盘形成entry log, entryFile是长期存储的消息文件, 最后在写入journal，在经过group commit方式flush到磁盘落地后，再ack客户端发送消息成功。jornal只是为了恢复entry file而写的。</p></li><li><p>entry log<br> entry log 是bookkeeper中的物理文件，是消息数据的持久存储。可以在bookkeeper内配置entry log的目录，可以是一个或多个，每个目录只对应一个entry log，所有ledger都落盘到这个file内。这个跟journal比较像，都是所有ledger的消息数据，但是entry log里的数据是按照ledger排列的，方便读取，而且entry log 是异步刷盘，journal是raw的消息数据，是同步刷盘(group commit方式)。当bookkeeper机器宕机后，未落盘的entry log 数据，可以根据check point从journal内恢复，这就是journal作为短暂临时存储的目的。</p></li><li><p>index file<br> bookkeeper的存储是有几种实现(接口称为LedgerStorage)可选:     </p><ul><li>InterleavedLedgerStorage</li><li>SortedLedgerStorage</li><li>DbLedgerStorage</li></ul><p> 前两种实现使用index file物理文件来作为entry的索引查找，最后一种使用rocksDB来做索引查找. 主要是查找某个特定entry的位置，比如给一个entry ID和一个ledger ID，查找这个entry在哪个entry log file里,在文件内的offset是多少。</p></li><li><p>fragment<br> 在发送消息时，如果ensemble里有一个bookkeeper机器掉线，客户端会再选择一个ensemble，继续发送消息，每个ensemble对应的一批消息称为fragment </p></li><li><p>ensemble(EM)<br> 几个bookkeeper实例组成一组存储，比如整个集群有10台机器，选择其中5台作为一个ensemble，WQ设置为3，AQ设置为2.</p></li><li><p>WQ<br> write quorum 发送消息时，必须写入的bookkeeper机器数量。在实际项目实践中，WQ一般和ensemble设置为一致，防止产生striping(一部分entry在一台机器上，下一部分跳到了另外一批机器上)而降低读消息的效率    </p></li><li><p>AQ<br> ack quorum 发送消息时，必须收到ack的bookkeeper机器数量   </p></li><li><p>Fencing<br> 当第一个客户端掉线后，第二个客户端必须关闭第一个客户端发送消息时写入的ledger，在关闭之前防止之前的ledger再继续写入，会先做fence操作，防止之前的客户端继续写入，产生脑裂，因为bookkeeper中的一个ledger写入，不允许有两个客户端同时写入，客户端必须保障这一点。</p></li></ol><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>bookkeeper对客户端有一定的要求:</p><ul><li>bookkeeper要求客户端在写入ledger的时候，不允许两个客户端同时写入，客户端必须保障这一点</li><li>bookkeeper要求客户端在写入ledger的时候，ledger Id必须是顺序的，客户端必须保障这一点</li></ul><p>相对于pulsar整体架构来说，pulsar的broker就是bookkeeper的客户端，所以broker会强依赖zk，保障任何时候一个topic只能被一个broker所负责。bookkeeper本身是一个无脑的存储，上边所说的两个保障都需要客户端自己来做。</p><p>数据的副本，也是靠客户端来保障的，比如像EM=3, WQ=3,AC=2这样集群设定，一个ensemble有3台bookkeeper机器，write quorum是3，Ack quorum是2，那客户端在发送消息时，必须发送3次，保障每台机器都发送到，但是可以在收到2个bookkeeper的ack后就算成功。</p><p>所以，bookkeepe本身对zk的依赖来说不重，主要做集群内机器上下线通知，和一些元数据存储，下边来详细看下zk上的元数据。</p><h1 id="Broker对Zookeeper的依赖总结"><a href="#Broker对Zookeeper的依赖总结" class="headerlink" title="Broker对Zookeeper的依赖总结"></a>Broker对Zookeeper的依赖总结</h1><table><thead><tr><th>项目</th><th>zk 路径</th><th>value/children</th><th>备注</th><th></th></tr></thead><tbody><tr><td>集群节点相关</td><td>/ledgers/available/[ip:port]</td><td>children</td><td>临时节点，当前在线的集群节点列表。客户端会来读取，创建新的ensemble</td><td></td></tr><tr><td></td><td>/ledgers/cookie/[ip:port]</td><td>children</td><td>持久节点，broker启动时自动注册，用来核实bookkeeper节点整个生命周期的配置信息</td><td></td></tr><tr><td></td><td>/ldegers/available/readonly/[ip:port]</td><td>children</td><td>启动时强制注册为readonly的节点，或者当磁盘无可用空间时转换为readonly，这样的节点无法接受写操作</td><td></td></tr><tr><td>ledger数据相关的</td><td>/ledgers/00/0000/L000X</td><td>value</td><td>ledger的metadata信息，例如每个fragment的ledger id范围，方便ledger读取时，确定ledger在哪台机器上</td><td></td></tr><tr><td></td><td>/ledgers/idgen/ID-0000000000X</td><td>value</td><td>每次创建新ledger时，从这个节点获取一全局唯一的ledgerId</td><td></td></tr></tbody></table><p>从上边的列表，不难看出，zk在这里的作用分两类，第一个是集群节点上下线注册和通知，第二类是全局唯一的锁，比如ledger Id的生成，以及ledger metadata的写入和更新。第三类，完全是配置类型的存储。</p><p>第一类，节点在zk上的注册，如果有网络抖动的话，或者zk自身jvm gc会造成节点瞬间下线，如果抖动时间比较长，会影响单个节点，或整个集群的稳定性，特别是zk数据量大了以后，自身jvm gc造成长时间卡住或假死，会造成全部节点下线，可用性降为0。所以如果条件允许，作为节点注册上下线，探活一类的zk，一定不能存储太多的数据。如果ledger自身数量比较多，考虑拆分集群，或替换为持久节点，外部增加一个scanner组件来主动扫描有问题的节点，如果节点端口不响应，可以将持久节点状态置为dead状态，或删除(在美团时，美团消息队列Mafka就是这样做的)。</p><p>第二类，全局唯一锁，这个可以使用redis做一个简单全局锁，或其他分布式锁组件，以此来替换掉zk。</p><p>第三类，配置存储类的，可以迁移到kv或mysql一类的关系数据库里，避免zk数据量的线性增长。</p>]]></content>
    
    
    <summary type="html">本文分析了apache bookkeeper对zk的依赖和去除思考</summary>
    
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Apache Pulsar" scheme="https://wangjunfei.com/tags/Apache-Pulsar/"/>
    
    <category term="Apache Bookkeeper" scheme="https://wangjunfei.com/tags/Apache-Bookkeeper/"/>
    
    <category term="Apache Kafka" scheme="https://wangjunfei.com/tags/Apache-Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Apache pulsar对zookeeper的依赖和去除分析(一)</title>
    <link href="https://wangjunfei.com/2023/06/15/Apache-pulsar%E5%AF%B9zookeeper%E7%9A%84%E4%BE%9D%E8%B5%96%E5%92%8C%E5%8E%BB%E9%99%A4%E5%88%86%E6%9E%90-%E4%B8%80/"/>
    <id>https://wangjunfei.com/2023/06/15/Apache-pulsar%E5%AF%B9zookeeper%E7%9A%84%E4%BE%9D%E8%B5%96%E5%92%8C%E5%8E%BB%E9%99%A4%E5%88%86%E6%9E%90-%E4%B8%80/</id>
    <published>2023-06-15T09:13:00.000Z</published>
    <updated>2024-03-24T00:58:30.775Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Apache pulsar是近年来国内比较时髦的消息队列，而且是开源的产品，有不少国内的互联网公司都开始了使用了。针对开源的几个消息队列产品比较，可以参看我之前的一篇博客<a href="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/" title="消息队列业界调研">&lt;&lt;消息队列业界调研&gt;&gt;</a>。Pulsar为什么现在比较火，说白了是搭上了”云原生”这趟车。在当今时代，任何互联网技术，特别是基础组件，如果没云原生化，出门别人都不好意思给你打招呼。特别是从2021年开始， 突然一切互联网技术都需要”云原生”了，其中隐情也是各有使然，当然这是另一个话题。(关于我在美团时负责的消息队列Mafka云原生化分析，可以参考我的这篇博客和 <a href="/2021/07/14/Mafka-LRP/" title="Mafka消息队列长期发展计划">&lt;&lt;消息队列Mafka列长期发展计划&gt;&gt;</a> 和 <a href="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/" title="Mafka全链路弹性伸缩演进策略">&lt;&lt;消息队列Mafka全链路弹性伸缩演进策略&gt;&gt;</a>  )Pulsar因为其”天然”的存算分离架构，和云原生讲究的弹性伸缩性(scalability)，品性特别符合，自然受到了大家特别的追捧。</p><p>关于pulsar架构的评价，可以参考我之前写的这篇博客<a href="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/" title="消息队列业界调研">&lt;&lt;消息队列业界调研&gt;&gt;</a>。本篇文章主要分析下pulsar对zookeeper的依赖，因为在当前的架构下(本篇以pulsar 2.8版本分析)，pulsar对zookeeper是强依赖关系，说白了就是zookeeper一旦挂掉，pulsar整个集群也就挂掉了。因为之前我也有一篇博客分析kafka 去除zookeeper依赖<a href="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/" title="Kafka去Zookeeper揭秘">&lt;&lt;揭秘Kafka去Zookeeper技术&gt;&gt;</a>，本篇分析下pulsar对zookeeper的依赖，以及如何去除。因为涉及的内容比较多，会分为三篇博客来写，第一篇分析pulsar本身，即pulsar broker，第二篇分析 bookkeeper对zookeeper的依赖，第三篇 是临时加的，因为2023年5月份，pulsar官方出了一个类似kafka kraft的一致性组件(<a href="https://streamnative.io/blog/moving-toward-zookeeper-less-apache-pulsar" title="moving-toward-zookeeper-less-apache-pulsar">moving-toward-zookeeper-less-apache-pulsar</a>)来去除pulsar对zookeeper的依赖，第三篇会重点分析下这个组件。</p><h1 id="架构简介"><a href="#架构简介" class="headerlink" title="架构简介"></a>架构简介</h1><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>在讨论细节之前先来重温下pulsar的架构，pulsar架构的详细介绍，可以参考我之前的博客<a href="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/" title="消息队列业界调研">&lt;&lt;消息队列业界调研&gt;&gt;</a>一文<br><img src="/2023/06/15/Apache-pulsar%E5%AF%B9zookeeper%E7%9A%84%E4%BE%9D%E8%B5%96%E5%92%8C%E5%8E%BB%E9%99%A4%E5%88%86%E6%9E%90-%E4%B8%80/pic5.svg"></p><ol><li>整个pulsar 分为broker和bookkeeper两大部分</li><li>broker 和 bookkeeper都依赖 zookeeper来元做数据存储</li><li>broker是无状态的计算层(有部分配置缓存和消息数据缓存)</li><li>bookkeeper是存储层, bookkeeper实际上是apache的另一个开源项目</li></ol><h2 id="几个实体"><a href="#几个实体" class="headerlink" title="几个实体"></a>几个实体</h2><ol><li>topic<br> topic就是一个队列，pulsar中的 topic 对应bookkeeper中的一个ledger。多partition的队列就是多个队列组成的，对应多个Ledger。</li><li>group<br>  消费组</li><li>bundle<br>  队列集合。pulsar 使用hash算法，将多个队列归为一个集合，叫做bundle。bundle是一个虚拟实体，bundle 会被分配到不同的集群节点上，每个bundle 包含一部分队列。要计算topic在哪台节点上，需要先计算topic在哪个bundle里。 pulsar管理集群节点和topic的归属关系时，是以bundle为粒度的。</li><li>tenant<br> 租户</li><li>namespace<br> ns空间，命名空间</li><li>managed leger<br> pulsar包装的bookkeeper中的ledger</li><li>managed cursor<br>  pulsar抽象化的消息队列指针</li><li>policy<br>  namespace空间内使用的集群规则条目</li><li>local policy<br>  本集群内所有bundle的信息等</li></ol><h1 id="Broker对Zookeeper的依赖总结"><a href="#Broker对Zookeeper的依赖总结" class="headerlink" title="Broker对Zookeeper的依赖总结"></a>Broker对Zookeeper的依赖总结</h1><p>先来看下broker对zk依赖的总结列表</p><table><thead><tr><th>项目</th><th>zk 路径</th><th>value/children</th><th>备注</th><th></th></tr></thead><tbody><tr><td>pulsar polices定义都集中在/admin/polices目录下</td><td>/admin/policies</td><td>children</td><td>租户列表</td><td></td></tr><tr><td></td><td>/admin/policies/[tenant]</td><td>children</td><td>namespace列表   初始化创建两个namespace： 1. public/default/ 2. pulsar/system/存放system topic</td><td></td></tr><tr><td></td><td>/admin/policies/tenant/[namespace]</td><td>value</td><td>namespace 级别policies策略</td><td></td></tr><tr><td>bundle相关的数据</td><td>/admin/local-policies/[namespace名称]</td><td>value</td><td>集群内所有的 namespace下的所有bundle信息   节点的value值实际上是 LocalPolicies类的序列化</td><td></td></tr><tr><td></td><td>/namespace/tenant/[namespace]</td><td>临时节点  value</td><td>bundle的owner信息 NamespaceEphemeralData[java类]: 节点服务信息ip和port一类</td><td></td></tr><tr><td>clusters</td><td>/admin/clusters</td><td>children</td><td>cluster列表</td><td></td></tr><tr><td></td><td>/admin/clusters/[cluster]</td><td>value</td><td>cluster 信息数据 clusterData</td><td></td></tr><tr><td></td><td>/admin/clusters/[cluster]/ namespaceIsolationPolicies</td><td>value</td><td>namespace isolation polices集群分组策略</td><td></td></tr><tr><td></td><td>/admin/configuration</td><td>value</td><td>动态配置 DynamicConfiguration</td><td></td></tr><tr><td>brokers</td><td>/loadbalance/brokers</td><td>children</td><td>active brokers在线的broker</td><td></td></tr><tr><td></td><td>/loadbalance/brokers/[ip:port]</td><td>临时节点 value</td><td>LocalBrokerData[java类]</td><td></td></tr><tr><td>topics</td><td>/managed-ledgers/[tenant]/[namespace]/persistent</td><td>children</td><td>topic信息</td><td></td></tr><tr><td></td><td>/admin/partitionedTopic/[topic全名]</td><td>value</td><td>topic的partition信息</td><td></td></tr><tr><td>topic的ledger、cursor、消费组相关信息</td><td>/managed-ledgers/[topic全名]</td><td>value</td><td>topic的 ledger 数据，实际是java类 ManagedLedgerInfo的序列化</td><td></td></tr><tr><td></td><td>/managed-ledgers/[topic全名]</td><td>children</td><td>topic 的消费组名称(同时也是cursor名称/cursor ledger名称)列表</td><td></td></tr><tr><td></td><td>/managed-ledgers/topic全名/[消费组名称]</td><td>value</td><td>消费组的cursor leger 信息 实际上是java类 ManagedCursorInfo的byte形式</td><td></td></tr></tbody></table><p>粗略分的话，大约分以下几类：</p><ol><li>topic相关信息： topic/group/bundle/ledger/cursor一类，这一类信息都是和topic相关的，但是集群在操作的时候都是以bundle粒度来操作的。要确定topic在哪台机器上，先确定topic属于哪个bundle.</li><li>broker相关信息: 集群内有多少个节点，每个节点当前的状态</li><li>配置类信息：tenant/namespace/cluster/动态配置/policy配置，这些信息都是涉及到整个集群配置的，创建、删除、修改都依赖zk的增删改查</li></ol><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><h2 id="1-topic相关信息"><a href="#1-topic相关信息" class="headerlink" title="1.topic相关信息"></a>1.topic相关信息</h2><p>上边说过，pulsar集群在操作topic时，是以bundle为粒度，一个bundle包含一批topic。bundle 被集群内的不同节点持有，哪个节点持有某个bundle，它就负责这些topic相关的操作，比如创建和删除topic /group/ledger/cursor等信息。</p><p>bundle 信息存储在zk上两个节点下:</p><ul><li><p><code>/admin/local-policies/[namespace名称]</code> 下Value值，存放着localPolicies对象的序列化信息，localPolicies对象里含有bundleData信息，bundleData主要包含三个条目:这个namespace下所有bundle的数量，每个bundle之间的界限范围列表，比如(0x00000000，0x100000000，0x200000000)</p></li><li><p><code>/namespace/[namespace名称]/[localhost:8080]/[0x00000000_0xffffffff]</code> ，即/namespace/[bundle名称]的Value 值，是一个临时节点，存放了SelfOwnerInfo(java类，包含nativeUrl,httpUrl)，就是包含这个bundle的节点信息的序列化串</p></li></ul><p>同时这两个节点也会在Pulsar的java类<code>NamespaceBundleFactory</code>和<code>OwnershipCache</code>中形成一个cache信息。</p><p>跟bundle关系紧密的类还包括java类<code>NamespaceService</code>。这个类主要是来服务bundle信息的，比如确定bundle在哪台broker上，获取一个bundle等，确定topic属于哪个bundle。</p><h3 id="多个节点并发写zk导致的一致性挑战-bundle信息并发写-和-bundle所有权多节点并发抢占"><a href="#多个节点并发写zk导致的一致性挑战-bundle信息并发写-和-bundle所有权多节点并发抢占" class="headerlink" title="多个节点并发写zk导致的一致性挑战: bundle信息并发写 和 bundle所有权多节点并发抢占"></a>多个节点并发写zk导致的一致性挑战: bundle信息并发写 和 bundle所有权多节点并发抢占</h3><p>因为 bundle 在 pulsar内被设计为可以在多个节点之间漂移的，同时也是可以被分裂成多个bundle的，所以bundle信息在zk上write和update等维护操作会在集群内多个节点之间产生并发竞争。</p><h4 id="bundle拆分产生的并发写zk操作"><a href="#bundle拆分产生的并发写zk操作" class="headerlink" title="bundle拆分产生的并发写zk操作"></a>bundle拆分产生的并发写zk操作</h4><p>namespace和bundle信息在zk上的path如下:</p><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/admin/local-polices/[ns1]     -&gt; [value]  localPolices</span><br><span class="line">                    [ns2].</span><br><span class="line">                    [ns3]·</span><br></pre></td></tr></tbody></table></figure><p>namespaceBundleFactory类有一个重要属性bundlesCache，这个cache内有每个namespace和其所有的bundle组成的KV缓存。<br>这个cache 也是异步加载的，需要人为来触发，当来一个lookup请求，需要知道哪个机器负责这个bundle时，就会触发当前topic所属namespace的缓存加载，加载时会load当前namespace所包含的所有bundle信息。这个KV缓存不止缓存本机拥有的bundle的namespace，他会包含所有被服务过的toipc的namespace。</p><p>实际加载动作由doLoadBundle完成:  从zk上读取bundle信息，反序列化成localPolicies，同时会保留一个pulsar自己的通过zk state构造的Sate里的version信息，是long型值，这些信息都会保存在KV缓存Value 里的Namespacebundles对象内， 将来做bundle拆分时，需要将拆分后的bundle信息回写到zk上时，这时会产生多个broker节点并发写zk的情况，因为这里存储的是某个namespace负责的所有bundle信息，其他broker也有拿到这个namespace下某一个bundle的所有权，做bundle拆分时，也会更新bundles 总信息，这时就要有一个一致性协调者zk，更新zk信息时，需要比较上次缓存的version信息和zk上现在的version信息时是否相等，避免覆盖其他人写的值。这个version在这里的作用，其实还是为了确保自己缓存的zk 数据信息是最新，防止将旧的数据会写到zk上。</p><h4 id="bundle所有权抢占产生的zk写竞争"><a href="#bundle所有权抢占产生的zk写竞争" class="headerlink" title="bundle所有权抢占产生的zk写竞争"></a>bundle所有权抢占产生的zk写竞争</h4><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/namespace/</span><br><span class="line">    <span class="selector-attr">[ns1]</span>/<span class="selector-attr">[0x00000000-0xfffffff0]</span>    -&gt; <span class="selector-attr">[value]</span> OwnedBundle</span><br><span class="line">    <span class="selector-attr">[ns1]</span>/<span class="selector-attr">[0xfffffff0-0xffffffff]</span></span><br></pre></td></tr></tbody></table></figure><p>NameSpaceService里的重要属性ownerShipCache对象，这个对象拥有一个重要的KV缓存属性，key是NamespaceBundlezNode，value是ownedBundle，简单说key就是一个bundle在 zk 上的路径(/namespace/[namespaceName]/[bundleRange])，zk上对应的value是bundle对象的序列化。这个缓存保存了当前节点拥有的bundle列表，这些信息在OwnerShipCache里保存了一份，同时也会保存在zookeeper上。当前broker 负责的bundle信息，在zk上保存的是一个临时节点，因为当前broker如果宕机了，zk链接就会断开，临时节点就会丢掉，当前broker释放bundle的所有权，以期望其他broker能获取。</p><p>注意这个cache不是自动创建的，必须有人来触发他，比如有一个lookup请求打到这个节点上时，broker 需要直到这个topic所属于哪个bundle，并且会从本机的这个缓存里查找一下，看自己是否拥有这个bundle。如果拥有，则正常返回。如果不拥有这个bundle，则会再从zk上查一下谁当前拥有这个bundle。这里查询的时候，如果查到这个节点已经存在，则会比较下节点创建的zk sessionId，和当前的sessionId是否相等，并且负责这个bundle的broker的url是否也相等，如果都相等的话，则认为是自己负责的。注意，这时其实发生了zk和本机缓存不一致的情况，zk上的临时节点是自己创建的，但是本机缓存却不存在，这里实际上是做了一次补偿，来统一zk数据和本机缓存数据。如果不想等，则会认为是其他人拥有这个bundle，会将请求打到真正负责这个bundle的broker上。如果没人拥有这个bundle，会触发让leader选取一个合适的候选节点来负责这个bundle。如果候选节点是本机，则当前broker会尝试获取这个bundle，把这个bundle负责起来。<br>尝试获取bundle的时候，实际发生了 zk 的并发抢占，当其他节点也发现无人负责这个bundle时，很有可能也去抢占获取这个bundle，所以这时需要一个zk的一致性机制来保障。</p><p>copy polices to local polices: 把polices里的bundle信息保存到local policies里，保存时，期望zk里的version是 -1，其目的是表明是自己来完成初次的local polices的构造，防止覆盖了其他人的写。</p><p><strong>总体来看</strong>，<ins>namespace下所有bundle信息的维护，bundle的拆分，以及拆分后每个bundle的所有者分配，完全可以交由集群的leader来维护，避免多个节点都去执行写操作，产生并发写竞争。避免因为并发写，而必须引入zookeeper这个一致性协调者。所有的写操作，都可以交由leader来完成，leader和其他节点的通信，使用epoch方式来保障，确保集群内所有的节点对当前leader 有统一和一致的认识，这点可以参考Kafka类似的系统。</ins> </p><p><strong>当bundle信息确定后</strong>，<ins>每个节点都有负责的一组固定的bundle，一个bundle对应着一批topic，topic的ledger信息、cursor信息、group 信息都有topic所在的节点自己来负责，对zk的读写操作基本都是低频的，即便发生并发，在单节点、单jvm内使用普通的java并发工具包类也是很好控制的，基本不涉及到多个节点的并发。因此这类操作，基本是拿zk当存储来使用，并没有使用到zk的全局一致性保障功能。</ins></p><h3 id="附-topic相关的操作"><a href="#附-topic相关的操作" class="headerlink" title="附 topic相关的操作:"></a>附 topic相关的操作:</h3><div style="color: #6E7173"><p>ledger、cursor 相关的topic操作列表，以及访问zk的操作</p><ol><li>topic创建<br>创建ledger，保存ledger信息到zk</li><li>group创建<br>创建cursor ledger，保存cursor ledger信息到zk。分区topic 的 group创建是分别给每个分区的topic轮流创建一遍。</li><li>producer创建<br>无zk操作。分区topic的producer创建也是按分区个数轮流创建。</li><li>send操作<br>当前ledger添加满之后，创建新的ledger，保存新的ledger信息到zk</li><li>consume操作<br>消息拉取委托managedCursor来完成，本身无相关的 zk 操作。</li><li>客户端ack消息<br>ack的消息和位点信息，最终会构造为一个PositionInfo的对象，序列化之后添加到cursor ledger中，cursor ledger虽然也是一个ledger，但不同的是这个ledger只会有一个，当当前ledger添加满了之后，topic的ledger会负责创建一个新的ledger来存储位点信息。</li></ol><p>这些都没有涉及到zk的操作。只有创建cursor ledger时，需要将这个ledger信息保存到zk上。<br>同时，当ack消息添加到cursor ledger失败时，或关闭cursor时，或cursor ledger发生切换时，才会将位点信息补写一份到zk的cursor 节点value中。</p></div><h2 id="2-broker-节点相关的操作"><a href="#2-broker-节点相关的操作" class="headerlink" title="2.broker 节点相关的操作"></a>2.broker 节点相关的操作</h2><p>broker 节点相关的zk操作基本都在<code>/loadbalance/</code>节点下，节点上线、下线会导致创建或删除临时节点，这一部分和负载均衡的逻辑在一起。所有broker会定时将本机的负载数据，写到zk上，内容是LocalBrokerData类对象的json序列化,路径是<code>/loadbalance/broker-time-average/[ip]</code>。</p><p>集群会首先选出一个leader，leader会启动一个loadSheddingTask和一个LoadResourceQuotaTask，前者会根据集群当前的负载信息卸载需要均衡的bundle，后者会综合所有 broker 上报的系统负载信息和bundle信息计算出长期、短期两个维度的负载信息，再更新到zk上，内容是TimeAverageBrokerData对象的json序列化，zk 路径是<code>/loadbalance/broker-time-average/[ip]</code>。这里leader broker和普通的broker往 zk 上上报的信息，<ins>使用的是不同节点，不涉及到zk的并发写，因此这里仍然是拿zk作为一个存储来使用的。</ins></p><h2 id="3-配置相关的操作"><a href="#3-配置相关的操作" class="headerlink" title="3.配置相关的操作"></a>3.配置相关的操作</h2><p>tenant/namespace/cluster/动态配置/policy配置，这些信息都是涉及到整个集群配置的，创建、删除、修改都依赖zk的增删改查。这些信息都是集群的静态配置，目前是每个集群节点都可以去操作zk来处理这些请求的，同样也是通过zk的返回代码来判断是否有并发写。依据前面topic信息一类的分析，仍然是可以由集群leader来独自完成的，避免对zk的并发写。</p><h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>如果使用epoch的方法，所有的集群操作都由leader来完成，leader 会不会变成一个单点风险？ 确实会，不过这时可以用zk来做一个抢占临时节点来选出集群leader，其他所有的集群写操作都由leader来完成，需要存储的数据由关系数据库或kv来完成(这一项我们在美团递消息队列Mafka castle的模块改动上有实践过)。这是第一个需要zk的地方，由zk来辅助选出集群的一个leader。第二个是集群节点的上下线也需要zk来监控和通知leader，这也是zk所擅长的。如果完全靠leader来检测其他节点，则需要通过节点间RPC调用，配合心跳健康检查，来确定其他节点的上下线，相当于自己实现了一遍zk的功能。</p><p>如果都由leader来完成，leader会不会称为一个瓶颈点？不会，总结上边会触发zk写操作的事件，相比收发消息一类的请求来说，都不是一个量级的，所以leader节点不会是一个瓶颈点。如果实在担心，可以将leader节点设置为纯 leader，不承载任何 bundle 数据，不接受消息收发类的数据请求，这点我们在美团消息队列Mafka上使用过。还可以将数据请求操作和集群管理操作做分类，leader 节点在处理请求时，优先处理管理类操作，也可以减轻leader节点的负担，就像是Kafka在1.1.0版本后的改动一样。</p>]]></content>
    
    
    <summary type="html">本文分析了apache pulsar broker对zk的依赖和去除思考</summary>
    
    
    
    
    <category term="Apache pulsar 消息队列 kafka RocketMQ" scheme="https://wangjunfei.com/tags/Apache-pulsar-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-kafka-RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>时间轮算法分析和应用</title>
    <link href="https://wangjunfei.com/2023/04/10/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E5%92%8C%E5%BA%94%E7%94%A8/"/>
    <id>https://wangjunfei.com/2023/04/10/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E5%92%8C%E5%BA%94%E7%94%A8/</id>
    <published>2023-04-09T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.795Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>时间轮是一个比较有趣的算法，他最早刊登在George Varghese和Tony Lauck的论文里。</p><p>问题的初衷是如何实现一个高效的定时器调度。比如有很多定时任务，每个任务的定时时间不一样，有1s 后，5s 后，1小时后，3天后，假设有很多个这样的任务，数千个或数万个，怎么通过程序来实现高效的调度每个任务，让他们在到期后顺利执行。</p><p>java中最直接的就是使用Timer类，使用 add方法增加一个定时任务。但是这种方法有几个问题:</p><ol><li>定时任务需要Timer内的线程来执行，一个Timer在背后只有一个线程在执行，假设其中一个任务本身的执行时间太久，后边的任务就会被耽搁，特别是当有很多任务，比如成千上万个需要调度时</li><li>而且这个类还有一个问题，如果其中一个TimerTask在执行时抛出了异常，那么整个计时器会停止运行。</li></ol><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>下边来看看论文里讲的几种实现方法</p><p>总结一下，整个任务调度算法分为4种操作：</p><ol><li>创建一个任务(start_timer)</li><li>取消一个任务(stop_timer)</li><li>时钟走一格，需要做的操作(per_tick_bookkeeping)</li><li>启动到期的任务 (expire_process)</li></ol><h2 id="方案1-无序列表"><a href="#方案1-无序列表" class="headerlink" title="方案1: 无序列表"></a>方案1: 无序列表</h2><p>假设有一个列表，每个元素存储一个任务，任务包含任务到期后要做的操作，以及任务的到期时间。<br>这时，我们通过程序模拟时钟在走动(tick)，比如, 14:20:21, 14:20:22,  。。。按顺序推动时间走，时间每走一格，上边4个操作需要的时间复杂度如下:</p><ul><li>开始调度一个任务(start_timer): 来了一个新的任务，我们把任务直接插入到列表尾部，时间复杂度O(1)，每次插入后返回任务的指向指针，这样在取消任务时，就可以直接拿来操作。</li><li>取消一个任务(stop_timer):  如上，我们持有任务的指针， 假设我们使用双向链表来实现列表，直接操作指针即可完成。</li><li>时钟走一格，需要做的操作(per_tick_bookkeeping)：因为整个列表里，每个任务的过期时间不一样，我们需要遍历整个列表，找到当前这一时间格时，过期里边所有任务。所以时间复杂度度是O(n)</li><li>启动到期的任务 (expire_process)：这个操作只要找到过期的任务，直接操作即可，不需要额外的时间处理。</li></ul><p>因为取消一个任务，启动到期任务两个操作，只要我们保存任务的指针，即可完成，时间复杂度都是O(1)，因此后续的方案都不再赘述他们。</p><h2 id="方案2-有序列表"><a href="#方案2-有序列表" class="headerlink" title="方案2: 有序列表"></a>方案2: 有序列表</h2><p>将列表维护为一个有序列表，把任务按照时间到期的顺序做排序，最早到期的任务排在最前面。<br>这样，算法的操作如下:</p><ul><li>开始调度一个任务(start_timer): 来一个新的调度任务时，需要将任务插入到有序列表相应的位置，按照过期时间排序，最坏时间复杂度是O(n)。</li><li>时钟走一格，需要做的操作(per_tick_bookkeeping)：直接从列表开头开始找任务，和当前时间做比较，因为最先到期的都在列表开头，因此时间复杂度基本是常数，是O(1)的时间复杂度。</li></ul><h2 id="方案3-树形结构"><a href="#方案3-树形结构" class="headerlink" title="方案3: 树形结构"></a>方案3: 树形结构</h2><p>将列表维护为一个非平衡二叉树，堆或者前序、或后序遍历树，这种情况下，插入一个任务的时间复杂度可以降低到O(logn)</p><h2 id="方案4-简单时间轮"><a href="#方案4-简单时间轮" class="headerlink" title="方案4: 简单时间轮"></a>方案4: 简单时间轮</h2><p>时间轮方式。将所有任务的换算为多少秒或毫秒(Interval)后到期，维护一个最大过期值(Interval)长度的数组。比如有10个任务，分别是1s，3s，100s 后到期，就建一个100长度的数组，数组的index就是每个任务的过期值(Interval)，当前时间作为第一个元素，那么第二个元素就是1s 后到期的任务，第三个是2s 后到期的任务，依次类推。当前时间随着时钟的前进(tick)，逐步发现过期的任务。<br><img src="/2023/04/10/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E5%92%8C%E5%BA%94%E7%94%A8/timing_wheel.png"></p><p>这种方案的时间复杂度:</p><ul><li>开始调度一个任务(start_timer): 来一个新的调度任务时，换算任务的到期时间为到期值(Interval)，直接放入相应的数组元素内即可，时间复杂度是O(1)。</li><li>时钟走一格，需要做的操作(per_tick_bookkeeping)：时钟走一格直接拿出这一格内的任务执行即可，时间复杂度是O(1)。</li></ul><h2 id="方案5-hash有序时间轮"><a href="#方案5-hash有序时间轮" class="headerlink" title="方案5: hash有序时间轮"></a>方案5: hash有序时间轮</h2><p>方案4虽然很完美，所有的操作时间复杂度都是O(1)，但是当任务最大到期时间值非常大时，比如100w个时，构建这样一个数组是非常耗费内存的。可以改进一下，仍然使用时间轮，但是是用hash的方式将所有任务放到一定大小的数组内。 这个数组长度可以想象为时间轮的格子数量，轮盘大小(W)。</p><p>hash的数值仍然是每个任务的到期值(Interval)，最简单的是轮盘大小(W)取值为2的幂次方，Interval哈希W后取余，余数作为轮盘数组的index，数组每个元素可能会有多个任务，把这些任务按照过期的绝对时间排序，如方案二一样，最先过期的排在最前面，这样就形成了一个链表，或者叫做时间轮上的一个桶。<br><img src="/2023/04/10/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E5%92%8C%E5%BA%94%E7%94%A8/timing_wheel_sorted.png"><br>这种方案的时间复杂度：</p><ul><li>开始调度一个任务(start_timer): 来一个新的调度任务时，换算任务的到期时间为到期值(Interval)，hash 一下时间轮的轮盘大小，放置在余数为index的格子内，同时需要放置有序列表合适的位置上，这样最坏的时间复杂度为O(n)(放置的位置刚好在列表最后的一个元素)，最好的时间复杂度为O(1)(放置的位置在列表的第一个位置)。平均时间复杂度为O(1)，当轮盘大小(W) &gt; 所有任务的个数n时，并且hash函数能将所有任务均匀的分布在每个数组内。</li><li>时钟走一格，需要做的操作(per_tick_bookkeeping)：时钟走一格直接拿出这一格内的任务列表，从列表开头开始拿出任务过期时间的绝对值和当前时间做对比，过期的直接拿出，触发过期操作。</li></ul><h2 id="方案6-hash无序时间轮"><a href="#方案6-hash无序时间轮" class="headerlink" title="方案6: hash无序时间轮"></a>方案6: hash无序时间轮</h2><p>因为方案5在执行添加任务时，需要和hash 在同一时间格子内的有序任务列表内的元素做比较，放在合适的位置上，最坏时间复杂度是O(n)。如果要摆脱这个问题，需要可以将数组元素内的列表作为无序列表。<br>开始调度一个任务(start_timer): 来一个新的调度任务时，换算任务的到期时间为到期值(Interval)，hash 一下时间轮的轮盘大小，放置在余数为index的格子内，商值保存在任务内，因为余数数组元素内的列表是无序数组，直接放置在末尾即可，时间复杂度是O(1)。<br>时钟走一格，需要做的操作(per_tick_bookkeeping)：时钟走一格直接拿出这一格内的任务列表，从列表开头开始，逐个检查列表内的元素，如果商值为0，则直接过期数组，如果非0，则需要做减一操作，等待下一个时钟周期。这里的最坏时间复杂度为O(n)，因为需要遍历列表内的每一个元素。平均时间复杂度是O(1)，当轮盘大小(W) &gt; 所有任务的个数n时，并且hash函数能将所有任务均匀的分布在每个数组元素内。<br><img src="/2023/04/10/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E5%92%8C%E5%BA%94%E7%94%A8/timing_wheel_unsorted.png"></p><h2 id="方案7-多级时间轮"><a href="#方案7-多级时间轮" class="headerlink" title="方案7: 多级时间轮"></a>方案7: 多级时间轮</h2><p>这个方案是直接模拟时钟，将天、小时、分钟、秒作为4个不同的时间轮，每个时间轮都有一个单独的数组，来模拟时间轮盘。</p><p>注意，这个方案的核心思想是将最大过期时间值Max(Interval)按级别，分散在不同的时间轮内来标识，以此来用比较少的数组元素来表示最大值Max(Interval)的过期时间。秒级时间轮转一圈刚好是1分钟，分钟级时间轮转一圈是一小时，小时级时间轮转一圈是一天，天级时间轮转一圈可以是100天或1年，轮盘大小可以根据需要承接的最大时间段来确定。比如天级轮盘大小设置为100，小时级设置未24消息，分钟、秒级都设置为60个，那么可以承接的最大过期时间值Max(Interval)(每级轮盘不超额放置)将是100*24*60*60=864万，而实际底层存储我们只使用了100+24+60+60=244大小的数组。</p><p>时间轮驱动是由最小级开始的，秒级时间轮转一圈，分钟级时间轮转一个格子。分钟级时间轮转一圈，小时级时间轮转一个格子，小时级时间轮转一圈，天级时间轮转一个格子。假设一个任务的过期时间是3天，10小时，15分，10秒。那么天级时间轮也是拿时间段来hash轮盘大小，比如 hash 完是3那么就放到第3个格子，小时级时间轮同样的做hash余数作为数组的index，放置到相应的格子内，依次类推。当天级时间轮，过期一个时间时，需要将任务踢到下级时间轮，看是否在下级时间轮的范围时间内，如果能放进去，则继续用下级时间轮来推动，否则再继续往下级时间轮来踢，如果所有的时间轮都无法承接这个过期任务了，那么就启动定时任务。还拿这个任务来做例子，如果天级时间轮发下，3天已经过完了，就会把这个任务踢到小时级时间轮，小时级时间轮发现10小时、15分、10秒在自己可以承担的时间范围内，则放到相应的格子内。10小时过完以后，小时级时间轮又会把这个任务踢到分钟级，分钟级过完后，又会踢到秒级，秒级过完后，发现已没有更下级时间轮了，就直接启动定时任务。<br><img src="/2023/04/10/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E5%92%8C%E5%BA%94%E7%94%A8/timing_wheel_hiatarch.png"><br>这种方案的时间复杂度：</p><ul><li>开始调度一个任务(start_timer): 来一个新的调度任务时，换算任务的每个级别，天、小时、分、秒的到期时间为到期值(Interval)，hash 一下时间轮的轮盘大小，放置在余数为index的格子内，时间复杂度是O(1)。</li><li>时钟走一格，需要做的操作(per_tick_bookkeeping)：时钟走一格直接拿出这一格内的任务列表，从列表开头开始，逐个检查列表内的元素，检查任务是否还有下级时间轮，没有的话直接过期任务，有的话踢到下级时间轮内，比如某个任务的过期时间是3min50后，那么个任务会存储在分钟时间轮3那个桶里，当这个桶过期后，查看剩余的时间是否能放到下一级时间轮，发现剩余50min 就将任务放到秒级时间轮的50那个桶里，等待过期；并且这个方案的平均时间复杂度是O(1)，前提是当轮盘大小(W) &gt; 所有任务的个数n时，并且hash函数能将所有任务均匀的分布在每个数组元素内。</li></ul><blockquote><p>注意：在n&lt;W时，即过期任务个数小于轮盘大小W时，方案6、7的平均时间复杂度都是O(1)，但是在时钟每走一格，需要做的操作里(per_tick_bookkeeping)，方案6和方案7会有一些细小的区别，会影响到方案选择：</p><p>设T为所有过期任务的平均时长跨度(开始到结束的时间间隔)<br>设M为所有数组的元素个数总和，即时间轮大小<br>设m 为多层时间轮的层数</p><p>那么方案6里，每个任务的总用时间为：<br>c(6)*T/M<br>c(6)是时钟每走一格，需要将任务递减1需要的用时。如果任务需要递减T/M次，那么任务的总用时就是c(6)*T/M。</p><p>相对于方案7，每个任务的总用时间为:<br>c(7)*m<br>c(7)是踢到下一级时间轮的用时，m 是时间轮的最大层级，所以每个任务的总用时即c(7)*m</p><p>如果有 n 个定时任务，那么每个时间单位内的任务的用时是:<br>方案6是:   n*c(6)/M<br>方案7是:   n*c(7)*m/T</p><p>因为c(6),c(7)两项的用时基本是常数，m值也不会很大(因为层级不可能很多)，这样一比较就会发现，虽然方案6、方案7的start timer都一样，时间复杂度都是O(1)，但(per_tick_bookkeeping)还是有差别的(虽然平均时间复杂度都是O(1))，根据上边的公式，如果M大那么应该选方案6(除数大)，如果T大应该选方案7。</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>综合比较一下上述的5个方案:</p><table><thead><tr><th>方案</th><th>start_timer</th><th>stop_timer</th><th>per_tick_bookkeeping</th><th>备注</th></tr></thead><tbody><tr><td>方案1：无序列表</td><td>O(1)</td><td>O(1)</td><td>O(n)</td><td></td></tr><tr><td>方案2：有序列表</td><td>O(n)</td><td>O(1)</td><td>O(1)</td><td></td></tr><tr><td>方案3：树、堆结构列表</td><td>O(log(n))</td><td>O(1)</td><td>O(1)</td><td></td></tr><tr><td>方案4：简单时间轮O(1)</td><td>O(1)</td><td>O(1)</td><td>当时间跨度很大时，比较耗内存。</td><td></td></tr><tr><td>方案5：hash 有序桶时间轮</td><td>O(n)最坏情况</td><td>O(1)平均时间复杂度</td><td>O(1)</td><td>O(1)</td></tr><tr><td>方案6：hash无序桶时间轮</td><td>O(1)</td><td>O(1)</td><td>O(n)最坏情况  O(1)平均时间复杂度</td><td>[1]*</td></tr><tr><td>方案7：多层时间轮O(m)</td><td>O(1)</td><td>O(1)平均时间复杂度</td><td></td><td></td></tr></tbody></table><p>[1]*per_tick_bookkeeping占用时间:     时间轮轮盘比较大时选择方案6，任务的平均过期时间长度比较长时选择方案7</p><p>比较上边几个方案，从时间复杂度来看，最好选择方案5、6、7。但是方案5在创建一个调度任务时，会有最坏的时间复杂度O(n)。在方案6和方案7之间作比较，在设定比较大的轮盘值W时(W&gt;n)，并且任务均匀的散列到每个桶内时，都会有一个比较好的最好时间复杂度O(1)，但是对于时间跨度比较大的情况(T&gt;W)时，选择方案7会比较好，在时间跨度比较小(T&lt;W)时，选择方案6会稍微好一些。</p><p>举个例子，对于最高峰值10000 qps的服务，检查每个请求是否在2s内过期，设定tick为1ms，T 的最大值为2000(ms)，相对于方案7中的例子，时间跨度并不是很大，在选择轮盘大小时，我们甚至可以设置W为2048，依据上边的公式比较，所以选择方案6 会更合适。实际在现实例子中，使用时间轮来调度定时任务时，时间跨度都不会很大因此T一般都会小于W，所以方案6在绝大多数场景下都适用。</p><h1 id="java中的几种实现"><a href="#java中的几种实现" class="headerlink" title="java中的几种实现"></a>java中的几种实现</h1><p>下面来看下几种典型的定时调度算法实现 :</p><h3 id="java-Timer"><a href="#java-Timer" class="headerlink" title="java Timer"></a>java Timer</h3><p>这是java库里最基础的，如文章开头所述有2个问题，不能调度太多的任务，而且精度也不准。根据java api文档，其内部实现是一个二叉堆，调度一个任务的时间复杂度是O(logn)</p><h3 id="java-ScheduledThreadPoolExecutor"><a href="#java-ScheduledThreadPoolExecutor" class="headerlink" title="java ScheduledThreadPoolExecutor"></a>java ScheduledThreadPoolExecutor</h3><p>这是java 5 开始引入的一个定时调度器，用来代替之前的Timer和TimerTask组合，这个调度器可以指定多个线程来执行调度任务。另外执行调度任务时，还可以catch住任务抛出的异常，还 不会影响其他任务的调度。另外还可以重载他的afterexecute方法来对异常做处理。</p><h3 id="Netty时间轮io-netty-util-HashedWheelTimer"><a href="#Netty时间轮io-netty-util-HashedWheelTimer" class="headerlink" title="Netty时间轮io.netty.util.HashedWheelTimer"></a>Netty时间轮io.netty.util.HashedWheelTimer</h3><p>这是上边所述的方案6的典型实现，hash 时间轮加无序桶。 默认的时间轮盘值是512，tick time是100ms。如上所述，因为现实使用中，时间跨度度不会很大，方案6是适用于现实中绝大多数定时任务调度场景。</p><h3 id="Kafka内置的时间轮"><a href="#Kafka内置的时间轮" class="headerlink" title="Kafka内置的时间轮"></a>Kafka内置的时间轮</h3><p>这是上边所述的方案7的典型实现，多级时间轮。kafka使用这个时间轮来实现消息的延迟生产、拉取等longpoll操作。</p>]]></content>
    
    
    <summary type="html">本文分析了hash和多层时间轮算法的实现原理和应用</summary>
    
    
    
    
    <category term="kafka netty 时间轮" scheme="https://wangjunfei.com/tags/kafka-netty-%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>Kafka去Zookeeper揭秘</title>
    <link href="https://wangjunfei.com/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/"/>
    <id>https://wangjunfei.com/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/</id>
    <published>2021-11-30T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.776Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Kafka为什么要去Zookeeper-？"><a href="#一、Kafka为什么要去Zookeeper-？" class="headerlink" title="一、Kafka为什么要去Zookeeper ？"></a>一、Kafka为什么要去Zookeeper ？</h2><h2 id="Zookeeper的作用"><a href="#Zookeeper的作用" class="headerlink" title="Zookeeper的作用"></a>Zookeeper的作用</h2><p><strong>1 .依赖Zookeeper的一致性选举</strong></p><p>Kafka集群有多个节点组成，在管理集群级别的任务和数据时，必须有一个主来充当指挥者，Kafka内将这个主节点命名为Controller。在集群第一次启动或是Controller宕机时，集群内每个节点都会去争取当选Controller，在复杂网络环境下，要形成一个一致性的选举结果，目前这个任务是交由Zookeeper来完成的，各个节点在Zookeeper上抢占一个临时节点来当选，Kafka集群内部并未实现一致性协议。类似的主节点选举还包括每个分区的主副本(leader replica)。</p><p><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/zk_status.svg"></p><p><strong>2 .依赖Zookeeper的存储和Listener监听回调</strong></p><p>Kafka的元数据，比如topic，partition，AR(assiged replica)，ISR，consumer等信息都存储在Zookeeper上，由Controller负责管理。另外，Controller还注册了很多监听器(Listener)，比如创建topic，扩容<br>parttion，ISR发生变化，broker节点上下线，partition重新分配，删除topic等，都是由admin工具或broker先在Zookeper上挂节点，触发Controller的监听器回调，由Controller执行具体的操作。</p><h2 id="使用Zookeeper的劣势和不足"><a href="#使用Zookeeper的劣势和不足" class="headerlink" title="使用Zookeeper的劣势和不足"></a>使用Zookeeper的劣势和不足</h2><h3 id="元数据加载速度慢"><a href="#元数据加载速度慢" class="headerlink" title="元数据加载速度慢"></a>元数据加载速度慢</h3><p>上边说过，Zookeeper存储了Kafka集群所有的元数据，集群的Controller每次启动时，都需要将所有的元数据从Zookeeper上全量拉取一次，试想当集群的broker节点、topic、consumer或partition数量线性增⻓<br>起来后，每次加载全量元数据的时间势必会很⻓，在此之间Controller是无法响应和工作的，这样势必会影响整个集群的可用性。此外zookeeper也不适宜存储大量的数据，读写qps的增加，以及leader和follower的<br>切换，很容易造成⻓时间的java gc停顿，影响Z ookeeper的可用性。所以元数据加载慢这个问题，直接影响了集群的大小，比如集群内节点数量不能很多，partition数量不能很大，比如超过 100 万个。</p><h3 id="数据一致性问题"><a href="#数据一致性问题" class="headerlink" title="数据一致性问题"></a>数据一致性问题</h3><p>上边说到，Controller会加载集群的所有元数据信息到内存内，加快读取速度，但是当集群的元数据需要变更时，Controller需要先将变更结果存储在Zookeeper上，再更新到本机内存，分成两步去操作和执行，这样做在实际运营过程中，很容易产生Zookeeper和内存数据不一致，甚至controller和其他节点的数据不一致，对集群可用性造成影响。另外，Controller在获取集群操作任务时，大多是由admin工具或其他broker在Zookeeper上挂节点，然后触发Controller的回调，回调执行完成后，再挂相应的watcher，整个过程中，很有可能漏掉一些watcher事件。所有这些问题产生的Zookeeper和内存数据的不一致，最终都必须重启<br>Controller节点来重新全量加载Zookeeper数据，来恢复整个集群的数据同一致性。</p><h3 id="多维护一个组件"><a href="#多维护一个组件" class="headerlink" title="多维护一个组件"></a>多维护一个组件</h3><p>使用Zookeeper还会带来另外一个问题，多维护一个组件，对于当今企业应用要求来说，这不仅意味着多一个不稳定因素，Zookeeper的不可用会导致Kafka的不可用，另外还需要一个team来维护zookeeper服务，增加⻛险和成本。</p><h2 id="二、Kafka去Zookeeper架构概览"><a href="#二、Kafka去Zookeeper架构概览" class="headerlink" title="二、Kafka去Zookeeper架构概览"></a>二、Kafka去Zookeeper架构概览</h2><p>使用Z ookeeper的K afka集群架构如下图所示，集群在部署的时候，除了部署Kafka集群外，还需要部署一个Zookeeper集群，Kafka集群每个节点都会有写入Zookeeper操作，除此之外，只有Controller才会读取Zookeeper上存储的元数据。</p><p><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/now_arch.svg"></p><p>去除Zookeeper以后的集群部署如下：</p><p><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/arch1.svg"></p><p>集群有 5 个节点，BrokerA和BrokerE是普通的节点，BrokerB、BrokerC、BrokerD是单纯的Controller节点。这里Controller是指一个⻆色，这三个Controller节点组成了一个一致性集群(Quorum)，三个节点会通过Raft算法选出一个Active的C ontroller担任整个集群真正的Controller，当Controller节点宕机或下线后，会重新选出一个新的Controller节点。</p><p>或是以下方式部署，每个Controller节点还可以同时起一个普通节点进程，在同一个Jvm内，但是在不同端口来接受服务请求。<br><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/arch2.svg"></p><p>去除Zookeeper之后，需要在部署集群节点时，在配置文件内写清楚每个节点的⻆色(Role)，如果是Broker，就是普通节点，如果是Controller则是Controller节点，如果两个都有，则在同一个JVM内启动两个⻆色<br>的实例。同时还要写清楚集群Quroum的每个节点的IP，以及集群cluster ID等信息。</p><p><strong>集群数据存储方面，</strong> 集群的topic、consumer、partition等信息，从创建到变更都存储在Raft Log（相关的Raft背景知识可以先了解下）里，为了和原有的Kafka Log保持一致性和兼容，这里的RaftLog直接使用了Kafka原有Log的格式，并追加了一些特殊字段，除此之外可以理解为普通的Topic Log，但是只有一个partition，而且没有副本，没有partition leader。普通Broker节点会通过监听器，(从本机Raft层)实时接收最新的元数据变更信息，并应用到自己的metadata cache内，供本机使用。</p><p><strong>任务监听回调方面，</strong> 之前需要Controller监听Zookeeper节点所做的任务，比如Broker节点的上下线，是通过Broker节点和Active Controller节点之间的心跳来达成变更的，其他的比如创建topic、consumer、扩容partition等集群内任务，如果发到了普通节点，都会被转发给Active的Controller来执行，Active Controller将执行结果通过运行Raft算法来复制到Quorum的其他节点上，数据会在被各节点真正Committed（Raft Committed，这里需要了解一些Raft背景知识）之后，应用到本机的状态机内，形成metadata cache。</p><p>去除Zookeeper之后，集群的元数据在Quorum节点之内会以Raft Log方式来复制，因此当Controller宕机之后，新选出来的Active Controller本地就有全量数据，不需要再从其他节点拉取，这样就解决了上一部分说的“元数据加载慢”的问题，第二因为现在的元数据是以Raft Log的方式来存储和复制，也不存在“内存和Zookeeper”之间数据不一致的问题，由Raft来保障集群内所有节点上的元数据一致性。最后，去除了Zookeeper之后，因为数据就在Kafka内部，也不需要额外再维护另外一个组件。</p><h2 id="三-Kafka-Raft-算法"><a href="#三-Kafka-Raft-算法" class="headerlink" title="三. Kafka Raft 算法"></a>三. Kafka Raft 算法</h2><p>如果大家对Raft算法比较了解，我们拿Kafka Raft和传统的Raft算法做一个对比，就会比较容易理解。</p><h3 id="标准Raft算法"><a href="#标准Raft算法" class="headerlink" title="标准Raft算法"></a>标准Raft算法</h3><p>传统的Raft算法如下图</p><blockquote><p>*下图引用自Raft paper</p></blockquote><p><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/raft.png"></p><h4 id="⻆色分类"><a href="#⻆色分类" class="headerlink" title="⻆色分类"></a>⻆色分类</h4><p> 为了更容易理解，我们把分布式一致性场景分为两种，一种是“正常场景”，就是服务正常运行期间，没有机器宕机，没有机器上下线，没有网络分区。另外一种是“异常场景”，就是前边说的反面，发生宕机，发生机器上下线，发生网络分区。</p><p>正常场景下，Raft集群内所有节点只有 2 中⻆色，Leader 和 Follower。</p><ul><li>leader: 集群内只有一个leader，负责接收客户端的请求，发送AE(AppendEntries)请求给follower，复制command或发送心跳。</li><li>Follower：被动接受leader发来的心跳请求或是复制过来的command.</li></ul><p>异常场景下，多了一种状态candidate</p><ul><li>candidate: 当某个节点决定参与leader选举时，会转换为这个状态。</li></ul><h4 id="⻆色转换"><a href="#⻆色转换" class="headerlink" title="⻆色转换"></a>⻆色转换</h4><ul><li>Follower: 一个节点进入Quorum集群后，就是Follower状态，当经过election timeout 时间后还未收到AE请求的话，那么就转换为Candidate状态。</li><li>Candidate: 当经过election timeout时间后，还未选举出Leader，重新进入Candidate状态，触发新一轮选举。</li><li>Leader：当Candidate收集到足够多的Votes之后，就转换为Leader状态。如果Leader在接收到AppendEntries响应之后，发现了新的Epoch，那么就转换为Candidate状态。</li></ul><h4 id="提交流程"><a href="#提交流程" class="headerlink" title="提交流程"></a>提交流程</h4><ol><li>客户端发送submit请求(包含的具体内容是command)给leader.</li><li>leader保存command到本地log里作为一个新的entry.</li><li>leader发送AppendEntries请求给集群内其他的server，</li><li>当Leader收集到集群内多数派server的正确响应后，将comand应用到本地状态机。</li><li>leader将上一步中状态机返回的结果返回给客户端</li></ol><h4 id="RPC请求类型"><a href="#RPC请求类型" class="headerlink" title="RPC请求类型"></a>RPC请求类型</h4><ol><li>AppendEntries 请求(简称AE请求): Leader发送给Follower的请求，不仅用来复制Raft Log，同时也用作心跳探活请求<ul><li>参数：term、leaderId、prevLogTerm、prevLogIndex、leaderCommit、entries</li><li>处理逻辑：Follower检查自己的Log是否符合p revLogTerm、prevLogIndex，如果不符合的话，说明发生日志分歧，返回给leader追加日志失败。如果符合的话，追加自己的Log里。检查Leader发送来的leaderCommit index和自己Log里的最大index，两者取最小值作为自己最新的commitIndex，前进的index所附带的entries是本次新的committed entry，状态机监听到以后会apply这些entry内附带的command。</li></ul></li><li>RequestVote 请求(简称Vote请求)</li></ol><ul><li>参数：candidateTerm、candidateID、LastLogIndex、LastLogTerm</li><li>处理逻辑：如果candidateTerm大于小于本机Term则直接拒绝，如果本机Term和candidateTerm相等，candidate的lastLogTerm大于本机logTerm，或者这两个term相等而且candidate的l astLogIndex大于本机logINdex，这返回成功，赞成这个选举，否则返回失败。</li></ul><h3 id="Kafka-Raft算法"><a href="#Kafka-Raft算法" class="headerlink" title="Kafka Raft算法"></a>Kafka Raft算法</h3><p>Kafka Raft里节点的状态转换如下图所示，但是注意下，这个是KIP里计划的，实际上Kafka 3.0版本代码实现上没有Observer这个⻆色，也没有Observer到Voter的转换，这几个功能还未真正实现。</p><p><strong>在Kafka Raft里，一些概念有不同的名词。比如Raft里的term，在kafka里称为epoch，Raft里的log index，在Kafka Raft里称之为offset</strong></p><blockquote><p>*下图引用自Kafka KIP-595</p></blockquote><p><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/kraft.png"></p><h4 id="⻆色分类-1"><a href="#⻆色分类-1" class="headerlink" title="⻆色分类"></a>⻆色分类</h4><p>正常场景下，整个quorum里的⻆色包含以下几个：</p><ul><li>leader：接受客户端请求。注意这里的客户端不是指kafka生产消费消息的客户端，是指controller，controller在处理一些集群内管理事务时，会生成一些command，这些command 会提交给 leader，运行一次raft算法。</li><li>follower：主动从leader上拉取command，注意这点跟Raft是不一样的，在Raft里follower是一个被动⻆色，等待leader的AE请求。</li><li>observer：不参与抢主，也不参与投票，只从leader拉取command，类似zookeeper里的observer，作为一个状态机的只读节点。注意，虽然KIP-595里定义了这个⻆色，到目前为止，在 3 .0版本的实现里它实际上是一个状态为unattached的节点。</li></ul><p>异常场景下，会多几个⻆色：</p><ul><li>unattached：脱离状态的节点，一般是刚上线的新机器，之前没有参与过集群的任何事务，注意这个状态是代码实现里有的，没有在上图里标识出来。</li><li>candidate: 某个节点决定竞选leader后，会转换为这个状态。</li><li>voted：某个节点投了票之后会转换为这个状态</li><li>resigned：集群的leader准备卸任时，会转换为这个状态。注意这个状态是代码实现里有的，没有在上图里标识出来。<br>总结下，Kafka Raft里每个节点会有 7 种状态，比原生Raft多出了 4 个状态observer、unattached 、voted和resigned.</li></ul><h4 id="⻆色转换-1"><a href="#⻆色转换-1" class="headerlink" title="⻆色转换"></a>⻆色转换</h4><ol><li>Unattached: 这是节点启动的初始状态，任何一个节点启动来后，会先进入这个状态。 如果当前节点为Voter（也就是⻆色配置为Controller的节点），经过election timeout的时间后转换为Candidate。如果当前节点不是Voter，则发起拉取FR(FetchRequest)请求。</li><li>Candidate：经过election timeout之后，开始进行back off，给与其他Candidate发起Vote的机会，这里就是Raft paper中说到的Random时间发起Vote。如果在election timeout之内的话，会发起Vote请求。<br>如果在back off 时间结束之后的话，会再次转换为Candidate，继续发起新一轮Vote。 在收到多数派节点的Vote支持之后，当选为Leader，转换为Leader状态。</li><li>Voted：经过election timeout之后，转换为unattached状态，否则继续等待。</li><li>Leader：在收到resign请求后，转换为resigned状态。</li><li>Follower：经过election timeout 之后，转换为Candidate参与选举，否则发送FR请求，从Leader拉取最新的增量数据（依据上次拉取的Offset）。</li><li>Resigned：leader在收到 resign请求后，会转换为这个状态，然后跟其他节点发送EndQuorum请求，代表卸任这个leader任期。</li><li>Observer：Kafka 3.0版本中未实现这个⻆色。</li></ol><h4 id="提交流程-1"><a href="#提交流程-1" class="headerlink" title="提交流程"></a>提交流程</h4><ol><li>Active Controller执行了一些集群内的任务，如果需要写入metadata数据的话，会提交给Raft leader（也就是Active Controller）。</li><li>Follower发起Fetch请求，从Leader拉取自上次请求之后的新增数据，依据上次拉到的offset，leader返回新追加的数据。Leader查看Follower请求中的offset，比较多数派拉到的最小offset，前进<br>HighWaterMark，这里指的是标识已经被committed的数据。</li><li>Unattached节点，也就是当前 3.0版本中的普通节点Broker，也会发起FR操作，从Leader拉取自上次请求之后的新增数据，具体处理流程和Follower相同。</li><li>Follower和Unattached节点上，如果有增量的committed的数据，则会触发本机的metaDataListener的接收数据操作，这里的metaDataListener就是注册在Raft上的committed数据监听器。接收到的新数据会更新到本机的metadata cache中，供节点读取使用。</li></ol><h4 id="RPC请求类型-1"><a href="#RPC请求类型-1" class="headerlink" title="RPC请求类型"></a>RPC请求类型</h4><ol><li>Vote请求</li></ol><ul><li>参数：candidateEpoch、candidateId、lastOffsetEpoch、lastOffset</li><li>处理逻辑：处理逻辑和普通的Raft算法相同。</li></ul><ol start="2"><li>BeginQuorum请求：leader发给q uorum里其他voter的请求。注意这个请求是标准R aft里没有的。其实这个请求的目的就是广播新当选的leader，因为在标准Raft里，心跳是由leader发出的，所以leader当选后发出心跳即可广播整个集群的新leaderID和leaderEpoch。但是kafka Raft在正常场景下都是依靠拉取(pull)来获得新的log的，没有从Leader发出的主动心跳请求，所以单加了这个。</li></ol><ul><li>参数：leaderId、leaderEpoch</li><li>处理逻辑：查看本机epoch是否和leader的e poch相同，不同的话更新epoch，转换为follower⻆色。</li></ul><ol start="3"><li>EndQuorum请求：Kafka Raft新加的一个请求，作用是加速leader的优雅关闭。比如l eader在优雅关机的情况下，可以发出这个请求，主动通知其他Voter发起选举。如果么没有这个请求的话，其他Voter需要等待election timeout的而时间后才会发起新的选举，这无疑会延⻓集群无leader的时间。</li></ol><ul><li>参数：leaderId、leaderEpoch、preferredSuccessors</li><li>处理逻辑：接收到这个请求的voter会主动转换为candidate时间，但是会有一个不同的等待时间，这个等待时间是老的leader通过p referredSuccessors传给他的voter的。</li></ul><ol start="4"><li>Fetch请求：这个是与标准Raft区别最大的地方，标准Raft是通过leader主动发起AE请求( push模式)给他节点，一方面复制log使用，另一方面作为心跳探活来使用。但是Kafka Raft是pull模式，所以log的拉取是依靠follower主动发起到leader的请求。这里需要介绍下Kafka Raft的snapShot，如下图所示，snapShot是Kafka节点里Kafka Raft的本机metadata数据的一个全量快照。Kafka会根据设定好的新增数据最大量来确定是否在log里某个offset新创建一个snapShot。<br><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/snapshot.svg"><br>另外一个是在处理拉取请求时，leader需要比较Follower的日志状态。如下图所示，有些Follower的日志可能比leader少，比如(a)(b)。有些可能多，比如(c)(d)。有些情况有多又少，比如(e)(f)。leader需要根据不同的情况来处理，有些需要发送snapShot，有些需要告诉follower截取日志，有些正常的拉取，leader和follower根据请求和返回来前进自己的highWaterMark。</li></ol><blockquote><p>*下图引用自Raft paper</p></blockquote><p><img src="/2021/12/01/Kafka%E5%8E%BBZookeeper%E6%8F%AD%E7%A7%98/log.svg"></p><ul><li>参数：currentLeaderEpoch、fetchOffset、lastFetchEpoch、logStartOffset</li><li>处理逻辑：follower的fetchOffset如果不在leader的log范围之内，说明是新加入的follower或者是follower因为什么原因log差距太远了，这种情况下leader会返回响应，让follower再次发起一个拉取snapShot的请求。第二种情况是拉取leader检查出follower的lastFetchEpoch和fetchOffset与leader本机的log不匹配，发生了日志分歧，这时leader会返回一个调度日志的epoch和offset。最后一种情况是，follower拉取的offset范围是正常的，这时leader会返回上次拉取到当前的新增数据，如果没有的话，就等待一个时间。如果拉取到数据了，这时leader就可以检查多数派已经拉到的offset index，前进自己的highWaterMark。<br>Follower在接收到leader的响应后，如果是要拉取snapShot，就发送snapShot拉取请求。如果发生了日志分歧，就开始截取日志，然后再发起拉取请求。如果是正常的返回，则比较leader返回的highWaterMark和本机的highWaterMark，看自己是否需要更新。</li></ul><h2 id="三-Kafka-Raft思考和前瞻"><a href="#三-Kafka-Raft思考和前瞻" class="headerlink" title="三. Kafka Raft思考和前瞻"></a>三. Kafka Raft思考和前瞻</h2><p>以上就是Kafka去除Zookeeper的架构变更，和Kafka Raft的细节。虽然Kafka 2.8版本已经发布了KRaft模式作为Kafka 去除Z ookeeper预览，但是仍有一些重要的feature未实现。比如Quorum内节点替换，还有从非Raft模式到Raft模式的平滑滚动升级，这两项在实际的生产集群运营中都是必须的功能。</p><p>此外，Kafka Raft整个模块的实现，相对与整个Kafka系统来说相对独立，只有log层是和原有的Kafka log是共用，因此可以考虑抽离整个模块做成一个单独的lib库，替换一些服务依赖Zookeeper做一致性的功能，随服务一起发布。但这里有三个问题，第一，服务之前可能是无状态的，因为添加了Kafka Raft lib库之后变成了有状态服务，这样服务器的批量启停和替换必须得额外注意，不能全部关闭，因为Raft Quorum需要一定数量的节点才能运行。第二，因为Kafka Raft依赖磁盘来存储Raft log，而且每次追加Log时，必须是刷盘操作，因此对磁盘的性能和空间有一定的要求。第三，Zookeeper中实现的临时节点抢占操作、Listener回调等语义需要通过变通的方法来解决，因为原生Kafka Raft内没有这些api。</p><p>参考:</p><ol><li>KIP-595 、KIP-631</li><li>Raft paper</li></ol>]]></content>
    
    
    <summary type="html">本文研究分析了kafka去zookeeper的实质，分析了kafka raft算法和普通raft的区别</summary>
    
    
    
    
    <category term="kafka raft kraft zookeeper" scheme="https://wangjunfei.com/tags/kafka-raft-kraft-zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>「转」PRFAQ编写规范</title>
    <link href="https://wangjunfei.com/2021/09/15/PRFAQ%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/"/>
    <id>https://wangjunfei.com/2021/09/15/PRFAQ%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/</id>
    <published>2021-09-14T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.787Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本规范 旨在明确PR-FAQ文档的内容的规范性，提升PR-FAQ文档的质量，帮助基础技术部人员撰写标准的PR-FAQ。如需提升PRFAQ写作能力，可以详细参考附录提供的指导及范例。</p><h2 id="写作原则"><a href="#写作原则" class="headerlink" title="写作原则"></a>写作原则</h2><ol><li>写作⻛格：准确精炼，行文要求按照商业写作⻛格，避免营销⻛。</li><li>写作立场：实事求是，立场要求中立、客观，可以接受任何人的挑战。</li><li>写作逻辑：逻辑严谨，要求全文整体逻辑、段落逻辑、语句内逻辑的均严谨。</li></ol><p><strong>名词解释</strong></p><figure class="highlight stata"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">PR</span>-FAQ： <span class="keyword">PR</span>（Press Release，新闻稿）+ FAQ（Frequently Asked Questions，常⻅问题解答） + 附录（引入数据、产品草图、架构图等）。<span class="keyword">PR</span>-FAQ是逆向工作法思维的典型应用，在项目正式开始前通过撰</span><br><span class="line">写新闻稿/常⻅问题解答的方式，阐明并定义项目的用户、用户的问题、对用户的收益、用户体验，以及项目对公司的价值、项目边界。使用该文档可以和相关人员有效沟通、对⻬认知。简而言之，<span class="keyword">PR</span>-FAQ可以理</span><br><span class="line">解为浓缩版本的“商业计划书”，撰写方法参考这篇文章。</span><br></pre></td></tr></tbody></table></figure><h2 id="PR-FAQ文档规范"><a href="#PR-FAQ文档规范" class="headerlink" title="PR-FAQ文档规范"></a>PR-FAQ文档规范</h2><h3 id="PR-FAQ组成部分"><a href="#PR-FAQ组成部分" class="headerlink" title="PR-FAQ组成部分"></a>PR-FAQ组成部分</h3><p>PR-FAQ文档由三个部分组成：</p><ol><li>使用以客户为中心的语言概括性描述创意的新闻稿（PR）</li><li>客户和内部合作方可能询问的常⻅问题（FAQ）</li><li>以及帮助沟通创意的图例等组成的附录</li></ol><p>这三个部分在整个产品生命周期中经过组合和迭代，可提高理念的清晰度，并促进内部沟通效率。</p><h3 id="PR-FAQ写作规范"><a href="#PR-FAQ写作规范" class="headerlink" title="PR-FAQ写作规范"></a>PR-FAQ写作规范</h3><p>####PR写作规范</p><ol><li>标题 - - Heading<ul><li>a. 内容提要: 短小精悍的描述（最后写标题）。</li><li>b. 一句话总结 （要点）：描述你正在推出的产品以及客户将获得的最重要的好处（提示：这是你的电梯游说，保持简单）。</li><li>c. 日期: 你未来的发布日期（例如， 2020 年 6 月 1 日）。这告诉读者它尚未启动并设定启动时的期望。</li><li>d. 副标题：一句话总结。</li></ul></li><li>第一段 - — Summary：是什么的摘要简介 。假设这个人不会读完整篇新闻稿，所以第一段突出重点！不要啰嗦。<ul><li>a. 从客户出发： 正文第一句话准确地说明客户是谁以及你将提供的好处。例如，美团的用户现在可以提前一天知道新的餐馆位置，得到热⻔产品额外的优惠。</li><li>b. 描述你将/正在发布的产品： 使用客户能理解的词语。 在命名你的产品或服务之前，请说它是什么。 如果必须为你的产品或服务命名，请将名称放在［括号］中。</li></ul></li><li>第二段 - — Problem ： 机遇或问题需要以客户为中心 。清楚地解释需要解决的机会或问题。不要错误地放大问题或机会。实事求是，但引人注目。避免夸张。</li><li>第三段 - — Solution：途径或解决方案。 明确说明你如何充分利用客户的机会或如何解决客户问题的愿景。</li><li>第四段 - — Citing：引用一位美团领导人的话。 不要捏造事实。从美团领导者那边获得真实评价。 这表明你支持自己的想法。 领导者评价应该能够捕捉到将要提供给客户的价值（提示：要获得评价，请与领<br>导分享新闻稿的早期版本）。</li><li>第五段 - — Experience：描述客户体验 。描述客户将如何发现和使用你的建议以及他们将获得的价值。你写这段话的目的是激励读者去尝试。</li><li>第六段 - — Testimonial：客户证词 。这个是编造的，但应该是具体的、可信的，听起来像一个人说的。 使用推荐书来强化客户关心你发布内容的原因。</li><li>第七段 - — Call to action：行动呼吁。 引导读者到他们可以去的地方（例如，链接）。</li><li>⻚脚: 在底部包含“机密”。</li></ol><h3 id="FAQs规范"><a href="#FAQs规范" class="headerlink" title="FAQs规范"></a>FAQs规范</h3><p>FAQs旨在解答人们在阅读新闻稿后可能提出的问题。这是一个解开假设的工具。<br>FAQs要求如下：</p><ol><li>FAQ的需要包含 2 个视⻆：客户视⻆和利益相关者视⻆（利益相关者通常是项目的资源投入方/决策者/管理层等）</li><li>把最常⻅的问题放在最上面</li><li>至少请回答 10 个以上问题</li><li>必须包含下文的必答题，可选题请根据实际项目判断是否保留</li><li>不要隐藏或掩饰棘手的问题，如果不知道请回答“不知道，我们仍在通过XXXX来寻找调查答案”，以便寻求包括领导层在内的人员的帮助与反馈</li></ol><h4 id="必答问题"><a href="#必答问题" class="headerlink" title="必答问题"></a>必答问题</h4><p>（可根据产品不同，适当调整问题⻆度）</p><p>问题 1 ：XX的用户是谁？<br>场景：一切有“用户”的产品，都需要回答。尽量阐述清楚核心用户是谁，不建议直接用全体员工之类的宽泛表述。</p><p>问题 2 ：XX解决了哪些问题？<br>场景：直接描述问题本身（无法xxxx，缺少xxxx），而不是阐述解决问题的方法或结果（提供了xx功能，具备xx能力）。</p><p>问题 3 ：XX有哪些业界对标？<br>场景：请描述XX产品的业界对标产品，技术类的产品需要进行具体的指标对比。</p><p>问题 4 ：XX和YY的区别是什么？<br>场景：YY指某产品，YY可能是：1. 我们要对标的业界知名产品；2.一个业界开源版本，而XX的基于它的演进； 3. 公司内部解决类似问题的产品。请描述XX与YY的定位，相同点与差异点等。</p><p>问题 5 ：XX是不是重复造轮子？<br>场景：如果读者可能联想到公司的同类产品，则需要通过此问题进行说明。</p><p>问题 6 ：XX会依赖哪些服务？<br>场景：如果XX重度依赖（如，直接上下游，核心功能依赖，核心计算能力依赖）于某些服务，需要通过该问题澄清。目标是让读者理解系统架构，并且澄清未来可能的共建及合作。</p><p>问题 7 ：XX的性能标准有哪些？<br>场景：如果是技术类产品，需要回答。如果用户会关注到服务的性能则需要此问题。如产品或组件的使用方会关注可用性和延迟。性能既包括前端交互的性能，同时包括API的性能。在上线之后需要按实际能力调整。</p><p>问题 8 ：XX的成功标准是什么？<br>场景：因为通常产品都需要抓手，一般通过数据化指标来回答，并且要对指标作解释说明，便于阅读者理解和判断。</p><p>问题 9 ：XX的里程碑有哪些？<br>场景：里程碑可以为利益相关者和用户建立产品发展预期。</p><p>问题 10 ：XX的各阶段投入（人力投入 &amp; 基础设施成本）是多少？<br>场景：通常需要预估产品在各个阶段的成本投入情况，以方便团队成员、股东、HR等⻆色进行投入产出评估和资源的准备。</p><p><strong>可选问题推荐</strong></p><p>问题 1 ：XX有哪些入口？<br>场景：如果该产品是用户产品，则用户需要关心从哪里进入开始使用，该入口可能是网站地址、文档地址等。</p><p>问题 2 ：什么样的场景可以使用XX？<br>场景：如果该产品是用户产品，则需要列表用户的使用该产品的核心场景。</p><p>问题 3 ：XX做什么？不做什么？<br>场景：已经有同领域的产品时，需要明确产品的定位与边界。</p><p>问题 4 ：在达成目标的过程中，可能会遇到哪些挑战？准备如何应对？<br>场景：对于技术类产品，可以描述可能的技术挑战以及建议的解决方案；对于需推广运营等类型的产品，需要描述在产品运营过程中将遇到的挑战与解决办法。</p><h3 id="附录规范"><a href="#附录规范" class="headerlink" title="附录规范"></a>附录规范</h3><p>附录要求如下：</p><ol><li>所有外部数据等引用需要标注来源</li><li>需要展示产品的架构图或产品视觉设计图等，方便客户更好的理解，形成客户体验</li></ol>]]></content>
    
    
    <summary type="html">本文介绍PRFAQ的编写规范</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>「转」几种常见的工作方法论汇集</title>
    <link href="https://wangjunfei.com/2021/09/13/%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95%E8%AE%BA%E6%B1%87%E9%9B%86/"/>
    <id>https://wangjunfei.com/2021/09/13/%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95%E8%AE%BA%E6%B1%87%E9%9B%86/</id>
    <published>2021-09-12T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.792Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PDCA循环"><a href="#PDCA循环" class="headerlink" title="PDCA循环"></a>PDCA循环</h1><p>PDCA循环是一个持续改进模型， 它包括持续改进与不断学习的四个循环反复的步骤， 即计划（Plan）、执行（Do）、检查（Check）、处理（Act）。</p><ul><li>P（Plan）–计划，通过集体讨论或个人思考确定某一行动或某一系列行动的方案，包括5W1H；</li><li>D（Do）–执行人执行，按照计划去做，落实计划；</li><li>C（Check）–检查或学习执行人的执行情况，比如到计划执行过程中的“控制点”“管理点”去收集信息，“计划执行的怎么样？有没有达到预期的效果或要求？”，找出问题；</li><li>A（Act）–效果，对检查的结果进行处理，认可或否定。成功的经验要加以肯定，或着模式化或者标准化以适当推广；失败的教训要加以总结，以免重现；这一轮未解决的问题放到下一个PDCA循环。为了避免Act与Do的混淆，也有很多人将A解释为Adjust。</li></ul><p><img src="/2021/09/13/%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95%E8%AE%BA%E6%B1%87%E9%9B%86/pdca.svg"></p><p>PDCA的思想可以追溯到科学方法，本质上是一种探索学习的循环。</p><p>下面来自wikipedia的说明更完善一些：</p><p>PLAN - Establish the objectives and processes necessary to deliver results in accordance with the expected output (the target or goals). By establishing output expectations, the completeness and accuracy of the specification is also a part of the targeted improvement. When possible start on a small scale to test possible effects.</p><p>DO - Implement the plan, execute the process, make the product. Collect data for charting and analysis in the following “CHECK” and “ACT” steps.</p><p>CHECK - Study the actual results (measured and collected in “DO” above) and compare against the expected results (targets or goals from the “PLAN”) to ascertain any differences. Look for deviation in implementation from the plan and also look for the appropriateness/completeness of the plan to enable the execution i.e.,”Do”. Charting data can make this much easier to see trends over several PDCA cycles and in order to convert the collected data into information. Information is what you need for the next step “ACT”.</p><p>ACT - Request corrective actions on significant differences between actual and planned results. Analyze the differences to determine their root causes. Determine where to apply changes that will include improvement of the process or product. When a pass through these four steps does not result in the need to improve, the scope to which PDCA is applied may be refined to plan and improve with more detail in the next iteration of the cycle, or attention needs to be placed in a different stage of the process.</p><h1 id="STAR法则"><a href="#STAR法则" class="headerlink" title="STAR法则"></a>STAR法则</h1><p>STAR法则是情境(situation)、任务(task)、行动(action)、结果(result)四项的缩写。</p><p>STAR法则是一种常常被面试官使用的工具，用来收集面试者与工作相关的具体信息和能力。STAR法则比起传统的面试手法来说，可以更精确地预测面试者未来的工作表现。</p><h1 id="根本原因分析（Root-Cause-Analysis）"><a href="#根本原因分析（Root-Cause-Analysis）" class="headerlink" title="根本原因分析（Root Cause Analysis）"></a>根本原因分析（Root Cause Analysis）</h1><p>根本原因分析（Root Cause Analysis）是一项结构化的问题处理法，用以逐步找出问题的根本原因并加以解决， 而不是仅仅关注问题的表征。根本原因分析是一个系统化的问题处理过程，包括确定和分析问题原因，找出问题解决办法，并制定问题预防措施。在组织管理领域内，根本原因分析能够帮助利益相关者发现组织问题的症结，并找出根本性的解决方案。</p><p>根本原因分析法的目标是找出：</p><p>问题（发生了什么）；<br>原因（为什么发生）；<br>措施（什么办法能够阻止问题再次发生）。</p><p>所谓根本原因，就是导致我们所关注的问题发生的最基本的原因。</p><p>5 Whys 5个为什么<br>5 Whys是根本原因分析的一种具体方法。简单的说，就是针对问题持续的问5个（甚至更多）为什么，找到深层次的根本原因，并据此寻找解决之道。</p><h1 id="时间管理四象限"><a href="#时间管理四象限" class="headerlink" title="时间管理四象限"></a>时间管理四象限</h1><p>究竟什么占据了人们的时间？这是一个经常令人困惑的问题。著名管理学家科维提出了一个时间管理的理论，把工作按照重要和紧急两个不同的程度进行了划分，基本上可以分为四个“象限”：既紧急又重要、重要但不紧急、紧急但不重要、既不紧急也不重要。这就是关于时间管理的“四象限法则”。</p><table><thead><tr><th>重要但不紧急</th><th>重要且紧急</th></tr></thead><tbody><tr><td>既不紧急也不重要</td><td>紧急但不重要</td></tr></tbody></table><p>时间管理理论的一个重要观念是应有重点地把主要的精力和时间集中地放在处理那些重要但不紧急的工作上，这样可以做到未雨绸缪，防患于未然。</p><p>GTD</p><p>GTD需要将时间管理划分为四个象限：重要且紧急，重要不紧急，紧急不重要，不重要不紧急</p><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">A</span>、重要且紧急</span><br><span class="line"></span><br><span class="line">紧急状况</span><br><span class="line"></span><br><span class="line">迫切的问题</span><br><span class="line"></span><br><span class="line">限期完成的工作</span><br><span class="line"></span><br><span class="line">你不做其他人也不能做</span><br></pre></td></tr></tbody></table></figure><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">B</span>、重要不紧急</span><br><span class="line"></span><br><span class="line">准备工作</span><br><span class="line"></span><br><span class="line">预防措施</span><br><span class="line"></span><br><span class="line">价值观的澄清</span><br><span class="line"></span><br><span class="line">计划</span><br><span class="line"></span><br><span class="line">人际关系的建立</span><br><span class="line"></span><br><span class="line">真正的再创造</span><br><span class="line"></span><br><span class="line">增进自己的能力</span><br></pre></td></tr></tbody></table></figure><figure class="highlight mathematica"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">C</span>、紧急不重要</span><br><span class="line"></span><br><span class="line">造成干扰的事、电话、</span><br><span class="line"></span><br><span class="line">信件、报告</span><br><span class="line"></span><br><span class="line">会议</span><br><span class="line"></span><br><span class="line">许多迫在眉捷的急事</span><br><span class="line"></span><br><span class="line">符合别人期望的事</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><figure class="highlight mathematica"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">D</span>、不重要不紧急</span><br><span class="line"></span><br><span class="line">忙碌琐碎的事</span><br><span class="line"></span><br><span class="line">广告函件</span><br><span class="line"></span><br><span class="line">电话</span><br><span class="line"></span><br><span class="line">逃避性活动</span><br><span class="line"></span><br><span class="line">等待时间</span><br></pre></td></tr></tbody></table></figure><p>优先顺序=重要性*紧迫性</p><p>在进行时间安排时，应权衡各种事情的优先顺序，要学会“弹钢琴”。</p><p>对工作要有前瞻能力，防患于未然，如果总是在忙于救火，那将使我们的工作永远处理被动之中。</p><p>参考：</p><p>可以参考这本书：《Getting Things Done》 《小强升职记》</p><p>后期可以参考这本：《要事第一》 </p>]]></content>
    
    
    <summary type="html">总结了集中常见的工作方法论</summary>
    
    
    
    
    <category term="方法论 软素质提升" scheme="https://wangjunfei.com/tags/%E6%96%B9%E6%B3%95%E8%AE%BA-%E8%BD%AF%E7%B4%A0%E8%B4%A8%E6%8F%90%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>软素质螺旋上升</title>
    <link href="https://wangjunfei.com/2021/08/14/%E8%BD%AF%E7%B4%A0%E8%B4%A8%E8%9E%BA%E6%97%8B%E4%B8%8A%E5%8D%87/"/>
    <id>https://wangjunfei.com/2021/08/14/%E8%BD%AF%E7%B4%A0%E8%B4%A8%E8%9E%BA%E6%97%8B%E4%B8%8A%E5%8D%87/</id>
    <published>2021-08-13T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.820Z</updated>
    
    <content type="html"><![CDATA[<p>不同于技术和经验的成长是叠加型的，积累型的，认知和格局的上升往往是螺旋式的，经历四个阶段，如下图:</p><p><img src="/2021/08/14/%E8%BD%AF%E7%B4%A0%E8%B4%A8%E8%9E%BA%E6%97%8B%E4%B8%8A%E5%8D%87/soft_skil.svg"><br>​​​</p><ul><li>超级自信，状态十足<ul><li>这个阶段是状态最好的阶段，信心十足，思维活跃，情绪积极澎湃，最适宜运动员上场战斗，行动和创作的时期。</li></ul></li><li>遇到困难、犯错误，开始反思<ul><li>自信过头，固执己见，会进入狂妄区，碰壁，犯错误。这时善于总结的人会进入反思区。</li></ul></li><li>否定自己，怀疑自己，达到自卑之巅<ul><li>反思区内，过渡的怀疑自己，否定自己，分析自己，容易进入自卑之巅，否定一切，进入情绪的低落期。</li></ul></li><li>成功和胜利事件出现，开始肯定自己<ul><li>碰到成功和胜利的时间出现，开始逐渐的肯定自己，心理修复，走出阴暗区和情绪低落期。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">本文总结了软素质螺旋上升的规律</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Mafka全链路弹性伸缩演进策略</title>
    <link href="https://wangjunfei.com/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/"/>
    <id>https://wangjunfei.com/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/</id>
    <published>2021-07-21T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.785Z</updated>
    
    <content type="html"><![CDATA[<h1 id="业界全链路弹性伸缩调研"><a href="#业界全链路弹性伸缩调研" class="headerlink" title="业界全链路弹性伸缩调研"></a>业界全链路弹性伸缩调研</h1><h2 id="Apache-Kafka的快速扩缩容方法"><a href="#Apache-Kafka的快速扩缩容方法" class="headerlink" title="Apache Kafka的快速扩缩容方法"></a>Apache Kafka的快速扩缩容方法</h2><h3 id="架构特点-重存储，轻计算"><a href="#架构特点-重存储，轻计算" class="headerlink" title="架构特点-重存储，轻计算"></a>架构特点-重存储，轻计算</h3><p>整体架构上，Kafka是以文件形式存储消息的，如下图所示，在每个kafka server内，又有多个文件来存储消息，每个文件叫做分片(partition)。</p><blockquote><p>*注: 为了更容易理解kafka的扩容方式，以下介绍都省略了kafka内部controller，follower，以及副本和复制等方面的内容。</p></blockquote><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/p_offset.svg"></p><p>kafka server在接收到消息后，将消息顺序写的方式，落盘到磁盘文件上，用户在读取消息时也是以顺序方式读取消息。<br>因为整个文件读写都是顺序进行的，所以这种磁盘的使用方式速度特别快，效率也非常高，造就了Kafka高吞吐，低延迟的特性。<br>所以，整体上看，Kafka节点的资源压力主要来自于存储， <strong>磁盘IOPS</strong>的使用，以及<strong>磁盘空间</strong>的使用，使用部分内存作为pageCache来加快读写，对CPU的使用特别少。</p><p>对于Kafka来说，集群上的扩容分以下几种场景:</p><table><thead><tr><th align="left">场景</th><th align="left">备注</th></tr></thead><tbody><tr><td align="left">单队列扩容</td><td align="left">单个队列流量徒增，单个业务大促等</td></tr><tr><td align="left">多队列扩容</td><td align="left">多个队列一起扩容</td></tr><tr><td align="left">缓解存量节点压力</td><td align="left">缓解单个节点的压力，比如磁盘容量，IOPS资源不足的问题，迁移部分分片到新增的节点上</td></tr><tr><td align="left">集群整体扩容</td><td align="left">依据集群整体数据指标，周期性做整体扩容，整个集群增加新机器，集群内所有分片做全量重平衡</td></tr></tbody></table><p><strong>针对这四种业务场景，主要由以下四种扩容方法：</strong></p><h3 id="A、第一种、扩容分片-集群内扩容"><a href="#A、第一种、扩容分片-集群内扩容" class="headerlink" title="A、第一种、扩容分片(集群内扩容)"></a>A、第一种、扩容分片(集群内扩容)</h3><p>如下图所示，一个kafka集群包含3个节点，整个集群有一个主题A，它有一个分片。当这个主题的量在增大以后，一个分片无法满足业务方消息的生产速度时，就需要扩容。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic7.svg"></p><p>当这个主题的量增大以后，一个分片无法满足业务方消息的生产速度时，可以扩容多个分片来分担写入请求。如下图所示，主题A扩容为两个分片，此时两个分片共同承担客户端的消息的写入，如果消息的总写入量是10k/s的话，每个分片承担一半，各自5k/s。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic10.svg"></p><p>上边这种扩容，把主题A的两个分片都放到了节点1上。但是每个kafka server的磁盘容量，以及磁盘的IOPS是有限的，当超限以后，单台kafka server的资源就会被用尽。</p><p>这时，可以再扩容分片，并将新的分片分配到其他节点，这时主题A有3个分片，每个分片承担1/3的写入量。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic11.svg"></p><p>以上集群内的扩容方式，实际上Kafka在运行时，一般是大集群的运行状态，集群创建时都有一定的容量冗余。</p><h3 id="B、第二种，扩容集群节点，承担新的分片"><a href="#B、第二种，扩容集群节点，承担新的分片" class="headerlink" title="B、第二种，扩容集群节点，承担新的分片"></a>B、第二种，扩容集群节点，承担新的分片</h3><p>如上边所述，当某个队列的容量不够时，第一种方法是在集群内通过扩容分片的方式来扩容。但是当整个集群内，每个节点的磁盘容量或IOPS都不足时，就需要用到第二种方法，扩容集群。</p><p>在当今云原生时代下，业界主要使用的是k8s 容器化来协助扩容。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic12.svg"></p><p>如上图，扩容前，集群只包含3个节点，broker 1 ,broker 2和broker 3，如果kafka broker实现容器化部署后，使用k8s operator可以手动或编程的方式，快速新建两个新的实例 broker4和broker5，并加入到集群内，整个过程在容器资源充足的情况下，用时是秒级(&lt;60s)别的，</p><p>当然，这两个新节点只有kafka服务在运行，并未承接新的数据。要想快速承接新的数据(消息)，可以把新增加的分片放置到新的节点上，快速分担流量，就是上边的集群内扩容分片的方法，如下图。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic15.svg"></p><h3 id="C、第三种，扩容集群，迁移存量分片"><a href="#C、第三种，扩容集群，迁移存量分片" class="headerlink" title="C、第三种，扩容集群，迁移存量分片"></a>C、第三种，扩容集群，迁移存量分片</h3><p>可以对原集群节点上的存量队列分片做移动，将存量分片移动到新增的机器上，来减轻老节点的负载，如下图所示。<br>通过把老节点broker1，broker2，broker 3上的分片，移动到新的节点上，来减轻老节点的磁盘和IOPS压力。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic13.svg"></p><p>使用这种方法时，当需要迁移的分片数据比较大时，会比较耗时，Kafka官方公司对此有一个功能增强，叫做分层存储。</p><p>所谓分层存储，就是将时间比较近的消息数据存放在kafka  server机器本地，比如3个小时内的数据，将稍微久的数据存放在廉价存储上，比如S3、Hadoop或EBS上，如下图所示:</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic18.svg"></p><p>开启分层存储后，历史数据迁移到外部存储上，kafka节点本地数据减少：</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic16.svg"></p><p>分层存储有两个个优势：</p><ol><li>因为本机存储的数据变少了，提升了集群的磁盘容量，也减轻了磁盘的都请求压力，等于变相的扩容了集群。</li><li>因为本机存储的数据变少了，上边第二种扩容方法里，迁移分片时，挪动的数据也减少了，提高了分片的迁移速度。</li></ol><h3 id="D、第四种，存储任务交由外部组件"><a href="#D、第四种，存储任务交由外部组件" class="headerlink" title="D、第四种，存储任务交由外部组件"></a>D、第四种，存储任务交由外部组件</h3><p>这种方法比较简单，拿外部存储来替换本地磁盘，比如Amazon EBS，部署方式如下图，本地Kafka集群可以不配置或少配置磁盘，部署时磁盘地址挂接到EBS上：</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic21.svg"></p><p>在需要扩容集群的时候，可以分别扩容Broker和 EBS 磁盘存储。Kafka集群扩容时，可以依靠k8s operator快速创建Kafka实例；而磁盘容量或IOPS需要扩容时，交由EBS来处理。</p><p>方案优点:</p><ol><li><p>集群扩缩容比较快。当CPU和内存达到上限后，可以由k8s operator快速扩容kafka实例；当磁盘容量、IOPS达到上限后，kafka自身无需扩容，可以直接扩容EBS。</p></li><li><p>Kafka集群宕机时，集群恢复速度快。kafka broker可以快速起一个新的实例起来，挂接到原节点对应的EBS上。不需要上边那样迁移分区数据。</p></li><li><p>kafka集群可以缩小副本数量。由于EBS自身有多副本容灾机制，因此kafka的副本可以适当缩小，比如从3副本缩小到2副本。</p></li></ol><p>方案劣势：</p><ol><li>kafka  zero copy特性无法使用，数据必须从外部存储拉取到kafka节点上，经过内核态和用户态的转换，消费性能会下降</li><li>多了一层网络访问，增加一个网络RTT时间，延迟受网络影响较大，性能可能会降低。<br><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic14.svg"></li></ol><h2 id="Apache-Pulsar-的快速扩缩容方法"><a href="#Apache-Pulsar-的快速扩缩容方法" class="headerlink" title="Apache Pulsar 的快速扩缩容方法"></a>Apache Pulsar 的快速扩缩容方法</h2><p>Pulsar实际上是两个开源组件的组合，Pulsar集群+BookKeeper集群，下图是Pulsar的架构概览：</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic8.svg"></p><p>Pulsar架构简述:</p><ol><li>Pulsar依赖一个开源项目Apache BookKeeper，使用它来做消息存储，而pulsar本身是一个无状态服务。</li><li>Apache BookKeeper是一个分布式的日志条目(log entry)存储服务。</li><li>Pulsar和b ookeeper都使用zookeeper来存储自己的元数据，并在启动时往zookkeeper上注册节点，来供其他节点或客户端发现自己。</li><li>zookeeper同时负责监控pulsar和bookkeeper的健康状态。</li></ol><p>由此可⻅，Pulsar是一个典型的“计算+存储”类型的消息队列，Pulsar本身只做消息队列层的概念抽象逻辑，真正的消息数据落地在BookKeeper中。<br>在扩容时，如果是因为“计算”不足，则可以直接扩pulsar集群，因为这个集群是无状态的，可以由k8s operator来快速实例话容器。<br>如果是因为”存储不足”，则可以直接扩容bookeeper，但客户端在写入bookeeper时一直保持Write Quorum数量，如下图所示。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic6.svg"></p><p>pulsar在扩缩容方面的优势和劣势如下。</p><p>优势:</p><ol><li>pulsar集群因为是无状态节点，所以扩容速度比较快。</li><li>bookkeeper集群扩容速度也很快，新加入的节点可以快速分担集群的压力。</li></ol><p>劣势:</p><ol><li>bookeeper集群在节点宕机后，仍然要迁移宕机节点的数据到其他节点上，需要一段时间。</li><li>bookeeper集群在扩容后，因为能很快使用新的机器，导致新的fragement会创建到新节点上，在消费数据时，需要跳跃到多个节点上拿数据，性能损失比较大。</li></ol><h2 id="Apache-RocketMQ-快速扩容方法"><a href="#Apache-RocketMQ-快速扩容方法" class="headerlink" title="Apache RocketMQ 快速扩容方法"></a>Apache RocketMQ 快速扩容方法</h2><h3 id="4-0-及以前版本"><a href="#4-0-及以前版本" class="headerlink" title="4.0 及以前版本"></a>4.0 及以前版本</h3><p>如下图所示，RocketMQ的集群是由多对主从节点在组成的，每一个对主从机器都是一个部署单元，消息数据可以分散在多个单元上。</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/pic19.svg"></p><p>在这种架构下，扩容集群时，只需要构建更多的主从对即可，新的单元可以很快分担流量。</p><p>RocketMQ在快速扩容方面的优势和劣势如下<br>优势：</p><ol><li>新加入的部署单元可以很快分担队列流量</li></ol><p>劣势：</p><ol><li>需要手动指定新单元需要分担流量的队列，在集群内队列数量很多时，这个操作比较繁琐。</li><li>由于RocketMQ没有像Kafka一样的集群迁移操作，当扩容新的单元后，新数据落到了新节点上，老数据依然在老节点上，消费这些数据只能还跳回到老节点消费，实际未分散消费带来的服务压力。</li></ol><h3 id="5-0版本-预览版，8月13日刚发布"><a href="#5-0版本-预览版，8月13日刚发布" class="headerlink" title="5.0版本(预览版，8月13日刚发布)"></a>5.0版本(预览版，8月13日刚发布)</h3><p><strong>5.0版本则发生了很大的变化，初步从发布资料来看，架构采用了可分可合的存算分离方案，如下图所示:</strong></p><p>*以下引用自infoQ: RocketMq 5.0架构</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/rocke_mq5.jpg"></p><p>SDK: 用户客户端<br>LB Group： 负载均衡器<br>CBroker: 计算前端<br>SBroker: 存储后端</p><p>左侧是存算分离部署场景，右侧是放到一个机器上来部署，可以作为sidecar方式并存，也可以糅合到一个进程。<br>两种方式并存的架构体系，RocketMQ官方给出的理由是：</p><blockquote><p>*以下引用自infoQ: RocketMq 5.0架构</p></blockquote><blockquote><p>通过可分可合的存储计算分离架构，用户可以同一进程启动存储和计算的功能，也可以将两者分开部署。分开部署后的计算节点可以做到“无状态”，一个接入点可代理所有流量，在云上结合新硬件内核旁路技术，可以降低分离部署带来的性能及延迟问题。而选择“存储计算一体化”架构，同时也能契合“就近计算”的趋势，也就是在最靠近数据的地方做计算。</p></blockquote><blockquote><p>林清山表示新版本在存储计算分离的架构选择上非常慎重：“首先我们认为在云上多租、多 VPC、多种接入方式的场景下是非常有必要的，存储计算分离后能够避免后端存储服务直接暴露给客户端，便于实现流量的管控、隔离、调度、权限管理。”</p></blockquote><blockquote><p>但是有利必有弊，除了带来延迟的上升、成本的增加以外，存储计算分离也会给线上运维带来巨大挑战。在大多数场景下，用户更希望的还是存储计算一体化的架构，开箱即用、性能高、延迟低、运维轻松，尤其是在大数据场景下，能够极大降低机器及流量成本。其实这个问题本质上还是由消息产品的特性决定的，消息相比于数据库，计算逻辑相对简单，拆分后往往会沦为无计算场景可发挥、存储节点也得不到简化的状态，这个从 Kafka 的架构演进也可以得到印证。”</p><p>“存储计算分离只是适应了部分场景，架构的演进还是要回归到客户的真实场景。”</p></blockquote><ol><li>解耦计算和存储，两者可以分开扩容。</li><li>依据“就近原则”，可以将计算单独部署在最靠近数据的地方。</li><li>云上多租、多 VPC、多种接入方式的场景下是非常有必要的，存储计算分离后能够避免后端存储服务直接暴露给客户端，便于实现流量的管控、隔离、调度、权限管理</li><li>有利必有弊，存算分离会带来延迟的上升，成本的增加，同时带来线上运维的巨大挑战。在多数场景下，用户还是希望存算一体化，开箱即用，高性能，低延迟，运维轻松。</li></ol><p>另外，打听阿里内部RcoketMQ的开发人员，说RocketMQ已经开始接入云盘，但是现在没有官方资料放出来。</p><h1 id="Mafka-快速扩缩容演进计划"><a href="#Mafka-快速扩缩容演进计划" class="headerlink" title="Mafka 快速扩缩容演进计划"></a>Mafka 快速扩缩容演进计划</h1><h2 id="Mafka的现有扩缩容能力"><a href="#Mafka的现有扩缩容能力" class="headerlink" title="Mafka的现有扩缩容能力"></a>Mafka的现有扩缩容能力</h2><p>因为Mafka底层基于Kafka来研发，其底层扩缩容原理和上述的Kafka是一样的，总结Kafka和Mafka现有的扩缩容能力如下:</p><p><img src="/2021/07/22/Mafka%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E6%BC%94%E8%BF%9B%E7%AD%96%E7%95%A5/table1.png"></p><p>可以看出对于第三种扩容方法，存量数据迁移时，如果数据量比较大的时候，速度比较慢。</p><p>为了优化这个问题，可以有两种方案:</p><table><thead><tr><th align="left">方案</th><th align="left">优势</th><th align="left">劣势</th></tr></thead><tbody><tr><td align="left">一、现有Mafka架构+分层存储(Mstore)（扩容方法C增强）</td><td align="left"><ol><li>Mafka集群原本就是大集群模式，有足够的资源冗余来缓解业务的流量徒增。现有架构可以满足业务的全链路弹性伸缩需求，不需要太大变动。</li><li>充分利用本地盘的优势，提升热数据的读写速度。冷数据、历史数据迁移至远程存储，节约本机磁盘空间，降低成本。</li><li>无需对远程存储强依赖，减少三方组件影响，远程存储可用性不影响Mafka整体高可用性。</li><li>历史数据的读取不影响热数据的存取</li><li>现有架构稳定可靠，方案对整体架构变动小，结果可控</li><li>演进路线和官方相同，有庞大的社区来获取经验和帮助</li></ol></td><td align="left"><ol><li>存量数据分片已经很小了，但迁移时仍然需要一定的时间</li><li>新的功能feature，仍然需要社区的验证</li></ol></td></tr><tr><td align="left">二、Mafka + 外部存储 （扩容方法D、存算分离）</td><td align="left"><ol><li>存储层交由第三方组件维护，自身变成无状态节点，方便维护。</li><li>无状态节点的扩缩容，依靠k8s+容器化 速度会很快</li></ol></td><td align="left"><ol><li>Mafka本身主要是磁盘IO bound，基本无CPU运算，做存算分离拆分意义不大，额外增加一层风险和维护成本。而且即便拆分后，计算层利用率不高，徒增工作量。</li><li>多一层网络访问，数据写入和读取耗时会增高，性能有损失</li><li>Kafka零拷贝无法使用，消费性能会下降</li><li>历史数据读取、热数据读取粘合在一起，互相影响</li><li>可用性受存储影响，即便本地增加read cache热数据，可用性依然受远端存储影响。</li><li>从稳定性上来讲，整个链路多一个外部组件，而且存储的是核心数据，多一个风险，增加额外的维护成本。</li></ol></td></tr></tbody></table><p>参考:</p><ol><li><a href="https://aws.amazon.com/blogs/big-data/best-practices-for-running-apache-kafka-on-aws/">https://aws.amazon.com/blogs/big-data/best-practices-for-running-apache-kafka-on-aws/</a></li><li><a href="https://www.confluent.io/blog/deploying-apache-kafka-on-aws-elastic-block-store-ebs/">https://www.confluent.io/blog/deploying-apache-kafka-on-aws-elastic-block-store-ebs/</a></li><li><a href="https://github.com/apache/rocketmq/wiki/RIP-20-Streaming-Tiered-Storage-Optimize">https://github.com/apache/rocketmq/wiki/RIP-20-Streaming-Tiered-Storage-Optimize</a></li></ol>]]></content>
    
    
    <summary type="html">本文分析和研究了社区其他消息队列的弹性扩缩容方法，给出了Mafka全链路的弹性策略建议</summary>
    
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="rocketmq" scheme="https://wangjunfei.com/tags/rocketmq/"/>
    
    <category term="kafka" scheme="https://wangjunfei.com/tags/kafka/"/>
    
    <category term="pulsar" scheme="https://wangjunfei.com/tags/pulsar/"/>
    
  </entry>
  
  <entry>
    <title>Mafka长期发展规划(LRP)</title>
    <link href="https://wangjunfei.com/2021/07/14/Mafka-LRP/"/>
    <id>https://wangjunfei.com/2021/07/14/Mafka-LRP/</id>
    <published>2021-07-14T10:10:16.000Z</published>
    <updated>2024-03-24T00:58:30.777Z</updated>
    
    <content type="html"><![CDATA[<h1 id="云原生时代，Mafka的挑战"><a href="#云原生时代，Mafka的挑战" class="headerlink" title="云原生时代，Mafka的挑战"></a>云原生时代，Mafka的挑战</h1><h2 id="单体式架构时代"><a href="#单体式架构时代" class="headerlink" title="单体式架构时代"></a>单体式架构时代</h2><p> 大约在十几年前，我们在构建互联网应用时，使用的是下图这样的架构。</p><p> 外层提供一个API供客户端来调用，内层分为几个模块，每个模块负责一部分应用，如图所示，比如用户管理，购物⻋，商品目录，订单管理，库存，运输。这是一个典型的单体架构应用，所有的模块和API层都在一个应用里，客户端在HTML里调用服务端API来完成展示和交互，服务端访问数据库来完成一系列业务逻辑。开发、测试、部署，问题查找，扩容，都很方便快捷，尤其在初创型公司里，一个或几个人快速搭建一个应用原型，单体式架构非常高效。</p><p>随着业务需求的迭代，系统功能的增加，单体式应用逐渐遇到一些开发上的问题：</p><ol><li>系统随着业务需求的增加变得越来越复杂，没有一个人能完全了解整个系统。</li><li>每一次新的需求迭代开发，所需的开发时间越来越⻓，而且越来越容易出错误。</li><li>一个小的变更需要将整个系统重新部署一次，变更的代价和⻛险比较大。</li><li>一个小组件的问题或bug，会让整个系统变得不可用。</li><li>新的技术和框架很难被应用到项目中去</li></ol><p>直到最后，不得不重新编写整个系统。这个时候，微服务架构诞生！<br> <img src="/2021/07/14/Mafka-LRP/monothnic.svg"></p><h2 id="微服务架构时代"><a href="#微服务架构时代" class="headerlink" title="微服务架构时代"></a>微服务架构时代</h2><p>在微服务架构下，整个系统被拆分为若干个独立的服务，他们有各自的代码库，独立演进和迭代，如下图所示:</p><p> <img src="/2021/07/14/Mafka-LRP/mordern_apps.svg"></p><ol><li>整个系统被拆分为若干个小的服务子系统，便于理解和规划</li><li>每个小服务都是小单元，小项目，包含自己的数据，repo，代码和依赖，便于独立开发和迭代</li><li>每个服务都部署在一个容器内，由容器管理器来统一编排</li><li>没有统一的一个关系数据库，都有各自的数据库或存储，以及分布式缓存</li><li>使用统一的网关来做一些横向的策略应用，比如鉴权，分控等。</li></ol><p>最重要的是，现代的微服务架构充分使用了云的基础设施，实现 <strong>高扩展性</strong> ， <strong>高可用性</strong> ，以及 <strong>高韧性</strong> ，我们统一称这类微服务或应用为 <strong>云原生应用</strong> (cloud native application)。</p><p>面对市场形势多变的特点，以及互联网业务发展迅猛的形势，企业必须对业务进行快速的开发和迭代，以抢占瞬息万变的市场机会。云原生应用的最大特点就是快速拥抱变化，他们可以在几分钟内快速的扩容，缩容，迁移，销毁，以应对业务和市场快速的需求变化。这对应用和服务的周边配套设施，如构建，部署，配置，监控，PaaS，IaaS等支持服务提出了更高的要求.</p><h2 id="Mafka面临的挑战"><a href="#Mafka面临的挑战" class="headerlink" title="Mafka面临的挑战"></a>Mafka面临的挑战</h2><p>Mafka作为支持云原生的PaaS服务之一，面临着以下三个方面的挑战</p><h3 id="第一、扩展能力"><a href="#第一、扩展能力" class="headerlink" title="第一、扩展能力"></a>第一、扩展能力</h3><h4 id="接入k8s，提升集群扩展能力"><a href="#接入k8s，提升集群扩展能力" class="headerlink" title="接入k8s，提升集群扩展能力"></a>接入k8s，提升集群扩展能力</h4><p>以下是Mafka的系统架构图</p><p><img src="/2021/07/14/Mafka-LRP/mafka_arch.svg"></p><p>整体架构上，要匹配云原生服务的快速扩缩容，Mafka的几个核心模块首先必须具备横向扩展能力</p><table><thead><tr><th>模块</th><th>简介</th><th>服务类型</th><th>服务架构</th><th>容器+弹性伸缩接入情况</th><th>扩缩容能力</th></tr></thead><tbody><tr><td>Castle</td><td>Mafka调度器</td><td>RPC服务 (MNS invoker + Netty自有协议)</td><td>本机可重建Cache + KV存储 + ZK选主</td><td>已接入容器</td><td>已接入弹性伸缩</td></tr><tr><td>PushServer</td><td>Mafka Push代消费</td><td>RPC服务(Castle服务发现+Netty自有协议)</td><td>本机可重建Cache + KV存储 + ZK选主/简单通知</td><td>已接入容器</td><td>具备横向扩容能力</td></tr><tr><td>DelayServer</td><td>Mafka 延迟队列</td><td>RPC服务(Octo+Mtthrift)</td><td>本机可重建Cache + KV存储 + ZK选主</td><td>已接入容器</td><td>已接入弹性伸缩</td></tr><tr><td>Broker</td><td>Mafka 消息Broker</td><td>基于文件的分布式系统</td><td>本机磁盘存储 + ZK选主/元信息存储</td><td>接入容器中</td><td>具备横向扩容能力</td></tr></tbody></table><p>如图，三个RPC服务都已经接入了容器，并且接入了hulk弹性伸缩，已经具备了横向扩缩容的能力。<br>Mafka Broker 正在接入容器过程中，现阶段主要靠虚机来做扩缩容，目前还未接入弹性。<br>如消息队列业界调研所述，Kafka、Pulsar、RocketMQ都在使用容器以及k8s技术来增强自身的扩展性。<br>三家产品容器化技术对比：</p><table><thead><tr><th>产品</th><th>扩容组件</th><th>容器化技术</th></tr></thead><tbody><tr><td>Kafka</td><td>Confluent Cloud for k8s</td><td>k8s operator</td></tr><tr><td>Pulsar</td><td>StreamNative Helm</td><td>k8s operator</td></tr><tr><td>RocketMQ</td><td>阿里云消息队列RocketMQ版</td><td>k8s operator</td></tr></tbody></table><p>Kafka官方公司Confluent Cloud For k8s的服务架构:</p><blockquote><p>*下图引用自confluent engineering blog</p></blockquote><p><img src="/2021/07/14/Mafka-LRP/confluent_platform.png"></p><p>以Kafka为例，Confluent使用自研的k8s operator为集群扩容或替换。<br><img src="/2021/07/14/Mafka-LRP/confluent_op.svg"></p><p>如上图所示，Confluent Cloud可以动态扩容集群的节点，磁盘、CPU、M EM等，甚至可以做到以编程的方式来自动编排。<br>当某台容器宕机后，他可以自动侦测到，并自动添加新的节点到集群内，填补宕机节点的空缺。<br>所以，要提升Mafka的扩展能力， <strong>第一步要做的就是接入容器化，增加k8s operator的使用，增强Mafka broker的横向扩展能力</strong> 。</p><h4 id="去除ZooKeeper依赖，提升broker的扩展性"><a href="#去除ZooKeeper依赖，提升broker的扩展性" class="headerlink" title="去除ZooKeeper依赖，提升broker的扩展性"></a>去除ZooKeeper依赖，提升broker的扩展性</h4><p>Kafka一开始设计的时候，依靠zookeeper来解决系统的一致性问题，比如集群controller的选主，partition leader的选主，同时还保存了集群的metadata信息。<br>随着集群内topic数量，分区数量的增⻓，metadat数据数量也跟着增⻓，但是kafka集群在启动以后，或集群发生重新选主时，集群的controller需要全量拉取一次zookeeper上的metadata数据，所以这个数据越<br>大，拉取的耗时也会越⻓，直接影响了集群controller的可用性，最终必须限制metadata数据的大小， <strong>这就限制了Kafka集群的横向扩展能力</strong> 。</p><p><img src="/2021/07/14/Mafka-LRP/kafka_zk.svg"></p><p>Kafka官方为了解决这个问题，引入了一个新的提案KIP-500，去除Kafka对zookeeper的依赖<br><img src="/2021/07/14/Mafka-LRP/kafka_quorum.svg"></p><p>如上图，每个broker内都有一个副本Log文件，它的内容就是集群的全量的metadata数据。同时集群内stand by 的c ontroller会形成一个Raft协议集群，依靠自身来做一致性选举。<br>当发生controller选主的时候，Kafka集群不再需要从zookeeper 读取全量的metadata数据，这样就加快了controller的启动过程，即便集群内metadata数据再大，也不会有影响， <strong>①直接提升了broker的扩展性</strong> 。<br>去除z ookeeper除了提升broker的扩展性外， <strong>②还能降低组件的复杂度</strong> ，两个组件减少为一个组，演进和迭代能减轻很大的负担； <strong>③同时还能减少部署和运维</strong> ，部署kafka集群时不需要再部署一个zookeeper集群，<br>也不需要单独维护zookeeper的稳定性。<br>除此之外， <strong>④还能解决Mafka 容灾 2 .0特殊情况下的集群脑裂问题:</strong> 如下图</p><p><img src="/2021/07/14/Mafka-LRP/disaster_recover.svg"></p><p>当机房间发生断网时，如果形成一个孤岛机房，而且集群的主(Controller)又恰好在孤岛机房内，孤岛机房外的集群节点会选举一个新的主(Controller)，这时当网络恢复后会，集群内会出现两个Controller，整个集<br>群会发生脑裂。</p><p><img src="/2021/07/14/Mafka-LRP/dual_idc_deploy.svg"></p><p>如果引入Kafka KIP-500去除Zookeeper PR后，一致性内嵌在Broker内部，可以通过配置小Quorum大小来解除孤岛机房内的主(Controller)，避免形成脑裂问题。</p><h4 id="抽取KRaft组件，形成一个以选主为主要功能的基础组件，供Mafka内部、公司内部其他组件使用"><a href="#抽取KRaft组件，形成一个以选主为主要功能的基础组件，供Mafka内部、公司内部其他组件使用" class="headerlink" title="抽取KRaft组件，形成一个以选主为主要功能的基础组件，供Mafka内部、公司内部其他组件使用"></a>抽取KRaft组件，形成一个以选主为主要功能的基础组件，供Mafka内部、公司内部其他组件使用</h4><h3 id="第二、扩展效率"><a href="#第二、扩展效率" class="headerlink" title="第二、扩展效率"></a>第二、扩展效率</h3><h4 id="使用分层存储，提升存量分区的迁移速度"><a href="#使用分层存储，提升存量分区的迁移速度" class="headerlink" title="使用分层存储，提升存量分区的迁移速度"></a>使用分层存储，提升存量分区的迁移速度</h4><p>在第一部分提到在云原生时代，云原生应用除了需要很高的横向扩展能力外，更重要的是要具备快速的扩展效率。<br>要提升扩展效率，除了接入容器化、k8s operator和弹性来提升自动化能力外，还要增强broker的扩容速度。<br>如Mafka Broker全链路弹性伸缩演进策略所述，对于单个主题或多个主题扩容时都有比较快速的方法，但是对集群整体扩容时，存量数据的迁移速度比较慢，耗时⻓，如下图所示:</p><p><img src="/2021/07/14/Mafka-LRP/mv_partition.svg"></p><p>使用分层存储后，单个分片数据量变小，不仅能节约磁盘空间容量，还能降低节点磁盘读压力，最重要的是加快了分区数据的迁移速度，增强集群的扩容效率。</p><p><img src="/2021/07/14/Mafka-LRP/tired_store_mvp.svg"></p><p>不仅如此，Kafka官方依靠分层存储实现了Kafka <strong>无限存储</strong> 能力，架构如下图:</p><blockquote><p>*下图引用自confluent engineering blog</p></blockquote><p><img src="/2021/07/14/Mafka-LRP/infinet_storage.png"></p><h1 id="业务需求对Mafka架构的挑战"><a href="#业务需求对Mafka架构的挑战" class="headerlink" title="业务需求对Mafka架构的挑战"></a>业务需求对Mafka架构的挑战</h1><h2 id="流量隔离、hash生产、消费模型对Mafka带来的资源压力"><a href="#流量隔离、hash生产、消费模型对Mafka带来的资源压力" class="headerlink" title="流量隔离、hash生产、消费模型对Mafka带来的资源压力"></a>流量隔离、hash生产、消费模型对Mafka带来的资源压力</h2><h3 id="流量隔离带来的队列资源消耗"><a href="#流量隔离带来的队列资源消耗" class="headerlink" title="流量隔离带来的队列资源消耗"></a>流量隔离带来的队列资源消耗</h3><p>由于业务的发展的需求，mafka支持多重流量隔离方案，比如泳道，方便了QA人员同时开展多条测试链路，每个泳道的消费者只消费本泳道生产者生产的消息<br>，如果下游没有泳道消费者，⻣干的消费者需要把泳道的消息也消费掉，如下图所示，<br><img src="/2021/07/14/Mafka-LRP/mafka_swl.svg"><br>类似的流量隔离方案，还有环境隔离，比如test/dev/prod/stage各类测试和生产环境；Set化隔离，比如North、East、West、South等各种Set。Mafka在满足这些流量隔离时，采用的是队列模拟，<br>比如对于业务的某个队列，在环境隔离时，每个环境用一个队列去模拟，当多种流量隔离发生交叉时，prod环境下的Set，test环境下的泳道，又会产生多个底层队列。再加上其他的特性，比如死信，<br>优先级队列等，这些功能都是通过底层队列来模拟的 <strong>，再次发生排列组合以后，队列资源耗费的比较快</strong> 。</p><h3 id="hash生产带来的partition资源消耗"><a href="#hash生产带来的partition资源消耗" class="headerlink" title="hash生产带来的partition资源消耗"></a>hash生产带来的partition资源消耗</h3><p>有些业务在向Mafka生产消息时，需要将特定类的消息放到一起，以便消费的时候，同一类消息由相同的消费者来消费<br><img src="/2021/07/14/Mafka-LRP/hash_produce.svg"><br>如上所示，业务在向订单队列生产消息时，希望某一类的订单集中放到一起，然后由同一个消费者来消费。Mafka在底层是通过分区来实现的，每一类的消息都放到同一个分区上，<br>在业务消费的时候，这个分区的所有消息统一由某一个消费者来消费。这样就带来一个问题， <strong>当业务hash的结果数据集类型比较多的时候，Mafka的paritition资源消耗的比较快。</strong></p><h3 id="消费模型带来的partition资源消耗"><a href="#消费模型带来的partition资源消耗" class="headerlink" title="消费模型带来的partition资源消耗"></a>消费模型带来的partition资源消耗</h3><p>Mafka的消息队列在被业务客户端消费时，受限于Mafka的消费模型，一个队列的一个partition只能被一个消费者消费<br><img src="/2021/07/14/Mafka-LRP/common_consume.svg"></p><p>如上图所示，队列A有 3 个partition 分别是P0、P1、P2，业务有3个消费者，A、B、C分别负责消费P0、P1、P2。当消费逻辑耗时比较高，队列产生消息积压时，业务会要求加入多个消费者，这时Mafka就必须为业务扩容partition，增加更多的分区，以便新创建的消费者能消费到消息。 <strong>在这种场景下，Mafka partition资源的消耗并不是来自于队列流量的增加，而仅仅是业务消费者数量的增加，消费者数量和partition数量有紧密的耦合关系，导致partition资源的消耗</strong> 。</p><h3 id="Mafka4-读写分离来解决"><a href="#Mafka4-读写分离来解决" class="headerlink" title="Mafka4 读写分离来解决"></a>Mafka4 读写分离来解决</h3><p>以上所说的三个问题，不管是队列资源的消耗，还是partition资源的消耗，都会让整个集群的partition数量的增⻓，从而消耗整个集群的容量。最明显的问题，就是整个集群的partition数量增加到一定程度后，用户<br>的发送耗时会增加，集群吞吐量会降低。<br>对于这个问题，业界和Kafka社区并没有现成的策略和办法来参考。经过我们的测试和调研，提出了Mafka 4解决方案，通过队列合并来，分离读写节点来解决这个问题。<br><img src="/2021/07/14/Mafka-LRP/mafka4.svg"></p><p>如上图所示，通过进入物理分区，虚拟分区，以及读写节点的概念，来重建整个Kafka 数据和存储模型。<br>这个方案不仅能有效的解决了上述所说的三个问题，还可以满足业务⻓期的发展需要，提升架构扩展性和效率：</p><ol><li>合并各类流量隔离队列，来减少物理机队队列数量的膨胀，减少队列资源消耗。能让架构更灵活高效，解决将来业务在线上的各种流量隔离需求。</li><li>解耦了partition数量和消费者数量之间的紧耦合关系，引入虚拟分区来解决这个问题。最终让业务对partition概念透明，业务有新的消费者上来后，分区会自动扩容，分配消息给新的消费者。</li><li>可以合并小流量队列到一个物理队列上，也可以合并队列多个分区到一个物理分区上，缩减集群的分区和队列数量，大幅提升原有集群的容量。</li></ol><h2 id="实时计算业务的痛点"><a href="#实时计算业务的痛点" class="headerlink" title="实时计算业务的痛点"></a>实时计算业务的痛点</h2><h3 id="引入Kafka-Stream-来构建一站式流式计算"><a href="#引入Kafka-Stream-来构建一站式流式计算" class="headerlink" title="引入Kafka Stream 来构建一站式流式计算"></a>引入Kafka Stream 来构建一站式流式计算</h3><p>随着业务的发展，实时计算技术近年来逐渐成熟起来，比如storm/flink一类实时计算框架，我们公司大数据业务也有相应的服务。<br>通常情况，在线业务在使用实时计算时采用的如下的架构：</p><p><img src="/2021/07/14/Mafka-LRP/mafka_storm.svg"></p><p>业务先将数据发送到Mafka，然后再storm、f link平台上消费Mafka的消息，来做实时计算，计算完成后将数据再推送回Mafka，供在线业务是消费和展示。<br><strong>①这种架构需要先将从Mafka搬迁到实时计算平台上，多了一次传输，浪费了一些时间和效率。<br>②而且在问题排查方面，storm和f link非常不友好，</strong> 因为业务需要将自己的代码上传到这两个平台上，程序实际是在远程平台上执行的，而远程平台又是大集群、多用户，<br>调查问题、调试程序非常麻烦，效率低下。<br><strong>③另外，storm和f link自身有一定的复杂度，入⻔成本也比较高，对于一些只需要做一个简单窗口聚合计算的用户来说比较重，需要花时间和精力先学习。</strong></p><p>实际上Kafka官方本身就支持轻量的实时流式计算服务，叫做Kafka Stream。K afka Stream是集成在Kafka内部的轻量流式计算库，他跟Kafka集成在一起。<br>不同于Flink和S torm，K afka Stream不是一个平台，不需要用户将代码打包上传到平台上，他只是一个简单的lib库，用户像写应用程序一样写流式计算服务，<br>编译打包成功后，运行在用户自己的机器上。<br>下图是一个Mafka集成Kafka Stream后的部署架构图：</p><p><img src="/2021/07/14/Mafka-LRP/kafka_stream.svg"></p><p>业务app后端服务将在线数据写入Mafka，然后通过自有的实时计算服务消费这些数据，计算完成后再把计算结果写回Mafka，供a pp后端服务来使用。<br>业务自有的实时计算服务是自己的服务，像普通的后端服务一样构建和部署。在实时流式计算过程中还可以使用到大数据存储Blade，计算结果也可以存储在Cellar<br>中供业务app后端服务来存取。</p><p>Kafka Stream目前使用也很广泛，大厂如twitter就将自己首⻚的推荐引擎也搬迁到了Kafka stream上，架构如下图：</p><blockquote><p>*下图引用自twitter engineering blog</p></blockquote><p><img src="/2021/07/14/Mafka-LRP/twitter_kafka_stream.png"></p><p>总结起来，引入Kafka Stream的优势:</p><ol><li>实时流式计算可以在Mafka一站式解决，减少数据的搬运，降低整个实时计算链路的延迟</li><li>KafkaStreams是本地lib库，开发、调试方便</li></ol><ul><li>意味着RD可以在本地开发和测试自己的Kafka Stream流式任务，Strom/Flink等需要将服务部署到集群上，开发者很难了解框架的具体运行方式，从而使得调试成本高，并且使用受限.</li></ul><ol start="2"><li>Kafka Stream非常的轻量级，可以应用到微服务、IOT等实时流式计算以及EDA架构场景下:</li></ol><ul><li>Strom/Flink都是计算框架，需要部署一个集群，将自己的流式作业上传到集群处理，kafaStreams是l ib库，业务程序集成后就可以可开始流式计算。</li></ul><ol start="3"><li>接入方便，使用成本低</li></ol><ul><li>Mafka在公司内广泛使用，业务已经将消息和数据发往了Mafka，如果Mafka推出s tream流式计算，业务只要升级Mafka client版本，既可拥有流式计算能力，相对业务来说，使用流式计算技术的成本非常<br>低。</li></ul><h3 id="引入Kafka-Stream-支持EDA-事件驱动架构"><a href="#引入Kafka-Stream-支持EDA-事件驱动架构" class="headerlink" title="引入Kafka Stream 支持EDA(事件驱动架构)"></a>引入Kafka Stream 支持EDA(事件驱动架构)</h3><p>事件驱动架构(Event Driven Architecture)是近两年流行起来的新的架构方式，相比传统的请求驱动架构(Request Driven Architecture)，他有以下优势:</p><ol><li>模块之间松散耦合</li></ol><ul><li>由于生产者和消费者两个模块通过消息队列解耦，消息生产者不需要知道消费者是谁，在不在线，可以一直生产。后续业务需求增加新的功能，不影响原有系统。</li></ul><ol start="2"><li>异步</li></ol><ul><li>生产者不需要等待消费者处理，只需要发送完消息即可返回，实现生产和消费的异步结构。</li></ul><ol start="3"><li>可扩展性强</li></ol><ul><li>由于模块之间松散的耦合，各自可以独立扩展，互不影响。</li></ul><ol start="4"><li>可恢复</li></ol><ul><li>因为模块之间通过消息来通知和驱动，消息又可以回放，因此当消费者宕机后，可以重新回放之前的消息来恢复系统状态。</li></ul><p>Kafka Stream对 EDA 架构具有天然的支持优势，如KTable，KSQL，各类Material View等。<br>如下图，依靠事件传输来驱动整个业务的完成：</p><p><img src="/2021/07/14/Mafka-LRP/event_driven.svg"></p><ol><li>整个系统包含订单系统、发货系统和客户系统，三个系统各自有自己的数据库，系统之间通信使用Kafka消息。</li><li>用户提交完订单后，发送订单创建消息</li><li>发货系统消费订单信息，提供发货支持</li><li>用户系统将用户资料变更发送给Kafka</li><li>发货系统消费用户变更资料，构建为全量的本地用户资料，存储在Ktable里</li><li>发货系统本身是一个流式运算系统</li></ol><p>同时还可以使用KSQL 产生各类预定义视图，如下图示，使用CQRS模式增强读写操作的扩展性:</p><p><img src="/2021/07/14/Mafka-LRP/cqrs.svg"></p><ol><li>创建订单后，发送消息到Kafka</li><li>在查询面，可以使用KSQL的功能，创建多种(Materialised View)实体图，因为Kafka的Pub/Sub模型，实体图的个数可以很多。</li></ol><h1 id="建议发展路径"><a href="#建议发展路径" class="headerlink" title="建议发展路径"></a>建议发展路径</h1><h3 id="综合以上分析，总结MQ长期要规划的项目有以下几点"><a href="#综合以上分析，总结MQ长期要规划的项目有以下几点" class="headerlink" title="综合以上分析，总结MQ长期要规划的项目有以下几点"></a>综合以上分析，总结MQ长期要规划的项目有以下几点</h3><table><thead><tr><th>编号</th><th>项目</th><th>收益</th><th>备注</th></tr></thead><tbody><tr><td>1</td><td>接入k8s，提升Mafka集群的扩展能力</td><td>接入容器化，增加k8s operator的使用，增强Mafka broker的横向扩展能力。</td><td></td></tr><tr><td>2</td><td>去除ZooKeeper依赖，提升broker的扩展性</td><td><ol><li>直接提升了broker的扩展性。</li> <li>降低组件的复杂度</li><li>减少部署和运维</li><li>解决Mafka 容灾2.0特殊情况下的集群脑裂问题</li></ol></td><td></td></tr><tr><td>3</td><td>使用分层存储，提升存量分区的迁移速度</td><td>提升Mafka Broker集群的存量分片迁移能力</td><td></td></tr><tr><td>4</td><td>建设Mafka 4 读写分离集群</td><td><ol><li>支持业务更多类型的流量隔离需求</li><li>解耦分片和消费者数量紧耦合关系，降低集群分片资源消耗速度</li><li>提升集群的整体吞吐量</li><li>合并小流量队列，减少集群分片的消耗，提升集群容量</li></ol></td><td></td></tr><tr><td>5</td><td>引入Kafka Stream 来构建一站式流式计算</td><td><ol><li>实时流式计算可以在Mafka一站式解决，减少数据的搬运，降低整个实时计算链路的延迟</li><li>KafkaStreams是本地lib库，开发、调试方便</li><li>Kafka Stream非常的轻量级，可以应用到微服务、IOT等实时流式计算</li><li>接入方便，使用成本低</li></ol></td><td></td></tr><tr><td>6</td><td>引入Kafka Stream 支持EDA(事件驱动架构)</td><td><ol><li>对业务的EDA架构应用提供完整的支持</li><li>降低业务应用架构的耦合度</li></ol></td><td></td></tr></tbody></table><h3 id="建议发展路径时间表"><a href="#建议发展路径时间表" class="headerlink" title="建议发展路径时间表"></a>建议发展路径时间表</h3><p>略</p><p>参考:</p><ol><li>Making Apache Kafka Serverless: Lessons From Confluent Cloud</li><li>Kafka，confluent，The Cloud-Native Evolution of Apache Kafka on Kubernetes</li><li>Kafka，confluent，Making Apache Kafka Serverless: Lessons From Confluent Cloud</li><li>Infinite Storage in Confluent Platform</li></ol>]]></content>
    
    
    <summary type="html">本文分析了云原生时代Mafka目前面临的扩展性挑战，以及面临的业务需求挑战，提出了Mafka的长期发展计划</summary>
    
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="rocketmq" scheme="https://wangjunfei.com/tags/rocketmq/"/>
    
    <category term="kafka" scheme="https://wangjunfei.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>美团消息队列Mafka</title>
    <link href="https://wangjunfei.com/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/"/>
    <id>https://wangjunfei.com/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/</id>
    <published>2021-04-14T16:00:00.000Z</published>
    <updated>2025-03-17T03:39:14.883Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>消息队列是现代互联网不可缺少的基础组件之一，承载着异步、削峰、解耦等重要特性。<br>Mafka是美团基础架构推出的消息队列产品，开发源于2014年底，成型于2016年初第二个版本-Mafka 2.0，现已经演进到了3.0版本。<br>MQ团队运营着美团数千个服务的Mafka消息队列，线上队列超过4万个，日消息调用量(生产+消费)超过2万亿(线上业务消息，不包含离线大数据计算消息量)，服务可用率SLA是99.999%，队列覆盖到店、到家、<br>金融、猫眼、两轮、广平等各美团事业群和业务。</p><h1 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h1><p><strong>从产品上来看，Mafka主要包含三个子类型产品:</strong></p><ol><li>Mafka 普通消息: 普通的消息收发、订阅，默认支持 7 天内的消息存储和回放。</li><li>Mafka 延迟消息: 延迟类消息，支持 5 s到N天内的任意时间延迟，以下称DelayServer。</li><li>Mafka Push消费端: push类消息消费端，支持以RPC调用方式消费消息，消费方对Mafka Partition透明，以下简称push消费。</li></ol><h2 id="Mafka普通消息"><a href="#Mafka普通消息" class="headerlink" title="Mafka普通消息"></a>Mafka普通消息</h2><p>Mafka普通消息客户端以java、c ++为主，还包含python/go/node.js等小语言客户端。</p><h3 id="分区和offset概念"><a href="#分区和offset概念" class="headerlink" title="分区和offset概念"></a>分区和offset概念</h3><p>生产者在将消息发送给Mafka后，Mafka内部会有分区的概念，一个分区即一个消息块，生产者可以决定将消息发送给哪个分区，这个涉及到消息保序一类，在后边会看到。<br>offset是消息在分区内的偏移量，消费者在消费某一个分区的消息时，会批量提交offset，表明自己消费到哪个位置了，这个信息记录在服务器上。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/offset_cocept.svg"></p><h3 id="消息生产和消费"><a href="#消息生产和消费" class="headerlink" title="消息生产和消费"></a>消息生产和消费</h3><p>Mafka普通消息就是传统的消息队列，支持多个渠道并发生产，多业务并发消费。用户在Mafka用户后台来申请队列，填入必要的信息，即可生成队列资源。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/topic_apply.jpg"></p><p>用户生产时填写appKey(服务标识)、Topic(队列名称)、NameSpace(事业部)即可开始生产，不同的服务可以同时往一个队列中生产，队列Owner也可以设置权限控制，只允许自己生产或消费。<br>消费时以组的方式进行，一个消费组内的所有消费者共同消费队列内的所有消息，一个消费组可以有多个实例(机器)，也可以有一个实例(机器)，如下图:</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/basic_consume.svg"></p><p>消费组A有两台机器组成，消费组B有一台机器组成， 1 92.168.1.1/2机器共同消费TopicA上的所有消息，一个机器只消费全部消息的一部分。 19 2.168.1.3消费TopicA内的所有消息。<br>Mafka集群是以事业部(BG)为单位部署的，一个BG下有多个集群，每个集群部署在不同的机房。默认情况下，申请的队列至少有两个集群，分布在两个机房，能保持机房粒度的容灾，后续还可以动态添加或减少集<br>群，实现机房内、机房间的水平扩容，同时队列可以在多个集群之间迁移变动，如下图:</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/basic_cluster.svg"></p><p><strong>topicA创建在A/B两个集群上，消息生产时，可以有两种模式:</strong></p><ol><li>单集群生产</li></ol><ul><li>单集群模式下，系统会根据生产者的地域位置信息，默认生产到相同机房的集群上，如果同机房没有，则会生产到同地域的集群上，如果同地域没有集群，则会生产到本BG下的其他地域的集群上。</li></ul><ol start="2"><li>多集群生产</li></ol><ul><li>开启多集群生产后，消息会以roundRobin方式生产到A/B两个集群上。</li></ul><p><strong>消息消费也分几种策略：</strong></p><ol><li>同机房消费: 消费端只会消费本机房内集群上的消息</li><li>同地域消费: 消费端只会参与消费本地域内集群上的消息</li><li>全地域消费: 消费方会参与消费所有集群上的消息</li></ol><p>消费端消费时，客户端每 5 秒钟，提交一次offset，即消息的消费偏移量，offset以主题方式存储在集群上。如果消息来自于不同的集群，每个集群各自存储自己的offset。</p><p><strong>生产和消费接口</strong></p><p>Mafka的生产接口分同步生产和异步生产。<br>同步生产情况下，客户端发送一条消息会同步等待生产结果，也可以同步批量发送。<br>异步发送时，可以设置发送结果回调，不论是生产成功或失败，因为异步发送本质先发往本机的缓冲区，再由后台线程批量发送给服务器，减少了单个消息的来回网络请求，发送吞吐会更大，发送效率也更高。<br>不过消息会临时存放在本机缓冲区，会有宕机丢失的⻛险，需要做好异步回调的补偿处理。Mafka默认设置本机缓冲区大小为 64M，超过后可以选择报错，或选择阻塞。</p><p><strong>死信</strong></p><p>死信是消息队里的最基本功能之一，Mafka死信背后是依靠延迟消息来完成的。<br>当用户遇到暂时不能处理的消息后，可以先投递到死信队列，继续消费后边的消息，等设定的时间到达后，再次消费之前未成功的消息。<br>同时Mafka还支持设置最大消费次数，达到次数之后不再重复投递，打印消息到日志里后跳过。</p><h3 id="消息保序"><a href="#消息保序" class="headerlink" title="消息保序"></a>消息保序</h3><p>传统的队列都要求有序，先进先出，保持严格的先后顺序。但随着多核CPU的出现，为了充分利用硬件的性能，对队列的需求不再要求严格有序，只要能保障大致上的有序即可。</p><p>Mafka能满足三种级别的保序要求，如下：</p><p><em><strong>全局有序</strong></em> ：如下图，全局有序意味着，只能有一个生产者或消费者，多于一个的话，生产时或消费时都会乱序，这时申请Mafka队列只能有一个分区。在当今CPU多核的时代，这种模式势必很低效。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/global_seq.svg"></p><p><em><strong>局部有序</strong></em> ：如下图，一个简单的奇数、偶数hash，将单数的消息发往分区 1 ，偶数的消息发往分区 2 ，此种场景下，能保障一个分区内消息有序，不管两个消费者的消费速度快慢，比如奇数分区 1 内， 3一定会在 1<br>之后被消费。<br>这种场景也被用来保障同一类的消息由同一个消费者消费，比如订单的状态变化，通过hash算法将订单分散到不同的分区里，但同一个订单id的消息一定会落在同一个分区内，保障这个订单的处理有严格的先后<br>顺序。<br>但是在此种场景下，也可能会造成局部消息积压，比如因为hash函数的选择，会导致某个分区的消息特别多，某些分区的消息特别少，消息多的分区消费的速度要慢一些，会造成积压。<br>如果通过再hash的话解决的话，会打乱原有的消息顺序，整个消费系统无法轻松的横向扩展。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/part_seq.svg"></p><p><em><strong>大致有序</strong></em> ：通用，高效的消息模式，推荐使用。生产者普通方式下生产，消息在各个分区内以均匀分布。随着消息量的增加，用户可以扩展分区或消费者，每个消费者是等位的，没有区别，因此系统可以很容易实现横向扩容，让整个业务系统的拥有最大弹性。这种模式下，消息虽然不是严格有序，但是却是大致是有序的。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/basic_seq.svg"></p><h3 id="可靠性、持久性保障"><a href="#可靠性、持久性保障" class="headerlink" title="可靠性、持久性保障"></a>可靠性、持久性保障</h3><p>Mafka的消息投递语义也是保障at least once，同一条消息至少生产或消费一次，消息绝不会丢失，但是可能会重复发送或消费。<br>消息生产时，可能因为网络原因，客户端没有收到服务端的生产响应，因而会重复投递消息。同样，客户端在消息消费后，提交offset之前宕机，会导致同一批消息再次被重复消费。</p><h4 id="生产端保障"><a href="#生产端保障" class="headerlink" title="生产端保障"></a>生产端保障</h4><p>先来看下消息生产，生产端SDK通过RPC将消息传输到Mafka集群，产生一个request，Mafka集群在接收到消息后，返回给生产端一个response，这时生产端认为这条消息 <strong>生产成功</strong> ，如下图所示:</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/produce_prot.svg"></p><p>看下生产时可能遇到的异常case：</p><ol><li>request因为网络抖动丢失。</li><li>response因为网络抖动丢失。</li><li>mafka集群故障。<br>不管上边那种情况，生产端都会重试这个request，理论上 3 0s内的网络抖动都可以克服。<br>如果网络抖动超过 3 0s，或者是因为一个Mafka集群有故障，生产端都会重试生产到另外一个集群。<br>所以除非两个机房的集群同时不可用，生产端基本不可能丢失消息，只会因为发生因为网络抖动时，重试产生小部分重复消息，所以Mafka的生产语义是at least once，至少生产一次。</li></ol><h4 id="消费端保障"><a href="#消费端保障" class="headerlink" title="消费端保障"></a>消费端保障</h4><p>消息生产到集群内后，用户就可以消费到了，对于每个队列，Mafka集群都会记录一个”点位( Offset)”，这点位是消费者在队列上的 <strong>消费位置记录</strong> ，如下所示:</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/offset_comit.svg"></p><p>消费者从Mafka集群拉一批消息，在本地消费，SDK内部线程会定时提交消费点位给Mafka集群，集群将这个点位记录下来，以便下次从这里继续消费。如果消费者在提交点位前或后宕机了，那么顶多是本次拉到<br>的消息重复消费一遍，但绝不会错过消息，造成”消息丢失”。</p><h4 id="Mafka集群保障"><a href="#Mafka集群保障" class="headerlink" title="Mafka集群保障"></a>Mafka集群保障</h4><p>消息在发给Mafka集群后，Mafka是靠”副本复制”机制确保高可用的，如下图所示:<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/cluster_prot_1.svg"></p><p>生产者将消息发送给Mafka集群，实际是发送到了BrokerA的” topicA-分区1 “上，这个称为主副本，”topicA-分区1 rep1” 和 “topicA-分区1 rep2” 是这个分区 1 的两个副本，topicA-分区 1 的两个副本所在的机器，<br>会实时从主本拉取消息。<br>主本和副本其实都是一个分区的两块相同内容的数据块，为的保障容灾和高可用，分布在不同的服务器上，当某台服务器宕机后，分区数据不会丢失。<br>在ack为- 1的情况下，这两个副本只有读拉取到生产者本次生产的消息后，这次生产才算完成。所以只要生产者将消息发送给了Mafka集群，即便同时有两台机器宕机，这条消息仍然不会丢失。<br>在只有单台机器宕机时，分区的一个副本会转化为主本，继续服务生产和消费，如下图所示：</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/cluster_protect2.svg"></p><p>上边所说的ack是消息生产者的一个属性配置，有三个可选值- 1 ， 0 ， 1 。Mafka的t opic副本数量&gt;=2，生产消息时，用户可以选择ack值，设置为 1 时，只要主本收到即可，设置为- 1 时，必须主本和副本都收到后才<br>算发送成功。<br>设置为 0 时，发送端不需要等待服务端的响应，默认发送成功。Mafka 队列的ack默认配置都是- 1 ，需要主本、副本都收到消息，但对于每分钟超过 600 万的主题，我们建议视业务情况，将ack值设置为 1 ，以取得更<br>好的发送吞吐。</p><h3 id="流量隔离"><a href="#流量隔离" class="headerlink" title="流量隔离"></a>流量隔离</h3><p>为了方便业务开发和测试，Mafka提供了两种流量隔离方案， <strong>环境隔离和泳道</strong> 。<br>如果队列开启 <strong>环境隔离</strong> ，只有相应环境下的消费端才能消费消息，如下图所示:<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/stream_qua.svg"></p><p>同一个队列，生产端会因为自身环境生产不同类型的消息，消费端也只会消费与自身环境匹配的消息。</p><p>环境隔离能解决不同环境下的开发和测试问题，但是当业务链路比较⻓，业务逻辑比较复杂，而且多个QA同时进行测试，有限的几个环境是不能满足测试需求的。</p><p>为此演化出了一个新的流量隔离方案， 泳道 。每个QA测试时，创建一个新的泳道，这条泳道上的消息就是自己独享的，而且当消费方不存在时，泳道上的消息还能回流到⻣干上去，如下图所示:</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/mafka_swm.svg"></p><p>上图中，自身处于泳道A的生产者，生产的消息只能被泳道A环境下的消费者消费，如果泳道A环境下没有部署消费者，那么泳道A的消息将被⻣干消费者消费到。</p><h3 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h3><p>在一些业务场景下，业务RD需要执行一个”操作”后，再发送一条MQ消息通知下游。而且希望这个”操作”和消息是绑定的，只有”操作”成功执行后再发MQ消息，如果”操作”失败了，就不发MQ消息。这就是事务消息使用场景，实现 (“操作”+发消息)的绑定关系，类似数据库里的事务，实现（删除一条数据+插入新表一条数据）两个操作的绑定，即原子性。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/trans_msg.svg"></p><p>Mafka事务消息就解决了这个问题。事务消息能保证本地事务的执行和消息发送两个操作的原子性，要么两个操作都成功，要么都失败。比如本地事务是一个数据库操作，那Mafka事务消息能保证数据库操作和发<br>消息这两个操作的原子性，要么数据库操作和消息发送都成功了，要么都失败了，不会存在一个成功而另外一个操作失败的场景。<br>使用也比较简单，发送事务消息时，实现一个设定好的接口即可，如下：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建事务消息生产者实例，开启事务消息</span></span><br><span class="line"> <span class="keyword">final</span> IProducerProcessor&lt;String, Object&gt; producer = MafkaClient.buildTxnProduceFactory(properties, <span class="string">"my-txn-msg"</span>, <span class="keyword">new</span> <span class="title class_">MyListener</span>());</span><br><span class="line"><span class="comment">// 发送事务消息</span></span><br><span class="line"><span class="type">ProducerResult</span> <span class="variable">result</span> <span class="operator">=</span> producer.sendMessageInTransaction(<span class="string">"transaction message"</span>, <span class="literal">null</span>);</span><br></pre></td></tr></tbody></table></figure><p>注意第三个参数MyListener，这里就是我们实现事务消息逻辑的地方，这个参数必须实现一个接口：</p><figure class="highlight aspectj"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TransactionListener</span> </span>{</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 发送消息成功后，会调用这个方法来执行用户的本地事务</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> msg 消息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> arg 本地事务执行时需要的参数，用户自定义</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Transaction state 返回本地事务执行的结果:提交消息 or 回滚消息(成功or失败)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">LocalTransactionState <span class="title">executeLocalTransaction</span><span class="params">(<span class="keyword">final</span> HalfMessage msg, <span class="keyword">final</span> Object arg)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 如果本地事务执行结果不可知，那么Mafka server端会定期回查本地事务的执行结果，用户在这个方法里定义回查逻辑</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> msg 消息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Transaction state 返回本地事务执行的结果:提交消息 or 回滚消息(成功or失败)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">LocalTransactionState <span class="title">checkLocalTransaction</span><span class="params">(<span class="keyword">final</span> HalfMessage msg)</span></span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>在这个接口里定义本地事务的执行逻辑，如果本地事务执行成功，返回了LocalTransactionState.COMMIT_MESSAGE，那么Mafka就会提交之前发送的消息，如果返回<br>LocalTransactionState.ROLLBACK_MESSAGE，Mafka就会撤回之前发送的消息。<br>同样，消费事务消息也非常简单，在创建消费者实例时，只需要额外配置一个消息消费隔离Level，类似Mysql的事务隔离级别：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//配置消息消费隔离级别</span></span><br><span class="line">properties.setProperty(ConsumerConstants.ISOLATION_LEVEL, IsolationLevel.READ_ALL);</span><br><span class="line"><span class="comment">//创建消费者实例</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">IConsumerProcessor</span> <span class="variable">consumer</span> <span class="operator">=</span> MafkaClient.buildConsumerFactory(properties, <span class="string">"myTopic"</span>);</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>根据这个消费级别，消费你想要的消息。消费隔离级别含有下边几种：</p><ol><li>read_committed 只消费提交的消息 <strong>(default)</strong></li><li>read_rollback 只消费回滚的消息</li><li>read_unknown 消费未知状态的消息</li><li>read_uncommitted（包含 2 和 3 ）</li><li>read_all (包含 1 、 2 、3 )</li></ol><h3 id="优先级消息"><a href="#优先级消息" class="headerlink" title="优先级消息"></a>优先级消息</h3><p>优先级消息通常是需要区别对待消息的消费时间要求，后到的消息因为优先级比较高，需要尽可能早的消费，不同优先级的消息到达后，需要按设定好的优先级顺序消费。</p><p>Mafka优先级消息支持 0~9个优先级，如下所示:</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">IPriorityProducerProcessor</span> <span class="variable">producer</span> <span class="operator">=</span> MafkaClient.buildDelayPriorityProducerFactory(properties, <span class="string">"mafka.xxx.priority.topic"</span>);</span><br><span class="line"> <span class="type">int</span> <span class="variable">level</span> <span class="operator">=</span> <span class="number">1</span>; <span class="comment">// 该级别参数需要业务侧根据业务情况和申请情况进行设置，一般是0-9范围的一个整型值</span></span><br><span class="line"> <span class="type">ProducerResult</span> <span class="variable">result</span> <span class="operator">=</span> producer.sendDelayMessage(level,<span class="string">"send sync message"</span> + i);</span><br><span class="line">  </span><br></pre></td></tr></tbody></table></figure><p>在内部，Mafka使用多个队列来接收不同优先级的消息。业务启动生产者实例后，内部会根据业务设定的优先级发到指定的队列里。<br>消息消费时，仍然是普通的消费接口，优先消费高优先级的，高优先级消费完后再消费低优先级的；当消费低优先级时，有高优先级的消息进来，能够优先消费高优先级的消息。<br>在消费者内部，Mafka会确保每个分配到Parition(分区)的消费者，能分配到Topic的所有Parition，以此确保高优先级的会被优先消费，如下图:</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/pri_msg.svg"></p><p>topic-0、t opic-1、t opic-2分别代表 3 中不同级别的优先级：0(高)、1 (中)、2 (低)。Mafka收到消息后，会根据消息的优先级级别，放在三个不同的队列上。<br>每个优先级队列又有多个分区，确保生产和消费吞吐速度，比如topic-0的p artition-0，p artition-1，p artition-2。c onsume-1、c onsume-2、c onsume-3分别代表不同的消费者，<br>每个消费者上线以后，Mafka调度会负责将所有优先级级别队列的相同分区分配给同一个消费者，比如consume-2分配到了topic-0的 1 号分区，topic-1的 1 号分区，topic-2的 1 号分区。<br>这样consume-2在消费时，会从高到低的扫描各队列是否有消息进来，如果有户优先消费级别高的队列里的消息，没有高级别的消息时，再去消费低级别的消息，每消费一条消息会再次扫描所有级别的队列，再次<br>给高优先级的队列消费机会。<br>Mafka优先级消息还支持消息延迟投递，同样也支持死信方式投递和消费，消费失败后，需要支持根据优先级投递到指定优先级对应的死信队列中。在消费时，同一优先级下，优先消费死信队列中的消息</p><h3 id="其他消息队列特性支持"><a href="#其他消息队列特性支持" class="headerlink" title="其他消息队列特性支持"></a>其他消息队列特性支持</h3><p>除了以上介绍的功能之外，Mafka支持大部分传统消息队列的特性，包括以下几点:</p><ol><li>基于消息的发送时间、offset回溯</li><li>队列粒度的消息消费延迟</li><li>消息的并行生产、并行消费</li><li>消息查找、消息轨迹</li><li>批量消费功能</li><li>消费异常重试次数自定义，或跳过有问题的消息</li><li>消费端在消费消息时，消费者上下线，支持粘性分配，减少分区变动</li></ol><h3 id="美团公司特有功能支持"><a href="#美团公司特有功能支持" class="headerlink" title="美团公司特有功能支持"></a>美团公司特有功能支持</h3><ol><li>支持故障注入，为客户端提供故障模拟功能，用于线上事故演练等场景</li><li>支持消息生产和消费以set方式隔离</li><li>灰度链路，支持业务线上灰度链路发布</li><li>线上蓝绿发布支持</li><li>全链路压测支持，方便业务在线上做全链路压测</li><li>主题鉴权，方便业务对队列做生产和消费权限控制</li><li>支持以Storm/Flink方式接入生产和消费</li></ol><h3 id="Mafka延迟消息"><a href="#Mafka延迟消息" class="headerlink" title="Mafka延迟消息"></a>Mafka延迟消息</h3><p>延迟消息是消息队列的主要功能之一，支持每个消息以特定时间的延迟投递。Mafka延迟消息支持5s~N天的自定义延迟时间投递，同时还支持改签、撤销、统计等功能。<br>用户使用时，在客户端SDK内初始化延迟队列的生产实例后，即可发送延迟消息。</p><figure class="highlight aspectj"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function">ProducerResult <span class="title">sendDelayMessage</span><span class="params">(V message, <span class="keyword">long</span> delayTime)</span> <span class="keyword">throws</span> Exception </span>;</span><br></pre></td></tr></tbody></table></figure><p>已经发送给Mafka的延迟消息，可以在消息到期之前重新设定投递时间，或撤销掉，另外还可以在平台上查询统计到未来一段时间即将到期的被投递的消息数量。</p><h3 id="Mafka-Push消费端"><a href="#Mafka-Push消费端" class="headerlink" title="Mafka Push消费端"></a>Mafka Push消费端</h3><h4 id="分片和消费者数量紧耦合问题"><a href="#分片和消费者数量紧耦合问题" class="headerlink" title="分片和消费者数量紧耦合问题"></a>分片和消费者数量紧耦合问题</h4><p>普通消息的客户端，是在SDK内通过和服务端的私有二进制协议来拉取消息的，而且消费者分配方式也是遵循队列的一个分区只能分配给一个消费者来消费。</p><p>这样的模型导致消费者和分区之间的比较紧的耦合关系，当用户的消费能力不足，需要增加消费者时，分区数量也必须增加。比如有 3 个消费者，分别消费 3 个分区，每个消费者负责消费一个分区，当消费者数量增加到 5 个时，分区同时也需要增加到 5 个，以便新增的 2 个消费者也有消息可消费。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/consume_p_problem.svg"></p><p>当消费者数量比较少时，这样的匹配关系好，但是当消费者数量是 100 甚至 200 个，队列消息量又不大，而分区如果也跟着扩容到 100 或 200 时，资源就会比较浪费。</p><h3 id="消费组Rebalance问题"><a href="#消费组Rebalance问题" class="headerlink" title="消费组Rebalance问题"></a>消费组Rebalance问题</h3><p>消费者在消费Mafka消息时，需要持有分区，如果一个队列有6个分区: P0，P1，P2，P3，P4，P5， 2 个消费者，那么这两个消费者分别会持有 3 个分区，如下图所示:<br>消费者 1 持有P0 、P1、P2，消费者2持有P3 、P4、P5，如果再添加第三个消费者，Mafka会充分利用所有的消费者资源，根据现有消费者个数重新分配分区，理想情况下平均分配，消费者 1 分到P1 、P2，消费者 2 分到P4、P5，消费者 3 分到P0 、P3。</p><p>这里P0 和P3分区，是从原来的消费者1和消费者2持有的分区里调出来的，这两个分区从原来的消费者停止消费，到消费者3开始消费，为了防止消息被重复消费，中间需要一个平滑的切换过程。比如从消费者 1 内调出P0后，需要挂起P0 分区，等待一段时间让客户端将P0分区的Offset提交完成，然后再将P0 分区分配给消费者3来继续消费，整个过程，挂起P0 分区那段时间会造成P0 分区的短暂积压，这就是比较知名的”消费组rebalance”问题。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/consume_rebalance_p.svg"></p><p>虽然Mafka在服务端使用调度器和客户端做紧密的协作，能将问题积压时间控制在秒级，但仍然不能完全消除这个时间。</p><h3 id="Push消费组来解决"><a href="#Push消费组来解决" class="headerlink" title="Push消费组来解决"></a>Push消费组来解决</h3><p>针对上述的两个问题，Mafka推出Push消费组服务来解决，这个服务简称PushServer。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/push_solve.svg"></p><p>PushServer是一个RPC服务，消费者不再直接从Mafka Broker拉取消息，而是改从PushServer代理获取消息。这里PushServer持有这个队列的所有分区，先把消息统一拉取到本地，然后供客户端通过RPC调用方<br>式来消费。<br>这样做的好处第一是解耦了客户端数量和服务端分区数量之间的紧耦合，即上边所说的第一个问题，因为客户端现在不需要持有任何分区，可以以RPC方式发起调用即可拉取到一条消息来消费，第二个好处就是消<br>费者数量可以无限扩展，不受服务端分区资源数量的限制，而且不需要做消费者之间的分区调配，即上边所属的第二个问题—“消费组Rebalance”。<br>PushServer很好的解决了对积压非常敏感，不希望在消费过程中因为消费者上下线导致消费抖动，而且有大量消费者参与消费的队列。但是因为中间多了一层代理，pushServer从所有分区拉消息，然后以RPC接口<br>方式提供消费，打乱了分区内的消费顺序。因为从一个分区内拉取的消息，有可能并发的被多个客户端同时消费，所以使用PushServer代消费时，消息的保序只能做到上边所说的大致有序。</p><h2 id="监控-告警"><a href="#监控-告警" class="headerlink" title="监控&amp;告警"></a>监控&amp;告警</h2><p>在Mafka的管理平台，用户可以实时查看自己的队列生产和消费情况。</p><h3 id="生产监控"><a href="#生产监控" class="headerlink" title="生产监控"></a>生产监控</h3><p>如下图所示，平台会监控生产速度，以及生产延迟，查看48h内的队列发送信息，还可以查看和搜索实时的生产者实例信息。<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/produce_mo.jpg"></p><h3 id="消费监控"><a href="#消费监控" class="headerlink" title="消费监控"></a>消费监控</h3><p>消费组实时消费速度，如下图所示，两种颜色分别代表两个机房的同一队列的消费速度：</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/consume_mo.jpg"></p><p>消费组积压信息，按分区来展示，消费组消费时延监控，消息的延迟监控：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/pile_mo.jpg"></p><p>消费者实例信息，以及消费状态信息：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/consume_instance.jpg"></p><h3 id="告警"><a href="#告警" class="headerlink" title="告警"></a>告警</h3><p>Mafka的告警支持自定义配置，包括消息积压，消费速率，消费者数量等告警项，持续时间、生效时间，阈值等配置项，如下图所示：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/topic_mo.jpg"></p><h2 id="容灾、故障转移"><a href="#容灾、故障转移" class="headerlink" title="容灾、故障转移"></a>容灾、故障转移</h2><p>Mafka容灾等级分为单节点、集群、机房、地域，故障转移方式分为 <strong>主动和被动</strong> ，主动就是业务客户端做发起故障转移，被动就是服务端发起故障转移。</p><h3 id="主动故障转移"><a href="#主动故障转移" class="headerlink" title="主动故障转移"></a>主动故障转移</h3><p>主动故障转移分为分片故障转移，节点故障转移，集群故障转移。</p><p>分片故障转移是指，当某个分片暂时不可用时，客户端主动将此分片的消息发往其他可用分片。</p><p>节点故障转移是指，当某个节点暂时不可用时，将此节点暂时拉黑，把消息发往其他可用节点上的分片。</p><p>集群故障转移是指，当某个集群暂时不可用时，将此集群暂时拉黑，把消息发往其他可用的集群上。如上所述，用户在申请Mafka消息队列时，Mafka至少为此队列配置 2 个可用的集群。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/active_move.svg"></p><p>如以上的Makfa集群A，有四个节点，节点A、B、C、D，假设有一个队列topicA，有四个分区P0 、P1、P2、P3分别分布在A、B、C、D四台机器上。当分片P0 暂时不可用时，Mafka会将消息发往P1/P2/P3分片<br>上。<br>如果当节点A不可用时，原本发往节点A上分片的消息发往其他节点的分片上。<br>如下图，对于同一个队列topicA，在集群A上有 4 个分区，在集群B上有 4 个分区，A、B两集群处于不同的机房，正常情况下，消息会发往 2 个集群的 8 个分区，但如果集群A不可用时，比如机房断网、断电时，客户端<br>会主动熔断，将消息全部发往集群B。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/active_move_2.svg"></p><h3 id="被动故障转移"><a href="#被动故障转移" class="headerlink" title="被动故障转移"></a>被动故障转移</h3><p>主动故障转移是客户端自动探测并执行的，整个过程依据默认参数设置比如网络timeout，冻结时间等自动触发的。被动故障转移是人工执行的，比如当某个机房断网、断电时，人工执行切换操作。<br>这个操作是人工在服务端设置某个集群不可用，让服务端下发指令给客户端，发起故障转移，停止发送消息到某一个集群。<br>整个操作如下图所示：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/passive_move.svg"></p><h3 id="高可靠集群模式"><a href="#高可靠集群模式" class="headerlink" title="高可靠集群模式"></a>高可靠集群模式</h3><p>不管是主动还是被动的故障转移，其实质就是停止向故障机房的集群发送或消费消息，生产和消费客户端都与他们断开连接，如下图所示：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/high_dua.svg"></p><p>这种容灾模式下，当机房故障能在短时间内恢复，或集群恢复后，都可以继续使用。因为消息队列的特性，业务方大多数只关心增量消息的可用性，故障产生后，比如只要增量的订单消息能继续生产或消费，对业务的影响都不是很大。存量未消费的消息，在上图中标为红色的部分，一方面因为对积压敏感的用户，生产和消费追的都会比较紧，基本不会产生多少条积压，所以影响不大，对积压不敏感的用户完全可以在机房或集群恢复后，继续生产和消费，只影响短暂的消费可用性。所以，这种双机房容灾模式，能满足绝大多数用户的需求。</p><p>但是对于消息可靠性要求非常高的业务场景，比如金融交易，或是上下游需要严格对账、审计类的消息，暂时几条消息不能消费的话，对业务影响会比较大。</p><p>针对这种场景，Mafka有跨机房集群来解决，如下图所示：</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/hig_du_solve.svg"></p><p>整个集群包含四个节点，BrokerA、BrokerB，B rokerC，BrokerD，每个分区的主本、副本被均匀的分布在两个机房，比如分区P0 的主本，P1 的副本都在机房A，分区P1 的主本、P0 的副本在机房B。<br>当客户端生产一条消息后，消息的主本存储了消息后，消息的副本也会存储，所有消息经过跨机房复制，保持副本一致。这样当一个机房故障后，可用机房的消息的副本会切换为主本，继续提供生产、消费服务，<br>保持高可用，高可靠。<br>当然，和其他高可用组件一样，通过跨机房复制数据，来严格保障数据的高可靠，会因机房间网络延迟和质量的影响，降低集群一定的吞吐率，所以具体还要根据业务实际情况来建设集群。</p><h2 id="运营"><a href="#运营" class="headerlink" title="运营"></a>运营</h2><h3 id="管理平台"><a href="#管理平台" class="headerlink" title="管理平台"></a>管理平台</h3><p>Mafka有两个运营平台，一个是管理平台，面向的用户是业务方使用人员，主要进行主题、消费组的创建、配置、监控和管理等，如上述所说的监控和报警就属于管理平台的一部分，主⻚界面如下：</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/use_plat.jpg"></p><p>在主题⻚面，可以进行各类的配置和管理：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/topic_config.jpg"></p><p>消费组⻚面:</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/consume_config.jpg"></p><h3 id="运维平台"><a href="#运维平台" class="headerlink" title="运维平台"></a>运维平台</h3><p>另外一个是运维平台，主要面向的是SRE运维人员和Mafka RD开发人员。运维平台主要功能包括集群创建、版本发布、监控和管理，主界面如下图所示：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/op_plat.jpg"></p><p>运维平台上，查看某个集群的节点信息：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/cluster_member.jpg"></p><p>集群负载：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/cluster_lode.jpg"></p><p>集群metrics:<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/cluster_metrics.jpg"></p><p>另外还包含其他运维功能，在这里不一一详述：<br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/other1.jpg"><br><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/other.jpg"></p><h2 id="架构概览"><a href="#架构概览" class="headerlink" title="架构概览"></a>架构概览</h2><p>从架构上来看，Mafka主要包含以下几个模块:</p><ol><li>Castle: 消息队列中控调度器</li><li>Broker: 消息收发和存储，基于kafka 0.9.01版本自研</li><li>ClientSDK: 业务使用的消息服务SDK，基于kafka client 0.8和0 .9版本自研</li><li>DelayServer API &amp; Scheduler: 延迟消息的两个组件API和Scheduler调度器</li><li>Zookeeper: Broker使用的消息队列元数据存储</li><li>PushServer: Push代消费服务</li><li>TOM: 集群资源控制器，负责Broker上主题、消费组资源的增加、删除，分区、leader、副本分布管理</li><li>Scanner: Broker存活状态扫描服务，会将dead的broker从zookeeper中摘除</li><li>Monitor: 用户主题、消费组监控服务，比如主题生产消费速度、延迟、积压等监控</li><li>管理平台：面向用户的mafka消息队列管理界面服务</li><li>运维平台：面向SRE、研发RD的集群、服务运营工具服务</li><li>外部KV存储: KV存储，服务于延迟消息的存储服务，以及线上主题及消费组配置的快速缓存</li></ol><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/mafka_arch.svg"></p><h5 id="如上图所示，消息的生产、消费交互流程如下"><a href="#如上图所示，消息的生产、消费交互流程如下" class="headerlink" title="如上图所示，消息的生产、消费交互流程如下:"></a>如上图所示，消息的生产、消费交互流程如下:</h5><ol><li>生产端和消费端服务在启动时，会先通过RPC调用和castle形成一个心跳机制，定期获取配置信息和控制指令。</li><li>拿到配置信息后，客户端获取到了Broker集群地址和配置等信息，就可以开始生产和消费消息了。</li><li>如果是延迟类消息，需要将消息以RPC方式发送给DelayServer API服务，将消息暂存在基础存储中，Scheduler调度器定期根据延迟时间分发消息到broker，然后消费方才能获取到消息，进行消费。</li><li>如果消费方希望以RPC接口调用方式消费，可以调用PushServer服务，获取消息消费。</li></ol><p>辅助系统交互逻辑：</p><ol><li>用户通过管理平台创建主题、消费组，管理平台协调TOM在b roker上生成物理资源，创建成功后将数据落入mysql，并将数据缓存一份在KV存储中。</li><li>TOM负责在broker上创建主题、消费组，并将结果反馈给管理平台。</li><li>TOM不仅负责真实资源的创建，还负责Broker集群上分区的分布，副本以及leader的分布平衡。他会自动采集午高峰、晚高峰的主题实际生产和消费量，根据分区分布，leader分布，分区读写QPS信息，分区<br>磁盘占用量等各项指标做综合分析，按照结果将集群内分片和leader信息平衡起来。</li><li>运维平台负责集群的创建，集群配置管理，节点上下线，集群内节点信息的界面展示等功能，是人工运营Broker集群的直接工具。</li><li>Scanner负责监控集群内Broker的存活状态，不断循环扫描broker的服务端口，判断是否宕机，将宕机的服务从zookeeper上摘除掉。原生的Kafka集群在zookeeper上使用的是临时结点，Mafka将其改造为持<br>久节点，依靠scanner来主动判断broker是否宕机。</li></ol><h2 id="演进方向前瞻"><a href="#演进方向前瞻" class="headerlink" title="演进方向前瞻"></a>演进方向前瞻</h2><h3 id="云原生时代，Mafka的挑战"><a href="#云原生时代，Mafka的挑战" class="headerlink" title="云原生时代，Mafka的挑战"></a>云原生时代，Mafka的挑战</h3><p>现代的微服务架构充分使用了云的基础设施，实现高扩展性，高可用性，以及高韧性，面对市场形势多变的特点，以及互联网业务发展迅猛的形势，企业必须对业务进行快速的开发和迭代，以抢占瞬息万变的市场机会。</p><p>云原生应用的最大特点就是快速拥抱变化，他们可以在几分钟内快速的扩容，缩容，迁移，销毁，以应对业务和市场快速的需求变化。这对应用和服务的周边配套设施，如构建，部署，配置，监控，PaaS，IaaS等<br>支持服务提出了更高的要求，包括Mafka。<br>Mafka将通过以下几个架构调整来满足云原生代的业务需求：</p><ol><li>组件各模块都接入k8s和容器，提升集群的扩展能力</li><li>去除ZooKeeper依赖，提升broker的扩展性</li><li>使用分层存储，减少本机存储的消息量，提升存量分区的迁移速度，提升扩展速度和效率</li></ol><h3 id="业务需求对Mafka的挑战"><a href="#业务需求对Mafka的挑战" class="headerlink" title="业务需求对Mafka的挑战"></a>业务需求对Mafka的挑战</h3><h4 id="流量隔离、hash生产、消费模型对Mafka带来的资源压力"><a href="#流量隔离、hash生产、消费模型对Mafka带来的资源压力" class="headerlink" title="流量隔离、hash生产、消费模型对Mafka带来的资源压力"></a>流量隔离、hash生产、消费模型对Mafka带来的资源压力</h4><p>由于业务发展的需求，Mafka支持多重流量隔离方案，比如泳道，方便了QA人员同时开展多条测试链路，每个泳道的消费者只消费本泳道生产者生产的消息，如果下游没有泳道消费者，⻣干的消费者需要把泳道的消息也消费掉。</p><p>类似的流量隔离方案，还有环境隔离，比如test/dev/prod/stage各类测试和生产环境；Set化隔离，比如North、East、West、South等各种Set。Mafka在满足这些流量隔离时，采用的是使用队列模拟，但这种方式在底层实现时，经过各种条件的排列组合，会产生很多的队列资源消耗。</p><p>另外一方面，Mafka的消息队列在被业务客户端消费时，受限于Mafka的消费模型，一个队列的一个partition只能被一个消费者消费，当用户使用hash key的方式来生产时，或用户的消费者很多的时候，这时Mafka<br>就必须为业务扩容partition，增加更多的分区，以便新创建的消费者能消费到消息。在这种场景下，Mafka partition资源的消耗并不是来自于队列流量的增加，而仅仅是业务消费者数量的增加，消费者数量和<br>partition数量有紧密的耦合关系，导致partition资源的消耗。</p><p><strong>Mafka4 读写分离来解决</strong></p><p>以上所说的三个问题，不管是队列资源的消耗，还是partition资源的消耗，都会让整个集群的partition数量的增⻓，从而消耗整个集群的容量。最明显的问题，就是整个集群的partition数量增加到一定程度后，用户的生产发送耗时会增加，集群吞吐量会降低。<br>对于这个问题，业界和Kafka社区并没有现成的策略和办法来参考。经过我们的测试和调研，提出了Mafka 4解决方案，通过队列合并来，分离读写节点来解决这个问题。</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/mafka4_concept.svg"></p><p>如上图所示，Mafka4在原有分区的概念之上，引入了”虚拟分区”的概念，来承担消费端的读取，原有分区只用来承担写入，为了区分两种分区，写入消息的分区称为”物理分区”。</p><p>消息发送到Mafka之后，先写入物理分区，进过集群内节点之间的数据复制和拆分，再同步到虚拟分区上。<br>通过这种设计，整个集群内物理分区的数量只会与写入速度相关，消费端新增消费者时，只需要扩充虚拟分区即可，不再需要增加物理分区数量。<br>Mafka 4 改变了原有Kafka的读写模型，与原生Kafka副本通过ISR概念一样，在读节点上引入了”RISR”概念来管理副本的状态。<br>Mafka 4目前正在研发阶段，第一期研发已经完成，通过初步的性能测试，Mafka 4集群比现有Mafka3 写入延迟tp999下降了将近 10 倍，集群机器节点使用量降低了近 1 倍！<br>2022 年Q 1会完成Mafka 4所有模块的研发，届时会上线实际接入用户队列，同时也会有专项的技术介绍blog发布，敬请期待。</p><h4 id="实时计算业务的痛点"><a href="#实时计算业务的痛点" class="headerlink" title="实时计算业务的痛点"></a>实时计算业务的痛点</h4><p><strong>引入Kafka Stream 来构建一站式流式计算</strong></p><p>随着业务的发展，实时计算技术近年来逐渐成熟起来，比如storm/flink一类实时计算框架，我们公司大数据业务也有相应的服务。<br>通常情况，在线业务在使用实时计算时采用的如下的架构：</p><p><img src="/2021/04/15/%E7%BE%8E%E5%9B%A2%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97Mafka/storm_problem.svg"></p><p>业务先将数据发送到Mafka，然后再storm、flink平台上消费Mafka的消息，来做实时计算，计算完成后将数据再推送回Mafka，供在线业务消费和展示。</p><ol><li>这种架构需要先将从Mafka消息搬迁到实时计算平台上，多了一次传输，浪费了一些时间和效率。</li><li>而且在问题排查方面，storm和f link非常不友好，因为业务需要将自己的代码上传到这两个平台上，程序实际是在远程平台上执行的，而远程平台又是大集群、多用户，调查问题、调试程序非常麻烦，效率低下。</li><li>另外，storm和flink自身有一定的复杂度，入门成本也比较高，对于一些只需要做一个简单窗口聚合计算的用户来说比较重，需要花时间和精力先学习。</li></ol><p>实际上Kafka官方本身就支持轻量的实时流式计算服务，叫做Kafka Stream。Kafka Stream是集成在Kafka内部的轻量流式计算库，他跟Kafka集成在一起。<br>不同于Flink和Storm，Kafka Stream不是一个平台，不需要用户将代码打包上传到平台上，他只是一个简单的lib库，用户像写应用程序一样写流式计算服务，编译打包成功后，运行在用户自己的机器上。<br>Mafka将引入Kafka Stream来承担一部分轻量式的流式计算业务，提升业务的接入和开发流式计算服务的效率。</p><h2 id="团队介绍"><a href="#团队介绍" class="headerlink" title="团队介绍"></a>团队介绍</h2><p>作者简介：王军飞（wangjunfei02）丨基础技术部-中间件研发中心-消息中间件组，消息中间件团队负责人。</p><p>团队介绍：美团基础技术部-基础架构团队诚招高级、资深技术专家，Base北京、上海。我们致力于建设美团全公司统一的高并发高性能分布式基础架构平台，涵盖数据库、分布式监控、服务治理、高性能通信、消息中间件、基础存储、容器化、集群调度等基础架构主要的技术领域。</p>]]></content>
    
    
    <summary type="html">本文介绍了美团消息队列产品Mafka</summary>
    
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="rocketmq" scheme="https://wangjunfei.com/tags/rocketmq/"/>
    
    <category term="kafka" scheme="https://wangjunfei.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>「转」项目管理-OKR</title>
    <link href="https://wangjunfei.com/2021/04/03/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-OKR/"/>
    <id>https://wangjunfei.com/2021/04/03/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-OKR/</id>
    <published>2021-04-02T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.820Z</updated>
    
    <content type="html"><![CDATA[<h1 id="WHY-WHAT-HOW"><a href="#WHY-WHAT-HOW" class="headerlink" title="WHY-WHAT-HOW"></a>WHY-WHAT-HOW</h1><p> OP1-》OKR-》MBR-》QBR覆盖了基本的战略，目标和结果管理</p><p> OP1通过自下而上和自上而下的结合制定部⻔中期战略（ 1 年）和核心产品以及成本预算</p><p> MBR检测进度和问题</p><p> QBR复盘挑战优先级和资源</p><p> OKR是战略到执行的</p><p> 聚焦，OKR数量有限，只注重核心目标</p><p> 链接，它具体化了战略和衡量指标</p><p> 扩展，它还可以包括一些过程管理，非项目管理，个人目标</p><p> OKR的常⻅误区</p><p> OKR是重点工作，不是“全部工作”，只完成OKR是不够的，但是OKR是优先的。</p><p> 执行OKR一个比较大的误区是把它当成了KPI和绩效挂钩，阻碍了员工的自我挑战性和创新性。所以OKR要区分</p><p><strong>承诺型</strong> 和  <strong>愿景型</strong></p><p> OKR关键是通晒和对⻬，但是不用僵硬地完全对⻬（OKR是化学拆解、聚合，不是物理拆解）。</p><figure class="highlight actionscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OKR是实践，不是理论。对于难以衡量和不确定性的挑战，可以少定义一些，要具有灵活性，不断迭代。Less <span class="keyword">is</span> more。</span><br></pre></td></tr></tbody></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><h3 id="如何既保持OKR的自我挑战又结合绩效"><a href="#如何既保持OKR的自我挑战又结合绩效" class="headerlink" title="如何既保持OKR的自我挑战又结合绩效"></a>如何既保持OKR的自我挑战又结合绩效</h3><ul><li><a href="http://www.sohu.com/a/307154455">http://www.sohu.com/a/307154455</a>_</li><li><a href="https://www.sohu.com/a/305839211_659569?sec=wd">https://www.sohu.com/a/305839211_659569?sec=wd</a></li></ul>]]></content>
    
    
    <summary type="html">项目管理-OKR方法</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>「转」项目管理-OKR编写规范</title>
    <link href="https://wangjunfei.com/2021/04/03/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-OKR%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/"/>
    <id>https://wangjunfei.com/2021/04/03/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-OKR%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/</id>
    <published>2021-04-02T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.820Z</updated>
    
    <content type="html"><![CDATA[<p>OKR管理机制示意图</p><p><img src="/2021/04/03/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-OKR%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/okr_demo.svg"></p><h3 id="OKR制定"><a href="#OKR制定" class="headerlink" title="OKR制定"></a>OKR制定</h3><p>部门总OKR向下层层拆解（化学拆解），review后，所有层级形成一系列有逻辑关联的OKR表，逻辑关联要求下层所有的Os合并起来覆盖上一层KRs。在展现和跟踪时候，按不同汇报需求，不同层级的表合并成一个大表。在实际运营时候，每一层级表相对独立，有相应部⻔维护。</p><ul><li>“O”的设定要合理，如果因为大目标很难SMART，则需要宏观、概括，表现有趋势。比如用“满意度提高 0.5 分”作为“O”不太合适。</li><li>KR的ETA都应该是这个Q。落地时间较⻓的结果需要设定 季度目标 迭代完成，分拆成多个Q的KR完成。</li><li>部门OKR的制定过程需要自上往下和自下往上双向对⻬。部⻔/中心OKR的制定方式需要根据实际情况上下对⻬。</li><li>跨团队项目的“O”归属在STO所在部⻔，可以要求协同部⻔设定KR，支持该项目。</li><li>大部门及各部⻔/中心OKR需要在大部门内部透明，可以根据客户需求提供。X1的OKR应该对大部透明。</li></ul><p>OKR模板<br><img src="/2021/04/03/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-OKR%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/okr_temp.png"></p><p><strong>注：项目里程碑通常粒度比KR小，里程碑可以是KR目标说明。</strong></p><h3 id="OKR复盘"><a href="#OKR复盘" class="headerlink" title="OKR复盘"></a>OKR复盘</h3><h4 id="每季度（OKR-对⻬会议）"><a href="#每季度（OKR-对⻬会议）" class="headerlink" title="每季度（OKR 对⻬会议）"></a>每季度（OKR 对⻬会议）</h4><ul><li>在季度末召开大部门OKR会议。会上review BU及BU-1 该季度OKR的达成情况和下季度的OKR内容。review结果更新到该季度/下季度的OKR。</li><li>从部门至X1节点，各层组织节点的整体OKR完成率达到 75 %是比较优秀的。</li><li>建议各BU- 1 部⻔内部做该季度的OKR review（达成情况、根因分析、改进方案），并讨论对⻬下一个Q的OKR。</li><li>每个部⻔/中心，每个Q需要一个OKR⻚面，放在这个子目录下（权限设置为大部门可⻅）：ITU 2020 - OKR。如“服务运维部-Q1 - OKR”⻚面。符合“ OKR填写原则 ”：不超过 4 个目标方向（O）；每个目标下，不超过 5 个关键行动（KR）；每个KR，都有smart的目标。</li><li>「KR完成情况」中需要明确 各个阶段性成果的完成率 ，</li></ul><ul><li>100 % ：完成结果达到预期/超出预期达成。【若超预期达成，标记状态时需注明超预期说明】</li><li>≥ 75 % ： 100 % &gt; KR完成率 ≥ 75 %。【需注明延期原因和延期完成时间】</li><li>≥ 50 % ： 75 % &gt; KR完成率 ≥ 50 %。【需注明延期原因和延期完成时间】</li><li>&lt; 50 % ： 50 % &gt; KR完成率。【需注明延期原因和延期完成时间】</li><li>已取消 ： 由于某种因素，原定阶段性产出不再符合部⻔/中心目标，需取消【需注明取消的原因】</li></ul><h4 id="每月（MBR-review）"><a href="#每月（MBR-review）" class="headerlink" title="每月（MBR review）"></a>每月（MBR review）</h4><ul><li>在MBR上review 各BU- 1 部⻔的OKR达成情况。 更新OKR表格，并将OKR表格copy至MBR PPT。</li><li>「KR完成情况」需要明确 各个阶段性成果的产出 ，需要标记“状态”：<ul><li>100 % ：根据KR路径拆解完成阶段性产出， 完成结果达到预期/超出预期/延期达成 。【若延期/超预期达成，标记状态时需注明超预期说明/延期说明及时间】</li><li>xx% ：阶段性产出进行中或者方案制定中， 产出进度正常 。【标记状态时需注明当时已完成产出的百分比】</li><li>xx% ：阶段性产出进行中或者方案制定中， 出现延期⻛险但可控 。【标记状态时需注明当时已完成产出的百分比、延期说明】</li><li>xx% ：阶段性产出进行中或者方案制定中， 已经确定出现延期 。【标记状态时需注明当时已完成产出的百分比、延期说明及预计完成时间】</li><li>未开始 ：阶段性产出还在准备中，相关任务未正式开始。</li><li>新增 ：根据KR路径拆解的调整，需新增的阶段性产出。</li><li>已取消 ： 由于某种因素，原定阶段性产出不再符合部⻔/中心目标，需取消【标记状态时需注明取消的原因】</li></ul></li><li>「具体进展」需要对「KR完成情况」做具体说明，突出重大进展、⻛险和问题。每月更新可直接覆盖上月内容。</li><li>所有Tracking留有痕迹，所有需要修改的内容，均用“中划线”做更改，而禁止删除。<ul><li>所有痕迹需要标注在「Tracking标注」中：“修改日期”及“【增】、【删】、【改】” 及 “修改原因”。 举例 ：KR 3 标注： 2 月5日【改】：受限于HC的限制和不胜任人才的影响，人才胜任力的汰换需要小步迭代逐步建立标准，故更改为…..。</li><li>所有更改必须在MBR上review。包括主R人的更改。<br>每周/双周（WBR review）<br>建议部⻔/中心负责人内部周/双周review BU- 1 至X1节点的OKR达成情况。 更新OKR表格。整体要求与MBR保持一致。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">项目管理-OKR编写规范</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>消息队列业界调研</title>
    <link href="https://wangjunfei.com/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/"/>
    <id>https://wangjunfei.com/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/</id>
    <published>2021-03-25T16:00:00.000Z</published>
    <updated>2024-03-24T00:58:30.797Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h1><p>消息队列是现代互联网企业技术中不可缺少的一个中间件，主要用来做组件解耦、流量削峰、异步处理，支持订阅发布(pub/sub)模式，在业务或数据的上下游中，起到一个链接作用。最早在 2000 年左右，J2EE2.0时代，消息队列有Sun主导的JMS标准，实现这个标准的产品比较多，比如IBM WebsphereMQ，Apache Active MQ，RabbitMQ等。到 2012 年后，随着linkedin开源自建的消息队列Kafka，Apache Kafka逐渐<br>成为引领开源社区消息队列的潮流。 2016 年，阿里巴巴将RocketMQ贡献给Apache，2018年后，Yahoo开始开源自己的消息队列产品Pulsar并贡献给Apache，两者都变成了apache的顶级项目。</p><p><strong>主要产品</strong></p><p>从整个互联网行业来看，Amazon云，阿里云，腾讯云，京东云以及各大知名互联网公司，都有自己的消息队列服务，产品非常多，可以参照附录A，但是开源的比较少。本文为了更准确和客观，仅分析公布了源代码的产品，一方面是因为根据源代码来做出的调研和分析得出的结论更有客观依据，另一方面是因为这些开源的产品基本上覆盖了整个行业的绝大部分用户。这些开源的产品主要包含Kafka、RocketMQ、Pulsar。下边从产品功能和技术架构两个方面，分别简单介绍下这些产品。</p><h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><p>功能分为几类，基本功能，高级功能，个性化功能和前沿功能。所谓的基本和高级功能，是作为消息队列这个产品本质来说，必须具有的基础功能点。个性化功能是指各个产品开发的具有本产品特色的功能，这些功能并不是消息队列产品必须具备的。前沿功能是指行业的领头羊正在做的活研究的功能点，他不是消息队列必须的发展方向，仅代表个体厂商的动向。</p><p><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/fea_comp.png"></p><h3 id="基本功能"><a href="#基本功能" class="headerlink" title="基本功能"></a>基本功能</h3><ul><li>四个产品都支持最基础的顺序消息生产和消费功能，Kafka不支持定时消息和死信。消息回溯方面，Pulsar只支持根据MessageId做回溯，不支持按时间和offset。定时消息方面，RocketMQ只支持按固<br>定时间的延迟，比如1m,5m,10m等有限数量的延迟，Pulsar只支持单机内存大小的定时消息，功能弱一些，Kafka不支持定时消息，Mafka支持任意时间的的定时消息。</li></ul><h3 id="高级功能"><a href="#高级功能" class="headerlink" title="高级功能"></a>高级功能</h3><ul><li>RocketMQ和Mafka都支持事务消息和消息轨迹，除此之外，Mafka还支持优先级消息和跨集群、地域的生产者、消费者客户端调度。</li></ul><h3 id="个性化功能"><a href="#个性化功能" class="headerlink" title="个性化功能"></a>个性化功能</h3><ul><li>Mafka支持比较多的美团公司特有的功能需求。</li></ul><h3 id="前沿功能"><a href="#前沿功能" class="headerlink" title="前沿功能"></a>前沿功能</h3><ul><li>Pulsar和Kafka都在往轻量流式计算、云原生方面演进，特别是Kafka，在轻量流式计算方面已经发展了超过 3 年，功能相对成熟，Pulsar在对标追赶。云原生方面，Kafka和P ulsar都有自己的商业运营平<br>台在做相关的扩展，比如快速扩容，按需付费，无需devops。开源社区方面，两个组件都在做分层存储，支持在廉价的存储介质上做⻓期存储，比如HDFS、S3、云存储等。Kafka单独在演进”KIP-500”—去除zookeeper，方便Kafka的部署和维护。</li></ul><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><h3 id="Apache-Kafka"><a href="#Apache-Kafka" class="headerlink" title="Apache Kafka"></a>Apache Kafka</h3><p>Kafka的整体架构</p><p>Kafka集群主要包含Kafka Broker本身，以及zookeeper组件，如下图所示。<br><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic9.svg"><br><strong>Kafka Broker:</strong> 主要存储消息数据，同时提供R PC接口，供客户端发送、拉取消息。</p><p>**Kafka 集群:**上图中，BrokerA、BrokerB、BrokerC、BrokerD四台机器组成一个集群，其中Broker C被选为controller。集群controller主要用于管理集群内节点、副本、分区的上下线，以及队列的创建、删除、扩容分区等。</p><p><strong>ZooKeeper:</strong> 在Kafka集群中，主要用来做集群选主、副本选主，同时存储集群元数据，如Topic、Partition、Replica等。</p><p><strong>Consumer Group:</strong> 主题的消费组</p><p><strong>Prodcuer：</strong> 主题的生产者</p><p><strong>分区和副本，高可用和高可靠</strong><br>Kafka Broker内的分区和副本，如下图所示:<br><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic11.svg"></p><ol><li>整个集群有3台机器组成</li><li>集群内有一个topic，这个topic有 3 个分区，分别是P0/P1/P</li><li>每个分区有3个副本，比如分区P0的第一个副本在BrokerA上，另外两个副本在BrokerB和BrokerC上。<br>分区是为了方便队列能并发的生产和消费，一个队列可以拆分成多个分区，分布在相同或不同的机器上。</li></ol><p>副本是为了保持队列的容灾和高可用，所以每个分区可以设置一个或多个副本，每个副本必须分布在不同的机器上，以保持N-1的机器宕机可用性，但客户端在生产和消费消息时，只会在主副本上进行。</p><p>相应的消息可靠性，体现在一条消费发送给服务端的时候，需要有几个副本收到才能算生产成功。如果可靠性要求很高，那么可以设置队列的ack为-1，要求所有副本收到后才算生产成功，或设置为 1 ，表示只要主副本收到后就算成功。</p><p>集群维度的可靠性，也可以通过设置最小同步副本(minInSync replica count)，表示必须有这么多个副本处于同步状态时，集群才可以使用，否则拒绝写入，以防止在副本不同步的情况下，发生几起宕机后，消息丢失。</p><p><strong>存储模型</strong></p><p>kafka的消息存储大量使用文件，所有的消息都存储在文件中，文件使用二进制编码。每个partition有一组相应的文件，在每个文件内，消息按顺序追加到文件末尾。每个消息有标准的存储格式，以字节方式写入每个partition有多个副本，分布在不同的机器上，副本之间依靠复制来保持消息高可用。副本在拉取主本消息后，写入本机磁盘作为备份。一般每个partition会有两到三个副本，副本之间依靠zookeeper来选主，只有主副本会接受客户端的读写。</p><p>如下图所示，有三个partition，每个partition的消息都是顺序追加，老数据在文件头，新数据在文件末尾，这样做得好处是，如果生产和消费都能跟的上，相差时延不多，那么新数据在被落盘之前，已经在pagecache里被消费者拿走消费了，效率非常高。</p><p>此外，在消息写入和读取时，因为使用顺序读写文件，效率也很高，基本都是disk IO bound型操作，cpu和内存使用非常少，不会遇到java gc带来的问题。</p><p>除了消息文件之外，还有一些index索引文件，各种checkpoint文件，leader epoch等帮助文件。除了zookeeper中存储的队列元数据信息外，其他数据全部存储在磁盘上。</p><blockquote><p>下图引用自kafka官方文档</p></blockquote><p><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic10.jpg"></p><p>**生产和消费模型 **</p><p>如上文所介绍，所有的消息都是按照partition来存储的，一个队列可以有多个partition，在partition内，消息是按顺序来写入的，partition之间的顺序依据用户的hash策略不同而不一样。多个partition有助于消息并发生产和写入，消息在消费时，也是按照partition来分配的，一个消费者可以分一个或多个partition，但是一个partition只能分给一个消费者。消费是按照组的粒度来区分的，每个消费组都能完整消费到一个队列的所有消息。每个消费组内，各个消费者之间，按照抢占方式来获取所消费的partition，抢占分配策略不同。因为partition数量和消费者数量不一定完全匹配，前者大于后者时，需要一个消费者承担多个partition的消费，相反，如果后者大于前者时，会有消费者抢占不到partition而处于闲置状态，如下图所示：</p><blockquote><p>下图引用自kafka官方文档</p></blockquote><p><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic12.jpg"></p><p><strong>Kafka架构的优势和劣势</strong></p><p>从技术架构⻆度来讲，kafka具有以下优势和劣势</p><p><strong>优势:</strong></p><ol><li>吞吐高，延迟低：因为消息的读写采用了顺序文件读写，效率高，速度快，kafka的吞吐非常大，延迟也很低。</li><li>可用性高，可靠性高：因为使用了分布式的方式，partition有自己的多副本，副本所在节点宕机后，依靠zookeeper一致性来选主，很快有副本顶上来作为主副本，在系统内有机器节点宕机时，可以维持n-1(n<br>为副本数量)的可用性。如果设置为ack=-1和mi nInsyncIRS &gt;=2，只有所有副本写入后才算发送成功，而且集群内一直保持有足够的副本同步，消息的可靠性很高。</li><li>扩缩容维护简单：一个集群内所有机器等位，扩缩容方法简单，加入机器、或减少机器，然后开启数据再平衡即可实现。</li><li>无j ava gc相关问题： 因为消息数据最终都是写入磁盘，在内存中没有存储和替换，对java内存使用少，没有java gc相关的问题。</li></ol><p><strong>劣势:</strong></p><ol><li>系统复杂：因为采用了分布式系统多活机制，集群内主节点和其他节点的通信，集群内选主，partition leader选主，主题的上下线，消息清除等，这些节点间的rpc调用以及集群内选主等带来了复杂本地数据维<br>护，特别是在多节点数据一致性方面，很容易产生bug。</li><li>消费这和分区关系强耦合，不够灵活：一个分区只能分给一个消费者消费，要增加消费能力，增加新的消费者，就必须扩容分区数量，消费者数量决定分区多少，间接会增大集群内分区数量的消耗。</li><li>集群必须附带一个zookeeper，增加维护成本：kafka将集群内一致性选主问题委托给zookeeper来处理，导致部署kafka时，必须部署一个zookeeper，多了一个组件，增加了一定的运营维护成本。</li></ol><h3 id="Apache-RocketMQ"><a href="#Apache-RocketMQ" class="headerlink" title="Apache RocketMQ"></a>Apache RocketMQ</h3><p>RocketMQ 主要包含两个模块 Broker和NameServer，如下图所示:<br><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic7.svg"></p><p><strong>NameServer</strong></p><blockquote><p>以下引用自rocketmq github 文档</p><p>NameServer是一个非常简单的Topic路由注册中心，其⻆色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。</p></blockquote><blockquote><p><strong>主要包括两个功能：</strong></p></blockquote><blockquote><ol><li>Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；</li><li>路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。</li></ol><p>然后Producer和Consumer通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。</p><p>NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息 ，所以&gt;每一个NameServer实例上面都保存一份完整的路由信息。</p><p>当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。</p></blockquote><p><strong>Broker</strong></p><p>Broker主要负责消息的存储、投递和查询以及服务高可用保证。broker会每隔30s向集群中的所有nameserver发送一个心跳包，nameserver会每隔10s扫描自己保存的broker列表，看broker最后一次发送的心跳包<br>是否是 12 0s前的，如果是就删除这个broker，关闭链接。</p><p><strong>生产端和生产端集群</strong></p><p>Producer与NameServer集群中的其中一个节点（随机选择）建立⻓连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立⻓连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。</p><p>group name相同的一组生产端，称之为生产端集群。集群内每个生产者都会给master发送心跳，所以master是掌握所有生产者信息的，在事务消息回查时，broker端可选择生产端集群中的一个，来执行回查逻<br>辑。</p><p><strong>消费端和消费端集群</strong></p><p>Consumer与NameServer集群中的其中一个节点（随机选择）建立⻓连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立⻓连接，且定时向Master、Slave发送心跳。</p><p>Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等<br> 因素建议下一次是从Master还是Slave拉取。<br>groupname相同的消费端，称之为一个集群。集群内每个消费者都会给broker发送心跳，所以broker端也掌握了所有消费者的信息，每个消费者上线、或下线时都会来查阅这个信息，进行队列重分配。</p><p><strong>Broker集群</strong><br>RocketMQ的集群比较特殊，是多个单元组成的一个集群。如上图所示，整个集群包含 5 台broker，两个单元，第一个单元是 3 台b roker，一主两从，第二个单元是一主一从。集群的划分是以cluster name名称为准<br>备，命名相同的机器都属于一个集群。如上图，所有broker的cluster name属性都叫order-cluster，他们都属于一个集群。<br>name相同的一组broker是一个单元，同一单元内，id属性为0的broker是ma ster，id属性为1的为第一slave，其他都是slave.</p><p><strong>队列存储模型</strong><br>Kafka里每个topic各自的partition消息，都会写入自己的文件里。RocketMQ不一样，它把所有的topic数据全部写入一个文件里，称之为commit log。Broker接收到消息后，统一都写入一个消息日志(commit log)<br>文件，由转发服务(reput Service)再转发生成消费队列(consume queue)文件，如下图所示:</p><p><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic8.svg"></p><p>上图可以看到有两个文件：</p><blockquote><p>*以下引用自rocketmq github 文档<br>(1) CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定⻓的。单个文件大小默认1G ，文件名⻓度为 20 位，左边补零，剩余为起始偏移量，比如<br>00000000000000000000 代表了第一个文件，起始偏移量为0，文件大小为 1 G=1073741824；当第一个文件写满了，第二个文件为 00000000001073741824 ，起始偏移量为 1073741824 ，以此类推。消息主要<br>是顺序写入日志文件，当文件满了，写入下一个文件；</p></blockquote><p>(2) ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，类似于kafka中的partition概念，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的c ommitlog索引文件。同样consumequeue文件采取定⻓设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、 4字节的消息⻓度、 8字节tag hashcode，单个文件由 3 0W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；</p><p>还有一个文件是:</p><blockquote><p>*以下引用自rocketmq github 文档</p><p>IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为 400M，一个IndexFile可以保存<br>2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。</p></blockquote><p><strong>RocketMQ架构的优势和劣势</strong></p><p>从架构上来看，RocketMQ具有以下优势和劣势</p><p><strong>优势:</strong></p><ol><li><p>模型简单：架构比kafka要简化很多，kafka是多节点组成的集群，RocketMQ简化为多组两台机器组成的主从结构集群。存储模型上，Kafka有复杂的节点controller控制节点来负责切换集群leader，分区leader，创建删除partition，replica等，容灾依靠多副本复制机制，以及高水位控制消费和副本拉取，rocketmq简化为一个commitLog和多个consume queue来实现，容灾依靠简单一对一或对多复制。</p></li><li><p>结构松散，模块之间无紧耦合的关系: NameServer是无状态的，可以多台部署，每台之间⻆色等位，单台宕机无影响；Broker服务发现依靠自行、定期上报到NameServer上去，NameServer对broker的简况检查也是定期巡检(默认10s心跳间隔，120s剔除)，来实现添加、删除Broker实例。NameServer和Broker之间网络抖动基本无影响，相互影响力弱。这点要优于kafka，Kafka和zookeeper之间的网络抖动、broker或zookeeper发生OOM无法响应心跳时，broker的状态会发生抖动。</p></li><li><p>组件单一，无依赖第三方组件: 集群内主从是固定死的，在部署都已经定义好，不需要选主操作，在部署上不需要额外部署zookeeper这样的一致性组件。</p></li></ol><p><strong>劣势:</strong></p><ol><li>由于消息数据全部落在一个commit log文件上，消费端检索消息时不能批量获取，需要逐个检索，在队列的qps增大时，对CPU的损耗比较大。</li><li>集群是有多组两台主从结构组成，在队列量数量变多、或是队列消息量变大时，因为所有机器并不像kafka一样⻆色等位，产生的集群扩缩容运维会比较繁琐。</li><li>存储模型上，一个JVM实例仅有一个数据文件，资源利用率不高。单机部署多个实例时，会产生额外的JVM、OS资源占用。</li><li>数据文件采用mmap读写，虽然效率很高，但mmap本身有诸多缺陷，比如mmap在jvm内无法显式unmap，必须等jvm内存gc或通过hack方法来回收，但是mmap在进程内文件句柄数又是有限的，如果不及时回收，可能会耗尽，mmap最大文件大小不能超过2G。</li></ol><h3 id="Apache-Pulsar"><a href="#Apache-Pulsar" class="headerlink" title="Apache Pulsar"></a>Apache Pulsar</h3><p>Pulsar实际上是两个开源组件的组合，Pulsar集群+BookKeeper集群，下图是Pulsar的架构概览：</p><p><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic5.svg"></p><p><strong>Pulsar架构简述:</strong></p><ol><li>Pulsar依赖一个开源项目Apache BookKeeper，使用它来做消息存储，而pulsar本身是一个无状态服务。</li><li>Apache BookKeeper是一个分布式的日志条目(log entry)存储服务。</li><li>Pulsar和b ookeeper都使用zookeeper来存储自己的元数据，并在启动时往zookkeeper上注册节点，来供其他节点或客户端发现自己。</li><li>zookeeper同时负责监控pulsar和b ookkeeper的健康状态。</li></ol><p>由此可⻅，Pulsar是一个典型的“计算+存储”类型的消息队列，Pulsar本身只做消息队列层的概念抽象逻辑，真正的消息数据落地在BookKeeper中。这种架构类似于美团很早之前自研消息队列Swallow，后者使用MongoDB作为存储，前端也是做简单的消息队列抽象逻辑。</p><p>在“计算层”，Pulsar抽象出了topic(主题)，subscription(订阅)和cursor(游标)的概念。topic是消息队列，是一系列连续的消息实体，日志结构的数据，每个消息一个偏移量(offset)；subscription是消费者的订阅关系，定义了消费者消费哪个主题，是独享消费，还是和其他消费者共享消费；cursor消费的位点信息，表示消费者消费到了topic里哪个位置。</p><p>在“存储层”，BookKeeper也是Yahoo开发的，之前是作为Apache Zookeeper的一个子项目，而后在 2015 年孵化为Apache的正式项目，bookkeeper人和zookeeper的是开发者是同一批人。</p><p>BookKeeper是一个通用的日志(log)存储方案，它定义了几个实体，entry是日志中的最小实体，类似于消息队列中的”消息”，一部分连续的entry组成了fragement(片段)，若干个fragement组成一个ledger(账本)。pulsar在抽象消息队列时，将entry抽象为自己的消息，ledger抽象为自己的topic。BookKeeper是以集群形式工作的，集群中每台机器称之为Bookie。</p><p>BookKeeper内没有leader或c ontroller的概念，客户端在写入时，需要设置E(Ensemble)，E实际就是几个Bookie集合，从现有的集群中选取几个。Qw(Write Quorum)是在E这个集合内，客户端在写入数据时，需要在多少个机器上写入，为的是将数据做备份和冗余，当某台bookie宕机后保持高可用。Qa(Ack Quorum)是在Qw内，客户端需要等待多少个Bookie机器确认存储完数据后返回写入成功。如下图所示，E是3台Bookie机器，Qw是3 ，Qa也是3 ，当然为了加快写入速度，可以将Qa设置为2或1，但也会相应增加机器宕机后数据丢失的⻛险，因为确认写入数据的机器数变少了。</p><p>如果某个bookie宕机了，client可以迅速形成新的E集合，并且在可用的E内选取新的Qa，对于增量数据来说，恢复速度比较快。</p><p><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic4.svg"></p><p>每台Bookie在接收数据时，需要将数据真实flush到磁盘上才算写入成功，为了加快写入速度，BookKeeper也使用了类似于Zookeeper和Mysql的group commit机制，由此可⻅Bookeeper的高可靠是依靠数据写入多个磁盘来保障的，不同于Kafka的依靠复制来保障。<br>真实数据在Bookkeeper内部的保存方式要复杂很多，如下图所示：</p><p><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/pic6.svg"></p><p><strong>BooKKeeper存储架构简述:</strong></p><ol><li>bookie内部使用两种类型的文件journal file和log EntryFile，还有一个RocksDB组件来存储数据。</li><li>官方建议使用两块磁盘来做存储，一块磁盘专用于写journal file，另一块专⻔用来写log entryFile和作为rocksDB存储盘来使用。</li><li>RocksDB也是一个开源的KV存储组件</li><li>写入数据时，需要同步先将数据写入到journal file中，然后异步线程再将数据写入log entryFile和RocksDB，这种存储方式是一个典型WAL(write ahead logging)案例应用。</li><li>在同步写入journal file时，也会同步写入一份到Write Cache里，这个cache是一个内存数据结构。在write cache内，数据会按topic分类来排序，以便以后在读取时能提升读取效率。</li><li>写入write Cache后，异步线程会将真实数据写入log EntryFile(一个树形存储结构)里，同时将消息(entry)条目在log EntryFile里的位置索引记录在rocksDB里，以方便后续读取。</li><li>write Cache会缓存最近的写入，所以最近写入的消息读取效率会很高，如果读取稍早的数据，或数据已经不在cache里的，需要到Log EntryFile磁盘文件里去溯源。</li></ol><p><strong>Pulsar架构的优势和劣势</strong></p><p>从架构来看，pulsar有以下优势和劣势<br><strong>优势:</strong></p><ol><li>因为消息可以选择ack最快的两个节点来存储，可以避免慢节点写入带来的延时影响。</li><li>集群可以快速扩容，新加入的bookie节点可以很快作为Qw的一员来接收消息。</li><li>由于整个集群没有leader的概念，所以不存在脑裂的⻛险。而kafka则会由于网络分区，形成脑裂。</li></ol><p><strong>劣势:</strong></p><ol><li>架构比较复杂，整个架构包含pulsar，bookkeeper，rocksDB三个组件，数据分散在这三个组件内。</li><li>数据存储模型复杂，最小存储单元fragement的Q a可以在多个bookie上，整个集群内fragement数量会巨大，而且分布琐碎和零散，维护复杂度高。而且读取时需要跳跃在多台机器上读取，效率会比较低下。</li><li>强依赖zookeeper。因为ledger、fragement对应关系，存储位置等信息都存放在zookeeper上，一旦一台bookie连接不上zookeeper，为了保持一致性，bookie停止接受服务，并自动重启，这意味着一旦集群内几个节点、或全部链接不上zookeeper，或者zookkeeper挂掉，整个集群都无法再继续服务。</li><li>没有顺序写入和读取的优势，在写入时需要做group commit，强制刷盘，读取时则需要根据索引在文件内随机读取，整体磁盘使用效率低。</li><li>bookie单点宕机后，仍然需要批量移动大量数据作为容灾副本恢复。 这点跟kafka类似，但比kafka好的是，增量数据不会有可靠性威胁，因为bookie在单点宕机后可以快速形成新的副本组，而kafka则需要通过打散来补⻬副本，在此之前，无论增量数据还是历史数据都少一个副本。</li></ol><p><strong>Pulsar的演进规划</strong></p><p>pulsar的商业支持公司streamnative.io，已经将pulsar搬到云上，提供消息和事件流式计算服务。规划中的发展方向包含以下几个方面：</p><ol><li>Pulsar Function: 类似于kafka stream的轻量流式计算，在pulsar内部做流式计算，不需要将数据再搬运到storm/flink一类大数据组件上。</li><li>Pulsar IO: 类似于kafka connect，使用pulsar桥接两个系统的数据流，比如从database到应用，从database到hBase大数据存储。</li><li>分层存储：类似于kafka 分层存储，将老数据搬运到低廉的存储组件上，例如S3，hadoop一类，而保持新数据在pulsar本地，降低pulsar的机器成本。</li><li>Helm: 类似于confluent商业公司的运营平台，通过平台来运维管理pulsar集群。</li></ol><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p>附录A: 业界消息队列产品概要<br><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/append1.png"><br><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/append2.png"><br><img src="/2021/03/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%9A%E7%95%8C%E8%B0%83%E7%A0%94/append3.png"></p>]]></content>
    
    
    <summary type="html">本文对目前业界比较流行的三个消息队列产品做了对比和分析</summary>
    
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://wangjunfei.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="rocketmq" scheme="https://wangjunfei.com/tags/rocketmq/"/>
    
    <category term="kafka" scheme="https://wangjunfei.com/tags/kafka/"/>
    
    <category term="pulsar" scheme="https://wangjunfei.com/tags/pulsar/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第五章 灰度选拔</title>
    <link href="https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%80%89%E6%8B%94/"/>
    <id>https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%80%89%E6%8B%94/</id>
    <published>2021-03-16T07:49:45.000Z</published>
    <updated>2024-03-24T00:58:30.788Z</updated>
    
    <content type="html"><![CDATA[<p>华为的干部评价标准包括品德价值，核心价值观，绩效和能力四个维度。</p><p>品德价值是底线，核心价值观是基础，绩效是必要条件和分水岭，能力是关键成功因素。这四句话是华为高层对于干部标准的高度概括。</p><h2 id="华为干部“四力”"><a href="#华为干部“四力”" class="headerlink" title="华为干部“四力”"></a><a href="#%E5%8D%8E%E4%B8%BA%E5%B9%B2%E9%83%A8%E2%80%9C%E5%9B%9B%E5%8A%9B%E2%80%9D" title="华为干部“四力”"></a>华为干部“四力”</h2><p>决断力<br>所谓决断力，就是要求高层干部冒敢于评估的风险，去做决策。敢于决策，且善于决策的人，才能成为高层干部，才能成为接班人。</p><h3 id="理解力"><a href="#理解力" class="headerlink" title="理解力"></a><a href="#%E7%90%86%E8%A7%A3%E5%8A%9B" title="理解力"></a>理解力</h3><p>理解力就是要听懂公司对于战略和战术背后的布局，并且变成自己的行动。</p><h3 id="执行力"><a href="#执行力" class="headerlink" title="执行力"></a><a href="#%E6%89%A7%E8%A1%8C%E5%8A%9B" title="执行力"></a>执行力</h3><p>执行力的培养是一个漫长的过程。</p><h3 id="人际连接力"><a href="#人际连接力" class="headerlink" title="人际连接力"></a><a href="#%E4%BA%BA%E9%99%85%E8%BF%9E%E6%8E%A5%E5%8A%9B" title="人际连接力"></a>人际连接力</h3><p>能当面聊绝不打电话，能电话说清绝不发邮件。对于干部来讲，要鼓励通过主动沟通来解决问题。</p><p>不同类型的干部对于四力的把控，可以从人员分级上来考量：</p><p>高层干部培养决断力，中基层干部要加强理解力，执行力和人际连接力。</p><p>对于高层干部，要更多的使用使命感去激发他们。</p><p>对于中层干部，要加强他们的危机感和紧迫感，让他们多做事，多动脑。</p><p>对于基层干部，要给他们构建起一种饥饿感，让他们觉得总有更多的目标要完成，有更多的事情去做。</p><h2 id="明确指的优先选拔的干部类型"><a href="#明确指的优先选拔的干部类型" class="headerlink" title="明确指的优先选拔的干部类型"></a><a href="#%E6%98%8E%E7%A1%AE%E6%8C%87%E7%9A%84%E4%BC%98%E5%85%88%E9%80%89%E6%8B%94%E7%9A%84%E5%B9%B2%E9%83%A8%E7%B1%BB%E5%9E%8B" title="明确指的优先选拔的干部类型"></a>明确指的优先选拔的干部类型</h2><p>第一类 有成功搞得区域业务实践经验。</p><p>第二类 是在影响公司长远发展的关键事件中表现突出的干部。要鼓励干部在关键时候敢于作为，敢于挺身而出。</p><p>第三类 是有干劲，服从公司安排，愿意承担挑战性岗位和更大责任的干部。</p><p>华为干部管理中还有一个重要的原则，叫作从成功的组织中选拔干部。如果一个组织没有达到好的绩效结果，就算一把手被免掉了，二把手、三把手也根本没有机会被提拔。</p>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第四章 灰度高效组织体系</title>
    <link href="https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%AB%98%E6%95%88%E7%BB%84%E7%BB%87%E4%BD%93%E7%B3%BB/"/>
    <id>https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E7%81%B0%E5%BA%A6%E9%AB%98%E6%95%88%E7%BB%84%E7%BB%87%E4%BD%93%E7%B3%BB/</id>
    <published>2021-03-16T07:48:59.000Z</published>
    <updated>2024-03-24T00:58:30.788Z</updated>
    
    <content type="html"><![CDATA[<p>很多企业组织是金字塔结构，一线员工发现了客户的需求或者机会要层层汇报，最后由总经理拍板。拍板后的决定又层层下传，到一线落地执行。这样的流程往往会夹杂一些自己的意见，最终决策人会因为对信息的真实性与准确性产生怀疑而难以判断。</p><p>华为是怎么突破这个呢？华为通过20年的管理变革，塑造了流程性组织。流程性组织最大的特点是决策指令并不来自于最高层，而是来自离客户最近的人，这就是以客户为中心的导向驱动。</p>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第三章 灰度的评价</title>
    <link href="https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%9A%84%E8%AF%84%E4%BB%B7/"/>
    <id>https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%9A%84%E8%AF%84%E4%BB%B7/</id>
    <published>2021-03-16T07:47:49.000Z</published>
    <updated>2024-03-24T00:58:30.788Z</updated>
    
    <content type="html"><![CDATA[<p>选对人，是人力资源成功的第一步。要向达到卓越的成果，我们就需要对绩效目标进行科学的管理。</p><p>价值评价的根本在于精准，但是人类社会在人才价值度量上是无法做到精准的，华为的灰度思想，就是要在牢牢抓住科学目标的基础上，允许绩效评价的迭代与优化。</p><h2 id="科学的目标管理体系"><a href="#科学的目标管理体系" class="headerlink" title="科学的目标管理体系"></a><a href="#%E7%A7%91%E5%AD%A6%E7%9A%84%E7%9B%AE%E6%A0%87%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB" title="科学的目标管理体系"></a>科学的目标管理体系</h2><p>绩效管理要紧紧围绕科学的目标，公正的过程和刚性的应用这三个方面展开。</p><p>刚性的应用:<br>我们花了很多精力去做目标管理，做公证的评价，但如果是评价出来的结果没有得到有效应用，那其实整个绩效工作也是没有意义的，所以一定要依据评价结果，做到刚性的应用。</p><h2 id="区别对待不同层级，做到公正底考核"><a href="#区别对待不同层级，做到公正底考核" class="headerlink" title="区别对待不同层级，做到公正底考核"></a><a href="#%E5%8C%BA%E5%88%AB%E5%AF%B9%E5%BE%85%E4%B8%8D%E5%90%8C%E5%B1%82%E7%BA%A7%EF%BC%8C%E5%81%9A%E5%88%B0%E5%85%AC%E6%AD%A3%E5%BA%95%E8%80%83%E6%A0%B8" title="区别对待不同层级，做到公正底考核"></a>区别对待不同层级，做到公正底考核</h2><p>通过PBC对中基层员工进行绩效管理<br>中基层员工根据他们的工作职责去承接一部分战略落地结果。对于这个群体，要引导他们用正确的方法去做正确的事，不断追求更好的工作效果，不需要太复杂的绩效目标进行考核，只要符合他们的岗位职责即可。</p><p>用这种方式去管理目标，我们需要重点考量三个因素。第一，阶段性工作目标，第二关键措施，第三，中基层员工他们的团队合作。</p><h2 id="高层人员的绩效管理主要采用述职的方法"><a href="#高层人员的绩效管理主要采用述职的方法" class="headerlink" title="高层人员的绩效管理主要采用述职的方法"></a><a href="#%E9%AB%98%E5%B1%82%E4%BA%BA%E5%91%98%E7%9A%84%E7%BB%A9%E6%95%88%E7%AE%A1%E7%90%86%E4%B8%BB%E8%A6%81%E9%87%87%E7%94%A8%E8%BF%B0%E8%81%8C%E7%9A%84%E6%96%B9%E6%B3%95" title="高层人员的绩效管理主要采用述职的方法"></a>高层人员的绩效管理主要采用述职的方法</h2><p>述职就是不断地通过和战略目标对标，将公司的战略目标分解过程和执行效果进行及时的校准，形成考核依据。</p><p>通过述职的方式还有一个好处，即可以促进高层领导理清思路，明确责任，抓住重点，综合平衡。</p><p>高层述职要掌握两个重点：</p><p>第一，绩效目标要形成“扭麻花”</p><p>设么叫扭麻花？比如，我们想要把销售目标传递下去，销售部门要制定目标，产品技术部门也要制定同样的目标，要形成合理去构建目标体系。</p><p>第二，要关注不同阶段的目标设计。</p><h2 id="绩效管理的原则"><a href="#绩效管理的原则" class="headerlink" title="绩效管理的原则"></a><a href="#%E7%BB%A9%E6%95%88%E7%AE%A1%E7%90%86%E7%9A%84%E5%8E%9F%E5%88%99" title="绩效管理的原则"></a>绩效管理的原则</h2><p>第一个原则，以行为为导向，引导员工以正确的行为做正确的事，不断改进工作。</p><p>第二个原则，个人目标和组织目标一致。</p><p>第三个原则，客观公正。 考核结果要以客观事实和数据为依据，考核过程要透明、公开，千万不能搞模棱两可的打分制。我非常反对360度评测，在华为没有这种评测机制。大家都说的那个人一定真的好么？ 不一定。真正做事情的人，必然会在做事的过程中与他人产生一些冲突，这种冲突一定会反应到别人对他的评价里来。</p><p>绩效管理的目的是什么？ 不是去考察一个不做事的人的人际关系，而是要考虑他实实在在的贡献，我们的评价一定要以事实为依据，以目标数据为考量标准，而不能考察人情分。</p><h2 id="做好PDCA循环，做到公正的执行"><a href="#做好PDCA循环，做到公正的执行" class="headerlink" title="做好PDCA循环，做到公正的执行"></a><a href="#%E5%81%9A%E5%A5%BDPDCA%E5%BE%AA%E7%8E%AF%EF%BC%8C%E5%81%9A%E5%88%B0%E5%85%AC%E6%AD%A3%E7%9A%84%E6%89%A7%E8%A1%8C" title="做好PDCA循环，做到公正的执行"></a>做好PDCA循环，做到公正的执行</h2><p>在PDCA循环中，正确的时间分配是，30%的时间花在绩效目标上，50%的时间拿来做绩效辅导，绩效评价10%，绩效反馈10%。对于管理者来说，绩效辅导就是把自己的成功经验和下属分享，最常用的方法就是开例会。一轮PDCA循环后，员工被分为了不同的等级，应该关注哪类人呢： 即关注最优秀的人和最差的人。这就是管理常说的“二八原则”，即用最少的成本抓住主要矛盾，这也是管理者要解决的问题。</p><p>绩效结果公开制度对管理者而言又是一个陡然的压力，意味着认为绩效评价不合理的员工有可能向公司投诉，管理者的盖子就捂不住了，评价不公正就会被揭开。这样的改个把绩效目标的设定和绩效评估的过程变得更加严格。这就是为什么刚性的应用可以优化整个绩效管理的过程，同时形成正向的绩效发展导向。</p>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第二章 灰度用人之法</title>
    <link href="https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%94%A8%E4%BA%BA%E4%B9%8B%E6%B3%95/"/>
    <id>https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%81%B0%E5%BA%A6%E7%94%A8%E4%BA%BA%E4%B9%8B%E6%B3%95/</id>
    <published>2021-03-16T07:47:02.000Z</published>
    <updated>2024-03-24T00:58:30.788Z</updated>
    
    <content type="html"><![CDATA[<h2 id="华为用人的六条标准"><a href="#华为用人的六条标准" class="headerlink" title="华为用人的六条标准"></a><a href="#%E5%8D%8E%E4%B8%BA%E7%94%A8%E4%BA%BA%E7%9A%84%E5%85%AD%E6%9D%A1%E6%A0%87%E5%87%86" title="华为用人的六条标准"></a>华为用人的六条标准</h2><p>很多企业没有用人标准，每个面试官都按照自己的思路招人。但其实一个企业就像是企业家的孩子，最重要的是要传承基因。企业只有有了基因密码，才可以复制和掌握。</p><ol><li>全力以赴的奋斗精神</li></ol><p>想要打造一支狼性团队，就一定不能找绵阳；找了一群绵阳，想要把它们培养成狼，这是绝对不可能的。所以要打造一支狼性团队，首先要招狼崽。从人才人口触发，就是要找全力以赴、有奋斗激情的人。</p><ol start="2"><li>客户为先的服务意识</li></ol><p>一个企业要打造以客户为中心的文化，前提是要有以客户为先的服务意识。</p><ol start="3"><li>至诚守信的优秀品格</li></ol><p>在华为，大家在会上承诺要做的事，到规定时间一定都会很自觉地交出成绩单，这就是诚信。</p><p>华为把诚信设为高压线，一旦触碰就会立即被开除。</p><ol start="4"><li>积极进取的开放心态</li></ol><p>对于新事物要永远保持一个积极开放的心态。许多大企业的员工总有一副高高在上的姿态，这是很不可取的。一定要始终保持开放的心态，主动而为，积极开放，这样爱能接纳更多好的动心，并为己所用。</p><ol start="5"><li>携手共进的合作精神</li></ol><p>这也是华为用人标准中很重要的点。在华为内部有一句话：胜则举杯相庆，败则拼死相救。</p><ol start="6"><li>扎实的专业知识与技能</li></ol><p>华为的六条用人标准中，真正针对专业技术的要求只占一条，而且放到最后。为什么？因为人的能力是可变的，知识技能也是可变的，但是人的素质是早已形成的，不是说变就能变的。</p><h2 id="华为识人的五项素质"><a href="#华为识人的五项素质" class="headerlink" title="华为识人的五项素质"></a><a href="#%E5%8D%8E%E4%B8%BA%E8%AF%86%E4%BA%BA%E7%9A%84%E4%BA%94%E9%A1%B9%E7%B4%A0%E8%B4%A8" title="华为识人的五项素质"></a>华为识人的五项素质</h2><h3 id="1-第一个素质：主动性"><a href="#1-第一个素质：主动性" class="headerlink" title="1. 第一个素质：主动性"></a><a href="#1-%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E4%B8%BB%E5%8A%A8%E6%80%A7" title="1. 第一个素质：主动性"></a>1. 第一个素质：主动性</h3><p>主动性是指人在工作当众补习投入更多的精力，善于发现和创造性的机会，提前预测事情发生的可能性，采取行动，从而提高工作绩效，避免问题的发生和创造新的机遇。</p><p>这种主动性不只是简单地积极行动，而是强调要有结果，要有预见性，而且这种预见性要产生好的结果。</p><p>主动性可以分为四个等级：</p><ul><li>主动性零级的人不会自觉完成工作，需要他人的督促，不能提前计划和思考问题，直接问题发生才意识到事情的严重性。</li></ul><p>主动性一级的人能主动行动，自觉投入更多的努力去工作。这类人不需要别人督促，只要分配的工作在他的工作范围内，他就会自觉的投入时间去做。</p><ul><li><p>主动性二级的人能主动思考、快速行动，及时发现某种机会和问题，并快速做出反应。二级建立在一级的基础之上，主动性二级的人不光能快速自觉地工作，还会主动思考，预判某一种情况，然后采取相应的行动。二级建立在一级的基础之上，主动性二级的人不光能快速的自觉地工作，还会主动思考，预判某一种情况，然后采取相应的行动。如果你手下有这样总是“蠢蠢欲动”的人，那真是捡到宝贝了。</p></li><li><p>主动性三级是最高等级。这类人不会等着问题发生，而是会未雨绸缪，提前行动，规避问题，甚至创造出机会来。谈管理的时候，常常会说抗洪的一个例子。很多人说洪水来的时候有抗洪先锋就行了，但也有人说我们平时把工作做好，疏浚通淤，建造堤坝，就不会有洪水发生。这个例子很好的说明了主动性二级和三级的区别。</p></li></ul><h3 id="2-第二个素质：概念思维"><a href="#2-第二个素质：概念思维" class="headerlink" title="2. 第二个素质：概念思维"></a><a href="#2-%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E6%A6%82%E5%BF%B5%E6%80%9D%E7%BB%B4" title="2. 第二个素质：概念思维"></a>2. 第二个素质：概念思维</h3><p>我们常说要找聪明人，那么聪明和不聪明的人区别到底在哪里呢？其实最主要的是概念思维，换言之就是思考方式。概念思维是一种识别表面上没有</p><p>明显联系的事情之间内部联系本质特征的能力，也就是说在面对不确定现象的时候，能找到里面的要害，高屋建瓴，一语道破。这是一种大的思维结构，要根据有限的信息作出全面的判断。能做这种结构话思维的人就是聪明人。</p><p>概念思维也分为四个等级。</p><ul><li><p>概念思维零级的人不能准确而周密地去思考问题，碰到问题想不清楚，弄不明白。</p></li><li><p>概念思维一级的人可以进行简单的类比。所谓简单的类比，就是根据自己过去的经验，对某个行为进行类似的复制。比如说我会打篮球，那么在此基础上，我也能通过简单类比，很快学会其他相似的球类运动。</p></li><li><p>概念思维二级的人能触类旁通。触类旁通通就是指运用复杂概念的能力，通过掌握事物发展的客观规律，以点带面的思考问题。比如我是厨师，菜炒的很好，同时我也可以去做管理，用炒菜的方式来管人。有一些做营销的人跨界做人力资源管理也做得很好，去做财务也能胜任，那是因为每个职位背后的深层规律是相同的。更厉害的人可以跨行业，在不同的行业间游刃有余低地切换。</p></li></ul><p>这不是因为他们是天才，而是因为他们掌握了事物发展的根本规律，做到了触类旁通。</p><ul><li>概念思维三级的人懂得深入浅出，他们不仅能将复杂事务一眼看破，还能高度总结成简单易懂的概念，让别人也能理解。</li></ul><p>老子在《道德经》中讲过一句话，叫做“治大国如烹小鲜”，意思是治理一个大国这么复杂的事情其实就跟做一锅菜是一样的。</p><p>再举一个例子，1997年，李一男在华为领导无线产品的开发。当时华为要从固网转到无线产品开发，没有任何积累。李一男就从国外的了类似产品的一张产品说明书开始，构建起了庞大的华为无线产品开发体系。李一男之所以能创造这样的奇迹，是因为他能够深入浅出地抓住事物的深层规律。</p><h3 id="3-第三个素质：影响力"><a href="#3-第三个素质：影响力" class="headerlink" title="3. 第三个素质：影响力"></a><a href="#3-%E7%AC%AC%E4%B8%89%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E5%BD%B1%E5%93%8D%E5%8A%9B" title="3. 第三个素质：影响力"></a>3. 第三个素质：影响力</h3><p>影响力是指施加影响的能力，是试图去说服、劝服、影响他人，留下印象，让他人支持自己观点的能力。影响力其实是一个场，这个场是一个人魅力所构成的天然资源，是一种人与人相互影响的一个方式。影响力的难点在于，主观上我们想要别人接受我们的观点，但是客观上我们又没有权利将自己的意愿强加给别人。</p><p>影响力同样也分为四个等级。</p><ul><li><p>影响力零级的人不能清楚地表达，说服不了比人。这类人不仅不能有效的影响他人，还容易被他人所影响，盲从者、从众者就是典型的代表。</p></li><li><p>影响力一级的人采用直接说服的方法来施加影响，通过向别人讲述理由、证据、事实等来直接说服对方接受自己的观点。在影响别人的过程中，他只能去争理。他会做很多准备，来告诉别人该怎么做。</p></li><li><p>影响力二级的人能换位思考。换位思考就是用别人的话去解决别人的问题，这又高出一个境界。我们经常说某人情商很高，见人说人话，见鬼说鬼话，比如他给你聊家常的时候，其实是在给你讲道理，想要影响你。</p></li><li><p>影响力三级的人用的是综合策略。他会用复杂的策略影响别人，或者通过微妙的手段来使别人接受自己的观点。围魏救赵就是一个典型的例子，我其实想要A，但是我不说A，我讲的是B的故事.</p></li></ul><h3 id="4-第四个素质：成就导向"><a href="#4-第四个素质：成就导向" class="headerlink" title="4. 第四个素质：成就导向"></a><a href="#4-%E7%AC%AC%E5%9B%9B%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E6%88%90%E5%B0%B1%E5%AF%BC%E5%90%91" title="4. 第四个素质：成就导向"></a>4. 第四个素质：成就导向</h3><p>成就导向指的是拥有完成某项任务，或在工作中追求卓越的愿望。也就是说，一个人对自己的定位是小富即安，还是愿意从事具有挑战性的工作。成就导向高的人在公祖欧中会强烈的表现自己的能力，并且不断地为自己树立标准。这就是我们经常讲的自驱力。</p><p>成就导向零级的人安于现状，不追求个人技术或专业上的进步。</p><p>成就导向一级的人追求更好，努力将工作做得更好，或努力要达到某个优秀的标准。</p><p>成就导向二级的人会自己给自己设立富有挑战性的目标，他压根不需要上级给他设定目标，而是会自己给自己设立富有挑战性的目标，并且为了达到目标而努力。</p><p>成就导向三级是最高级，这类人会在仔细权衡代价和收益后，冒着经过评估的风险做出某种决策，他们为了获得更大的成功敢于冒险，这也是我们经常讲的企业家特质之一。</p><h3 id="5-第五个素质：坚韧性"><a href="#5-第五个素质：坚韧性" class="headerlink" title="5. 第五个素质：坚韧性"></a><a href="#5-%E7%AC%AC%E4%BA%94%E4%B8%AA%E7%B4%A0%E8%B4%A8%EF%BC%9A%E5%9D%9A%E9%9F%A7%E6%80%A7" title="5. 第五个素质：坚韧性"></a>5. 第五个素质：坚韧性</h3><p>坚韧性是指在艰苦或不利的条件下能克服自身困难，努力实现目标：面的他人的敌意能保持冷静和稳定的状态，忍受这种压力。聪明人往往坚韧性不够，韧性够的人往往冲劲又不足，但最终成功的人不一定要机位聪明，却一定要能坚持。</p><ul><li><p>坚韧性零级的人经受不了批评、挫折和压力，稍微遇到点压力就选择放弃。坚韧性零级的人很难做成什么事情。</p></li><li><p>坚韧性一级的人叫“压不垮”。这类人在工作中能够保持良好的体能和稳定的情绪，能顶住压力工作。坚韧性一级的人能像老黄牛一样的勤勤恳恳的工作，任劳任怨，但是不能对结果负责，也不一定能把事情做好。</p></li><li><p>坚韧性二级的人叫“干得成”。这类人不仅能在艰苦的环境中顶住压力，重要的是一定能把事情做成。</p></li><li><p>坚韧性三级的人能通过建设性的方式消除他人的敌意或保证自己情绪的稳定，不受制与压力， 还能把压力解除。</p></li></ul><h2 id="用五项素质进行人才的评估"><a href="#用五项素质进行人才的评估" class="headerlink" title="用五项素质进行人才的评估"></a><a href="#%E7%94%A8%E4%BA%94%E9%A1%B9%E7%B4%A0%E8%B4%A8%E8%BF%9B%E8%A1%8C%E4%BA%BA%E6%89%8D%E7%9A%84%E8%AF%84%E4%BC%B0" title="用五项素质进行人才的评估"></a>用五项素质进行人才的评估</h2><p>五项素质的内在逻辑。</p><p>主动性代表一个人的态度、一种追求。</p><p>概念思维是一个人的本体。一个人的本体是良好的、强大的，才能驱动成功。</p><p>影响力是一个人和外部进行能量和信息交互的长，影响力越大，场就越大，对周边的影响也就越大。</p><p>成就导向是一个人的目标追求，目标追求越大，动力就越足。</p><p>坚韧性是一个人的底，这个底构建了人生的基础。如果这个底越厚，也就是如果一个人有很强的韧性，他就可以在人生的历程中客服一个又一个的困难。</p><p>这五项素质反复锤炼，就构成了领军人才需要具备的素养：积极，聪明，有强大的场能影响他人，有远大的追求，面对挑战坚持不懈。</p><h4 id="五项素质的评估结果，对应了三类人才的分类标准："><a href="#五项素质的评估结果，对应了三类人才的分类标准：" class="headerlink" title="五项素质的评估结果，对应了三类人才的分类标准："></a><a href="#%E4%BA%94%E9%A1%B9%E7%B4%A0%E8%B4%A8%E7%9A%84%E8%AF%84%E4%BC%B0%E7%BB%93%E6%9E%9C%EF%BC%8C%E5%AF%B9%E5%BA%94%E4%BA%86%E4%B8%89%E7%B1%BB%E4%BA%BA%E6%89%8D%E7%9A%84%E5%88%86%E7%B1%BB%E6%A0%87%E5%87%86%EF%BC%9A" title="五项素质的评估结果，对应了三类人才的分类标准："></a>五项素质的评估结果，对应了三类人才的分类标准：</h4><ol><li><p>开创性人才：主动性，概念思维，影响力，成就导向，坚韧性均达到二级以上。</p></li><li><p>守成型人才：主动性、概念思维、影响力，成就导向达到一级及以上，坚韧性为二级及以上</p></li><li><p>执行性人才：主动性，概念思维，影响力，成就导向，坚韧性均达到一级。</p></li></ol>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《华为灰度管理法》阅读-第一章 灰度文化</title>
    <link href="https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%81%B0%E5%BA%A6%E6%96%87%E5%8C%96/"/>
    <id>https://wangjunfei.com/2021/03/16/%E3%80%8A%E5%8D%8E%E4%B8%BA%E7%81%B0%E5%BA%A6%E7%AE%A1%E7%90%86%E6%B3%95%E3%80%8B%E9%98%85%E8%AF%BB-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%81%B0%E5%BA%A6%E6%96%87%E5%8C%96/</id>
    <published>2021-03-16T07:40:08.000Z</published>
    <updated>2024-03-24T00:58:30.788Z</updated>
    
    <content type="html"><![CDATA[<p>人性是复杂的，绝对不是简单的黑与白，因此，在构建人才战队的过程中，灰度管理是其哲学精要！以灰度来看，人才是一种资源，管理者与管理的使命就在于激发人的正能量，抑制人的负能量，团结一些可以团结的人，调动一切可以调动的积极性，挖掘一切可以挖掘的潜力，实现公司的目标和战略。</p><p>华为团队管理核心理念的第一条是倡导和建设以客户为中心，以奋斗者为本的高绩效企业文化。这条理念可以分为三条：以客户为中心，以奋斗者为本，高绩效的企业文化。</p><p>以客户为中心是一切行为的导向，以奋斗者为本其实是一种精神。高绩效是一种公平竞争的机制，绩效好，升职加薪，配股提拔，这是一种简介明了的管理风格，不需要太多理论，一切以实事求是的结果为导向。这跟公平的环境、英雄不问出处的氛围有极大的关系。高绩效企业文化其实就是这种英雄不问出处、每个人在公平环境中竞争的体现。</p><p>华为团队管理核心理念的第二条是导向冲锋，持续促进干部员工队伍艰苦分度，传承公司核心价值观。</p><p>华为团队管理核心理念的第三条是以奋斗者为本。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><a href="#%E6%80%BB%E7%BB%93" title="总结"></a>总结</h2><h4 id="核心理念："><a href="#核心理念：" class="headerlink" title="核心理念："></a><a href="#%E6%A0%B8%E5%BF%83%E7%90%86%E5%BF%B5%EF%BC%9A" title="核心理念："></a>核心理念：</h4><ol><li><p>高绩效企业文化</p></li><li><p>导向冲锋</p></li><li><p>以奋斗者为本</p></li></ol><h4 id="高绩效企业的三个关键词"><a href="#高绩效企业的三个关键词" class="headerlink" title="高绩效企业的三个关键词:"></a><a href="#%E9%AB%98%E7%BB%A9%E6%95%88%E4%BC%81%E4%B8%9A%E7%9A%84%E4%B8%89%E4%B8%AA%E5%85%B3%E9%94%AE%E8%AF%8D" title="高绩效企业的三个关键词:"></a>高绩效企业的三个关键词:</h4><ol><li><p>以客户为中心</p></li><li><p>以奋斗者为本</p></li><li><p>高绩效企业文化</p></li></ol>]]></content>
    
    
    <summary type="html">本系列文章是对《华为灰度管理法》阅读笔记</summary>
    
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/categories/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
    <category term="务虚-管理方法论" scheme="https://wangjunfei.com/tags/%E5%8A%A1%E8%99%9A-%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="华为" scheme="https://wangjunfei.com/tags/%E5%8D%8E%E4%B8%BA/"/>
    
    <category term="管理方法论" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    <category term="管理" scheme="https://wangjunfei.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
</feed>
